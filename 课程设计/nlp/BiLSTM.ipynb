{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e82734f-041d-427b-b842-50bde6530265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a0d09729cf4d1faf90a30cbb1663ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111254192267855, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/自然语言处理/wandb/run-20240605_225324-sknhoux1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/moguw/intent-recognition/runs/sknhoux1' target=\"_blank\">pious-snowflake-37</a></strong> to <a href='https://wandb.ai/moguw/intent-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/moguw/intent-recognition' target=\"_blank\">https://wandb.ai/moguw/intent-recognition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/moguw/intent-recognition/runs/sknhoux1' target=\"_blank\">https://wandb.ai/moguw/intent-recognition/runs/sknhoux1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| end of epoch   1 | time:  2.00s | train accuracy    0.139 | valid accuracy    0.248 \n",
      "| end of epoch   2 | time:  1.99s | train accuracy    0.354 | valid accuracy    0.472 \n",
      "| end of epoch   3 | time:  1.99s | train accuracy    0.529 | valid accuracy    0.590 \n",
      "| end of epoch   4 | time:  1.99s | train accuracy    0.639 | valid accuracy    0.662 \n",
      "| end of epoch   5 | time:  1.99s | train accuracy    0.706 | valid accuracy    0.702 \n",
      "| end of epoch   6 | time:  2.03s | train accuracy    0.747 | valid accuracy    0.709 \n",
      "| end of epoch   7 | time:  2.01s | train accuracy    0.784 | valid accuracy    0.760 \n",
      "| end of epoch   8 | time:  2.01s | train accuracy    0.802 | valid accuracy    0.762 \n",
      "| end of epoch   9 | time:  2.01s | train accuracy    0.821 | valid accuracy    0.766 \n",
      "| end of epoch  10 | time:  2.02s | train accuracy    0.843 | valid accuracy    0.769 \n",
      "| end of epoch  11 | time:  2.00s | train accuracy    0.851 | valid accuracy    0.792 \n",
      "| end of epoch  12 | time:  2.01s | train accuracy    0.864 | valid accuracy    0.779 \n",
      "| end of epoch  13 | time:  2.01s | train accuracy    0.879 | valid accuracy    0.793 \n",
      "| end of epoch  14 | time:  1.99s | train accuracy    0.893 | valid accuracy    0.792 \n",
      "| end of epoch  15 | time:  2.02s | train accuracy    0.898 | valid accuracy    0.810 \n",
      "| end of epoch  16 | time:  2.00s | train accuracy    0.909 | valid accuracy    0.805 \n",
      "| end of epoch  17 | time:  2.00s | train accuracy    0.916 | valid accuracy    0.802 \n",
      "| end of epoch  18 | time:  2.00s | train accuracy    0.927 | valid accuracy    0.801 \n",
      "| end of epoch  19 | time:  2.01s | train accuracy    0.947 | valid accuracy    0.811 \n",
      "| end of epoch  20 | time:  2.02s | train accuracy    0.954 | valid accuracy    0.814 \n",
      "| end of epoch  21 | time:  2.01s | train accuracy    0.956 | valid accuracy    0.812 \n",
      "| end of epoch  22 | time:  2.01s | train accuracy    0.961 | valid accuracy    0.816 \n",
      "| end of epoch  23 | time:  2.00s | train accuracy    0.965 | valid accuracy    0.805 \n",
      "| end of epoch  24 | time:  2.00s | train accuracy    0.967 | valid accuracy    0.815 \n",
      "| end of epoch  25 | time:  1.99s | train accuracy    0.968 | valid accuracy    0.804 \n",
      "| end of epoch  26 | time:  1.98s | train accuracy    0.973 | valid accuracy    0.811 \n",
      "| end of epoch  27 | time:  2.01s | train accuracy    0.978 | valid accuracy    0.814 \n",
      "| end of epoch  28 | time:  2.02s | train accuracy    0.981 | valid accuracy    0.818 \n",
      "| end of epoch  29 | time:  2.00s | train accuracy    0.983 | valid accuracy    0.815 \n",
      "| end of epoch  30 | time:  2.01s | train accuracy    0.983 | valid accuracy    0.815 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.012 MB of 0.012 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_accuracy</td><td>▁▄▅▆▇▇▇▇▇▇████████████████████</td></tr><tr><td>valid_loss</td><td>█▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>train_accuracy</td><td>0.98347</td></tr><tr><td>train_loss</td><td>0.00213</td></tr><tr><td>valid_accuracy</td><td>0.81488</td></tr><tr><td>valid_loss</td><td>0.03751</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pious-snowflake-37</strong> at: <a href='https://wandb.ai/moguw/intent-recognition/runs/sknhoux1' target=\"_blank\">https://wandb.ai/moguw/intent-recognition/runs/sknhoux1</a><br/> View project at: <a href='https://wandb.ai/moguw/intent-recognition' target=\"_blank\">https://wandb.ai/moguw/intent-recognition</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240605_225324-sknhoux1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import jieba\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from argparse import Namespace\n",
    "import wandb\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def load_data(train_file, test_file):\n",
    "    train_data = pd.read_csv(train_file, sep='\\t', header=None)\n",
    "    test_data = pd.read_csv(test_file, sep='\\t', header=None)\n",
    "    train_data[1], lbl = pd.factorize(train_data[1])\n",
    "    return train_data, test_data, lbl\n",
    "\n",
    "class BILSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, label_size, dropout=0.5):\n",
    "        super(BILSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, bidirectional=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden2label = nn.Linear(hidden_dim*2, label_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        sentence = torch.transpose(sentence, 1, 0)\n",
    "        x = self.embeddings(sentence)\n",
    "        lstm_out, self.hidden = self.lstm(x)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        y = self.hidden2label(lstm_out[-1, :, :])\n",
    "        return y\n",
    "\n",
    "def custom_data_iter(texts, labels):\n",
    "    for x, y in zip(texts, labels):\n",
    "        yield x, y\n",
    "\n",
    "def yield_tokens(data_iter, tokenizer):\n",
    "    for text, _ in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "def collate_batch(batch, text_pipeline, device, max_len=20):\n",
    "    label_list, text_list = [], []\n",
    "    for (_text, _label) in batch:\n",
    "        label_list.append(_label)\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        processed_text = F.pad(processed_text, pad=[0, max_len], mode='constant', value=0)\n",
    "        if len(processed_text) > max_len:\n",
    "            processed_text = processed_text[:max_len]\n",
    "        text_list.append(processed_text)\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = pad_sequence(text_list).T\n",
    "    return label_list.to(device), text_list.to(device)\n",
    "\n",
    "def train(dataloader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    total_loss = 0.0\n",
    "    for idx, (label, text) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        total_loss += loss.item()\n",
    "    return total_acc / total_count, total_loss / total_count\n",
    "\n",
    "def evaluate(dataloader, model, criterion, device):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            predicted_label = model(text)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            total_loss += loss.item()\n",
    "    return total_acc / total_count, total_loss / total_count\n",
    "\n",
    "\n",
    "def predict(dataloader, model, lbl, device):\n",
    "    model.eval()\n",
    "    test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            predicted_label = model(text).argmax(1)\n",
    "            test_pred += list(predicted_label.cpu().numpy())\n",
    "    return [lbl[x] for x in test_pred]\n",
    "\n",
    "def run(args):\n",
    "    wandb.init(project=args.project_name, config=args)\n",
    "    \n",
    "    train_data, test_data, lbl = load_data(args.train_file, args.test_file)\n",
    "\n",
    "    train_iter = custom_data_iter(train_data[0].values[:], train_data[1].values[:])\n",
    "    tokenizer = jieba.lcut\n",
    "\n",
    "    vocab = build_vocab_from_iterator(yield_tokens(train_iter, tokenizer), specials=[\"<unk>\"])\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "    def text_pipeline(x): return vocab(tokenizer(x))\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    BATCH_SIZE = args.batch_size\n",
    "    EPOCHS = args.epochs\n",
    "    LR = args.learning_rate\n",
    "\n",
    "    num_class = len(lbl)\n",
    "    vocab_size = len(vocab)\n",
    "    model = BILSTM(vocab_size, args.embedding_size, 64, num_class).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 5.0, gamma=args.gamma)\n",
    "    total_accu = None\n",
    "    best_accu = 0\n",
    "\n",
    "    train_iter = custom_data_iter(train_data[0].values[:], train_data[1].values[:])\n",
    "    train_dataset = to_map_style_dataset(train_iter)\n",
    "    num_train = int(len(train_dataset) * args.split)\n",
    "    split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "    train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda x: collate_batch(x, text_pipeline, device))\n",
    "    valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda x: collate_batch(x, text_pipeline, device))\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train_acc, train_loss = train(train_dataloader, model, criterion, optimizer, device)\n",
    "        valid_acc, valid_loss = evaluate(valid_dataloader, model, criterion, device)\n",
    "        if total_accu is not None and total_accu > valid_acc:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            total_accu = valid_acc\n",
    "        if valid_acc > best_accu:\n",
    "            best_accu = valid_acc\n",
    "            torch.save(model.state_dict(), args.model_path)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | train accuracy {:8.3f} | valid accuracy {:8.3f} '.format(epoch, time.time() - epoch_start_time, train_acc, valid_acc))\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"valid_accuracy\": valid_acc,\n",
    "            \"valid_loss\": valid_loss\n",
    "        })\n",
    "\n",
    "    test_iter = custom_data_iter(test_data[0].values[:], [0] * len(test_data))\n",
    "    test_dataset = to_map_style_dataset(test_iter)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda x: collate_batch(x, text_pipeline, device))\n",
    "\n",
    "    test_pred = predict(test_dataloader, model, lbl, device)\n",
    "    pd.DataFrame({\n",
    "        'ID': range(1, len(test_pred) + 1),\n",
    "        'Target': test_pred,\n",
    "    }).to_csv('lstm.csv', index=None)\n",
    "    \n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "seed_everything(42)\n",
    "args = Namespace(\n",
    "    data_dir='https://mirror.coggle.club/dataset/coggle-competition/',\n",
    "    train_file = 'https://mirror.coggle.club/dataset/coggle-competition/intent-classify/train.csv',\n",
    "    test_file = 'https://mirror.coggle.club/dataset/coggle-competition/intent-classify/test.csv',\n",
    "    batch_size=32,\n",
    "    split=0.8,\n",
    "    embedding_size=100,\n",
    "    epochs=30,\n",
    "    learning_rate=1,\n",
    "    gamma=0.5,\n",
    "    model_path='BiLSTM.pth',\n",
    "    project_name='intent-recognition',\n",
    ")\n",
    "run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad5055-0dd0-4434-94c1-fe35a1e84cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "809d198a-684b-428b-9c20-4d588ccb6fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "         Travel-Query       0.97      0.96      0.96       243\n",
      "           Music-Play       0.94      0.95      0.94       273\n",
      "        FilmTele-Play       0.90      0.95      0.92       262\n",
      "           Video-Play       0.96      0.95      0.96       264\n",
      "         Radio-Listen       0.95      0.94      0.95       261\n",
      "HomeAppliance-Control       0.97      0.97      0.97       239\n",
      "        Weather-Query       0.95      0.97      0.96       256\n",
      "         Alarm-Update       0.96      0.97      0.96       238\n",
      "       Calendar-Query       0.99      0.99      0.99       245\n",
      "       TVProgram-Play       0.90      0.76      0.82        49\n",
      "           Audio-Play       0.88      0.84      0.86        43\n",
      "                Other       0.77      0.57      0.66        47\n",
      "\n",
      "             accuracy                           0.95      2420\n",
      "            macro avg       0.93      0.90      0.91      2420\n",
      "         weighted avg       0.95      0.95      0.95      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def generate_classification_report(model_path, valid_dataloader, model, lbl, device):\n",
    "    # 加载模型\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(valid_dataloader):\n",
    "            predicted_label = model(text).argmax(1)\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            all_preds.extend(predicted_label.cpu().numpy())\n",
    "\n",
    "    # 生成分类报告\n",
    "    report = classification_report(all_labels, all_preds, target_names=lbl)\n",
    "    print(report)\n",
    "\n",
    "# 设置参数\n",
    "model_path = 'BiLSTM.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载数据\n",
    "train_data, _, lbl = load_data(args.train_file, args.test_file)\n",
    "tokenizer = jieba.lcut\n",
    "vocab = build_vocab_from_iterator(yield_tokens(custom_data_iter(train_data[0].values[:], train_data[1].values[:]), tokenizer), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "def text_pipeline(x): return vocab(tokenizer(x))\n",
    "\n",
    "train_iter = custom_data_iter(train_data[0].values[:], train_data[1].values[:])\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "num_train = int(len(train_dataset) * args.split)\n",
    "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=args.batch_size, shuffle=True, collate_fn=lambda x: collate_batch(x, text_pipeline, device))\n",
    "\n",
    "# 定义模型\n",
    "num_class = len(lbl)\n",
    "vocab_size = len(vocab)\n",
    "model = BILSTM(vocab_size, args.embedding_size, 64, num_class)\n",
    "\n",
    "# 生成分类报告\n",
    "generate_classification_report(model_path, valid_dataloader, model, lbl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe216d-bd2f-4421-a4fb-765b5603100c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
