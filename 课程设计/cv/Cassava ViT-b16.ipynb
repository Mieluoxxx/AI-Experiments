{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf152d6",
   "metadata": {
    "papermill": {
     "duration": 10.666799,
     "end_time": "2024-06-05T07:43:39.581662",
     "exception": false,
     "start_time": "2024-06-05T07:43:28.914863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/miniconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'timm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'timm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import timm\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import model_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0acfc08",
   "metadata": {
    "papermill": {
     "duration": 0.019408,
     "end_time": "2024-06-05T07:43:39.607217",
     "exception": false,
     "start_time": "2024-06-05T07:43:39.587809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Seeds basic parameters for reproductibility of results\n",
    "    \n",
    "    Arguments:\n",
    "        seed {int} -- Number of the seed\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49a301",
   "metadata": {
    "papermill": {
     "duration": 0.013752,
     "end_time": "2024-06-05T07:43:39.627166",
     "exception": false,
     "start_time": "2024-06-05T07:43:39.613414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# general global variables\n",
    "DATA_PATH = \"data/\"\n",
    "TRAIN_PATH = \"data/train_images\"\n",
    "TEST_PATH = \"data/test_images/\"\n",
    "MODEL_PATH = (\n",
    "    \"data/jx_vit_base_p16_224-80ecf9dd.pth\"\n",
    ")\n",
    "BEST_MODEL = \"best_model.pth\"\n",
    "SUBMISSION_FILE = \"submission.csv\"\n",
    "\n",
    "# model specific global variables\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "LR = 2e-05\n",
    "N_EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f871b",
   "metadata": {
    "papermill": {
     "duration": 0.058676,
     "end_time": "2024-06-05T07:43:39.691470",
     "exception": false,
     "start_time": "2024-06-05T07:43:39.632794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c5867a",
   "metadata": {
    "papermill": {
     "duration": 0.042679,
     "end_time": "2024-06-05T07:43:39.740833",
     "exception": false,
     "start_time": "2024-06-05T07:43:39.698154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613443a",
   "metadata": {
    "papermill": {
     "duration": 0.289601,
     "end_time": "2024-06-05T07:43:40.037551",
     "exception": false,
     "start_time": "2024-06-05T07:43:39.747950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.label.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b546aba6",
   "metadata": {
    "papermill": {
     "duration": 0.030573,
     "end_time": "2024-06-05T07:43:40.075136",
     "exception": false,
     "start_time": "2024-06-05T07:43:40.044563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, valid_df = model_selection.train_test_split(\n",
    "    df, test_size=0.1, random_state=42, stratify=df.label.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9de08d",
   "metadata": {
    "papermill": {
     "duration": 0.017827,
     "end_time": "2024-06-05T07:43:40.099585",
     "exception": false,
     "start_time": "2024-06-05T07:43:40.081758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassavaDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Helper Class to create the pytorch dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, data_path=DATA_PATH, mode=\"train\", transforms=None):\n",
    "        super().__init__()\n",
    "        self.df_data = df.values\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        self.data_dir = \"train_images\" if mode == \"train\" else \"test_images\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name, label = self.df_data[index]\n",
    "        img_path = os.path.join(self.data_path, self.data_dir, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(img)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd0d241c",
   "metadata": {
    "papermill": {
     "duration": 0.017256,
     "end_time": "2024-06-05T07:43:40.123542",
     "exception": false,
     "start_time": "2024-06-05T07:43:40.106286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IMG_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create image augmentations\u001b[39;00m\n\u001b[1;32m      2\u001b[0m transforms_train \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose(\n\u001b[1;32m      3\u001b[0m     [\n\u001b[0;32m----> 4\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[43mIMG_SIZE\u001b[49m, IMG_SIZE)),\n\u001b[1;32m      5\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mRandomHorizontalFlip(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m),\n\u001b[1;32m      6\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mRandomVerticalFlip(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m),\n\u001b[1;32m      7\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mRandomResizedCrop(IMG_SIZE),\n\u001b[1;32m      8\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m      9\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m), (\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m)),\n\u001b[1;32m     10\u001b[0m     ]\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m transforms_valid \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose(\n\u001b[1;32m     14\u001b[0m     [\n\u001b[1;32m     15\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mResize((IMG_SIZE, IMG_SIZE)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     ]\n\u001b[1;32m     19\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IMG_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "# create image augmentations\n",
    "transforms_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(p=0.3),\n",
    "        transforms.RandomVerticalFlip(p=0.3),\n",
    "        transforms.RandomResizedCrop(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_valid = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539d54f3",
   "metadata": {
    "papermill": {
     "duration": 0.021032,
     "end_time": "2024-06-05T07:43:40.151408",
     "exception": false,
     "start_time": "2024-06-05T07:43:40.130376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Vision Transformer Models: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'timm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable Vision Transformer Models: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtimm\u001b[49m\u001b[38;5;241m.\u001b[39mlist_models(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvit*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timm' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Available Vision Transformer Models: \")\n",
    "timm.list_models(\"vit*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5032b48",
   "metadata": {
    "papermill": {
     "duration": 13.740139,
     "end_time": "2024-06-05T07:43:53.898796",
     "exception": false,
     "start_time": "2024-06-05T07:43:40.158657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "class ViTBase16(nn.Module):\n",
    "    def __init__(self, n_classes, pretrained=False):\n",
    "\n",
    "        super(ViTBase16, self).__init__()\n",
    "\n",
    "        self.model = timm.create_model(\"vit_base_patch16_224\", pretrained=False)\n",
    "        if pretrained:\n",
    "            self.model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def train_one_epoch(self, train_loader, criterion, optimizer, device, writer, epoch):\n",
    "        # keep track of training loss\n",
    "        epoch_loss = 0.0\n",
    "        epoch_accuracy = 0.0\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        self.model.train()\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if device.type == \"cuda\":\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = self.forward(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # Calculate Accuracy\n",
    "            accuracy = (output.argmax(dim=1) == target).float().mean()\n",
    "            # update training loss and accuracy\n",
    "            epoch_loss += loss\n",
    "            epoch_accuracy += accuracy\n",
    "            if i % 20 == 0:\n",
    "                print(f\"BATCH {i+1}/{len(train_loader)} - LOSS: {loss.item():.4f} - ACCURACY: {accuracy.item():.4f}\")\n",
    "                writer.add_scalar('Training Loss', loss.item(), epoch * len(train_loader) + i)\n",
    "                writer.add_scalar('Training Accuracy', accuracy.item(), epoch * len(train_loader) + i)\n",
    "            optimizer.step()\n",
    "\n",
    "        return epoch_loss / len(train_loader), epoch_accuracy / len(train_loader)\n",
    "\n",
    "    def valid_one_epoch(self, valid_loader, criterion, device, writer, epoch):\n",
    "        # keep track of validation loss\n",
    "        valid_loss = 0.0\n",
    "        valid_accuracy = 0.0\n",
    "\n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        self.model.eval()\n",
    "        for data, target in valid_loader:\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if device.type == \"cuda\":\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            elif device.type == \"xla\":\n",
    "                data = data.to(device, dtype=torch.float32)\n",
    "                target = target.to(device, dtype=torch.int64)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = self.model(data)\n",
    "                # calculate the batch loss\n",
    "                loss = criterion(output, target)\n",
    "                # Calculate Accuracy\n",
    "                accuracy = (output.argmax(dim=1) == target).float().mean()\n",
    "                # update average validation loss and accuracy\n",
    "                valid_loss += loss\n",
    "                valid_accuracy += accuracy\n",
    "\n",
    "        writer.add_scalar('Validation Loss', valid_loss / len(valid_loader), epoch)\n",
    "        writer.add_scalar('Validation Accuracy', valid_accuracy / len(valid_loader), epoch)\n",
    "\n",
    "        return valid_loss / len(valid_loader), valid_accuracy / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3123c00f",
   "metadata": {
    "papermill": {
     "duration": 0.023725,
     "end_time": "2024-06-05T07:43:53.930088",
     "exception": false,
     "start_time": "2024-06-05T07:43:53.906363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_gpu(model, epochs, device, criterion, optimizer, train_loader, valid_loader=None):\n",
    "    writer = SummaryWriter()\n",
    "    valid_loss_min = np.Inf\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "\n",
    "    for epoch in  range(1,epochs+1):  #调用数据和模型进行训练-Log\n",
    "        gc.collect()  #通过gc清理内存\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"EPOCH{epoch}-TRAINING...\")\n",
    "\n",
    "        train_loss,train_acc=model.train_one_epoch(train_loader,criterion,optimizer,device,writer,epoch)\n",
    "        print(f\"\\n\\t[TRAIN] EPOCH{epoch}-LOSS:{train_loss},ACCURACY:{train_acc}\\n\")\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        gc.collect()\n",
    "\n",
    "        #valid\n",
    "        if valid_loader is not None:\n",
    "            gc.collect()\n",
    "            print(f\"EPOCH{epoch}-VALIDATING...\")\n",
    "            valid_loss,valid_acc = model.valid_one_epoch(valid_loader,criterion,device,writer,epoch)\n",
    "            print(f\"\\t[VALID] LOSS:{valid_loss},ACCURACY:{valid_acc}\\n\")\n",
    "            valid_losses.append(valid_loss)\n",
    "            valid_accs.append(valid_acc)\n",
    "            gc.collect()\n",
    "            #save !!!\n",
    "            if valid_loss<=valid_loss_min and epoch!=1:\n",
    "                print(\"Validation loss decreased ({:.4f} -->{:.4f}). Saving model...\".format(valid_loss_min,valid_loss))\n",
    "                torch.save(model.state_dict(),'best_model.pth')\n",
    "                valid_loss_min=valid_loss\n",
    "    writer.close()\n",
    "    return {\n",
    "        \"train_loss\":train_losses,\n",
    "        \"valid_losses\":valid_losses,\n",
    "        \"train_acc\":train_accs,\n",
    "        \"valid_acces\":valid_accs,   \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6252fe58",
   "metadata": {
    "papermill": {
     "duration": 0.021986,
     "end_time": "2024-06-05T07:43:53.959627",
     "exception": false,
     "start_time": "2024-06-05T07:43:53.937641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "    train_df, valid_df = model_selection.train_test_split(df, test_size=0.1, random_state=42, shuffle=True,\n",
    "                                                         stratify=df.label.values)\n",
    "\n",
    "    train_dataset = CassavaDataset(train_df, transforms=transforms_train)\n",
    "    valid_dataset = CassavaDataset(valid_df, transforms=transforms_valid)\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        drop_last=True,\n",
    "        num_workers=4,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        drop_last=True,\n",
    "        num_workers=4,\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    lr = LR\n",
    "    model = ViTBase16(n_classes=5, pretrained=True)\n",
    "    model=model.cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    #开始训练前\n",
    "    start_time=datetime.now()\n",
    "    logs = fit_gpu(model=model,\n",
    "                       epochs=N_EPOCHS,\n",
    "                       device=device,\n",
    "                       criterion=criterion,\n",
    "                       optimizer=optimizer,\n",
    "                       train_loader=train_loader,\n",
    "                       valid_loader=valid_loader)\n",
    "\n",
    "    print(f\"Execution time:{datetime.now() - start_time}\")\n",
    "    torch.save(model.state_dict(),f'end_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb808a7b",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-05T07:43:53.976569Z",
     "iopub.status.busy": "2024-06-05T07:43:53.976174Z",
     "iopub.status.idle": "2024-06-05T10:22:01.323267Z",
     "shell.execute_reply": "2024-06-05T10:22:01.322358Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 9487.358447,
     "end_time": "2024-06-05T10:22:01.325751",
     "exception": false,
     "start_time": "2024-06-05T07:43:53.967304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /usr/local/src/pytorch/torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EPOCH1-TRAINING...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH 1/1203 - LOSS: 1.8193 - ACCURACY: 0.0625\n",
      "BATCH 21/1203 - LOSS: 1.3054 - ACCURACY: 0.5000\n",
      "BATCH 41/1203 - LOSS: 0.9094 - ACCURACY: 0.7500\n",
      "BATCH 61/1203 - LOSS: 0.8337 - ACCURACY: 0.7500\n",
      "BATCH 81/1203 - LOSS: 1.0646 - ACCURACY: 0.6250\n",
      "BATCH 101/1203 - LOSS: 0.1364 - ACCURACY: 1.0000\n",
      "BATCH 121/1203 - LOSS: 0.8386 - ACCURACY: 0.6875\n",
      "BATCH 141/1203 - LOSS: 0.8563 - ACCURACY: 0.6875\n",
      "BATCH 161/1203 - LOSS: 0.3236 - ACCURACY: 0.9375\n",
      "BATCH 181/1203 - LOSS: 0.5087 - ACCURACY: 0.8750\n",
      "BATCH 201/1203 - LOSS: 0.3864 - ACCURACY: 0.8750\n",
      "BATCH 221/1203 - LOSS: 0.3766 - ACCURACY: 0.9375\n",
      "BATCH 241/1203 - LOSS: 0.5496 - ACCURACY: 0.7500\n",
      "BATCH 261/1203 - LOSS: 0.1367 - ACCURACY: 1.0000\n",
      "BATCH 281/1203 - LOSS: 0.3159 - ACCURACY: 0.9375\n",
      "BATCH 301/1203 - LOSS: 0.4981 - ACCURACY: 0.8125\n",
      "BATCH 321/1203 - LOSS: 0.5650 - ACCURACY: 0.7500\n",
      "BATCH 341/1203 - LOSS: 0.7562 - ACCURACY: 0.6250\n",
      "BATCH 361/1203 - LOSS: 0.7313 - ACCURACY: 0.6875\n",
      "BATCH 381/1203 - LOSS: 0.3227 - ACCURACY: 0.8750\n",
      "BATCH 401/1203 - LOSS: 0.4200 - ACCURACY: 0.8125\n",
      "BATCH 421/1203 - LOSS: 0.8893 - ACCURACY: 0.6250\n",
      "BATCH 441/1203 - LOSS: 0.5188 - ACCURACY: 0.8125\n",
      "BATCH 461/1203 - LOSS: 0.4724 - ACCURACY: 0.8125\n",
      "BATCH 481/1203 - LOSS: 0.8729 - ACCURACY: 0.6875\n",
      "BATCH 501/1203 - LOSS: 0.2982 - ACCURACY: 0.9375\n",
      "BATCH 521/1203 - LOSS: 0.5036 - ACCURACY: 0.8125\n",
      "BATCH 541/1203 - LOSS: 0.2505 - ACCURACY: 0.9375\n",
      "BATCH 561/1203 - LOSS: 0.7733 - ACCURACY: 0.8125\n",
      "BATCH 581/1203 - LOSS: 0.3799 - ACCURACY: 0.8750\n",
      "BATCH 601/1203 - LOSS: 0.3322 - ACCURACY: 0.8125\n",
      "BATCH 621/1203 - LOSS: 0.3715 - ACCURACY: 0.8125\n",
      "BATCH 641/1203 - LOSS: 0.1664 - ACCURACY: 0.9375\n",
      "BATCH 661/1203 - LOSS: 0.5048 - ACCURACY: 0.8125\n",
      "BATCH 681/1203 - LOSS: 0.3609 - ACCURACY: 0.8750\n",
      "BATCH 701/1203 - LOSS: 0.3213 - ACCURACY: 0.9375\n",
      "BATCH 721/1203 - LOSS: 0.4613 - ACCURACY: 0.8750\n",
      "BATCH 741/1203 - LOSS: 0.3759 - ACCURACY: 0.8750\n",
      "BATCH 761/1203 - LOSS: 0.5686 - ACCURACY: 0.6875\n",
      "BATCH 781/1203 - LOSS: 0.4938 - ACCURACY: 0.7500\n",
      "BATCH 801/1203 - LOSS: 0.2975 - ACCURACY: 0.8750\n",
      "BATCH 821/1203 - LOSS: 0.2716 - ACCURACY: 0.9375\n",
      "BATCH 841/1203 - LOSS: 0.2849 - ACCURACY: 0.8750\n",
      "BATCH 861/1203 - LOSS: 0.2844 - ACCURACY: 0.8750\n",
      "BATCH 881/1203 - LOSS: 0.5157 - ACCURACY: 0.7500\n",
      "BATCH 901/1203 - LOSS: 0.2026 - ACCURACY: 0.9375\n",
      "BATCH 921/1203 - LOSS: 0.3731 - ACCURACY: 0.8750\n",
      "BATCH 941/1203 - LOSS: 0.3182 - ACCURACY: 0.9375\n",
      "BATCH 961/1203 - LOSS: 0.2118 - ACCURACY: 0.9375\n",
      "BATCH 981/1203 - LOSS: 0.2156 - ACCURACY: 0.9375\n",
      "BATCH 1001/1203 - LOSS: 0.2155 - ACCURACY: 0.9375\n",
      "BATCH 1021/1203 - LOSS: 0.5085 - ACCURACY: 0.8750\n",
      "BATCH 1041/1203 - LOSS: 0.4846 - ACCURACY: 0.8125\n",
      "BATCH 1061/1203 - LOSS: 0.2020 - ACCURACY: 0.9375\n",
      "BATCH 1081/1203 - LOSS: 0.3702 - ACCURACY: 0.9375\n",
      "BATCH 1101/1203 - LOSS: 0.3014 - ACCURACY: 0.9375\n",
      "BATCH 1121/1203 - LOSS: 0.1972 - ACCURACY: 0.9375\n",
      "BATCH 1141/1203 - LOSS: 0.5891 - ACCURACY: 0.7500\n",
      "BATCH 1161/1203 - LOSS: 0.3278 - ACCURACY: 0.8750\n",
      "BATCH 1181/1203 - LOSS: 0.5466 - ACCURACY: 0.7500\n",
      "BATCH 1201/1203 - LOSS: 0.1578 - ACCURACY: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[TRAIN] EPOCH1-LOSS:0.5469805002212524,ACCURACY:0.8035640120506287\n",
      "\n",
      "EPOCH1-VALIDATING...\n",
      "\t[VALID] LOSS:0.4581235945224762,ACCURACY:0.839755654335022\n",
      "\n",
      "==================================================\n",
      "EPOCH2-TRAINING...\n",
      "BATCH 1/1203 - LOSS: 0.6616 - ACCURACY: 0.8125\n",
      "BATCH 21/1203 - LOSS: 0.3524 - ACCURACY: 0.8125\n",
      "BATCH 41/1203 - LOSS: 0.3123 - ACCURACY: 0.9375\n",
      "BATCH 61/1203 - LOSS: 0.5750 - ACCURACY: 0.8750\n",
      "BATCH 81/1203 - LOSS: 0.7110 - ACCURACY: 0.7500\n",
      "BATCH 101/1203 - LOSS: 0.0689 - ACCURACY: 1.0000\n",
      "BATCH 121/1203 - LOSS: 0.3668 - ACCURACY: 0.8750\n",
      "BATCH 141/1203 - LOSS: 0.2109 - ACCURACY: 1.0000\n",
      "BATCH 161/1203 - LOSS: 0.2881 - ACCURACY: 0.8750\n",
      "BATCH 181/1203 - LOSS: 0.3422 - ACCURACY: 0.8125\n",
      "BATCH 201/1203 - LOSS: 0.3515 - ACCURACY: 0.8750\n",
      "BATCH 221/1203 - LOSS: 0.3031 - ACCURACY: 0.9375\n",
      "BATCH 241/1203 - LOSS: 0.2989 - ACCURACY: 0.8750\n",
      "BATCH 261/1203 - LOSS: 0.0657 - ACCURACY: 1.0000\n",
      "BATCH 281/1203 - LOSS: 0.2707 - ACCURACY: 0.9375\n",
      "BATCH 301/1203 - LOSS: 0.6967 - ACCURACY: 0.7500\n",
      "BATCH 321/1203 - LOSS: 0.2955 - ACCURACY: 0.8750\n",
      "BATCH 341/1203 - LOSS: 0.6026 - ACCURACY: 0.7500\n",
      "BATCH 361/1203 - LOSS: 0.5372 - ACCURACY: 0.8750\n",
      "BATCH 381/1203 - LOSS: 0.4405 - ACCURACY: 0.8125\n",
      "BATCH 401/1203 - LOSS: 0.1961 - ACCURACY: 0.9375\n",
      "BATCH 421/1203 - LOSS: 0.9243 - ACCURACY: 0.7500\n",
      "BATCH 441/1203 - LOSS: 0.2146 - ACCURACY: 0.9375\n",
      "BATCH 461/1203 - LOSS: 0.6635 - ACCURACY: 0.7500\n",
      "BATCH 481/1203 - LOSS: 0.5852 - ACCURACY: 0.8125\n",
      "BATCH 501/1203 - LOSS: 0.1752 - ACCURACY: 0.9375\n",
      "BATCH 521/1203 - LOSS: 0.4659 - ACCURACY: 0.8750\n",
      "BATCH 541/1203 - LOSS: 0.2021 - ACCURACY: 0.9375\n",
      "BATCH 561/1203 - LOSS: 0.5040 - ACCURACY: 0.8125\n",
      "BATCH 581/1203 - LOSS: 0.4524 - ACCURACY: 0.8125\n",
      "BATCH 601/1203 - LOSS: 0.2809 - ACCURACY: 0.8750\n",
      "BATCH 621/1203 - LOSS: 0.2447 - ACCURACY: 0.8750\n",
      "BATCH 641/1203 - LOSS: 0.4936 - ACCURACY: 0.8750\n",
      "BATCH 661/1203 - LOSS: 0.3700 - ACCURACY: 0.9375\n",
      "BATCH 681/1203 - LOSS: 0.2194 - ACCURACY: 0.9375\n",
      "BATCH 701/1203 - LOSS: 0.1316 - ACCURACY: 1.0000\n",
      "BATCH 721/1203 - LOSS: 0.3911 - ACCURACY: 0.8750\n",
      "BATCH 741/1203 - LOSS: 0.4520 - ACCURACY: 0.8125\n",
      "BATCH 761/1203 - LOSS: 0.3116 - ACCURACY: 0.8750\n",
      "BATCH 781/1203 - LOSS: 0.3542 - ACCURACY: 0.8750\n",
      "BATCH 801/1203 - LOSS: 0.2783 - ACCURACY: 0.8125\n",
      "BATCH 821/1203 - LOSS: 0.4035 - ACCURACY: 0.8750\n",
      "BATCH 841/1203 - LOSS: 0.2914 - ACCURACY: 0.9375\n",
      "BATCH 861/1203 - LOSS: 0.1685 - ACCURACY: 1.0000\n",
      "BATCH 881/1203 - LOSS: 0.2819 - ACCURACY: 0.8750\n",
      "BATCH 901/1203 - LOSS: 0.2148 - ACCURACY: 0.9375\n",
      "BATCH 921/1203 - LOSS: 0.3110 - ACCURACY: 0.9375\n",
      "BATCH 941/1203 - LOSS: 0.3994 - ACCURACY: 0.8750\n",
      "BATCH 961/1203 - LOSS: 0.0857 - ACCURACY: 1.0000\n",
      "BATCH 981/1203 - LOSS: 0.2105 - ACCURACY: 0.9375\n",
      "BATCH 1001/1203 - LOSS: 0.4089 - ACCURACY: 0.8750\n",
      "BATCH 1021/1203 - LOSS: 0.5011 - ACCURACY: 0.8125\n",
      "BATCH 1041/1203 - LOSS: 0.4836 - ACCURACY: 0.8750\n",
      "BATCH 1061/1203 - LOSS: 0.0605 - ACCURACY: 1.0000\n",
      "BATCH 1081/1203 - LOSS: 0.3120 - ACCURACY: 0.8750\n",
      "BATCH 1101/1203 - LOSS: 0.2450 - ACCURACY: 0.9375\n",
      "BATCH 1121/1203 - LOSS: 0.1727 - ACCURACY: 1.0000\n",
      "BATCH 1141/1203 - LOSS: 0.5884 - ACCURACY: 0.8125\n",
      "BATCH 1161/1203 - LOSS: 0.2333 - ACCURACY: 0.9375\n",
      "BATCH 1181/1203 - LOSS: 0.1899 - ACCURACY: 0.9375\n",
      "BATCH 1201/1203 - LOSS: 0.1366 - ACCURACY: 0.9375\n",
      "\n",
      "\t[TRAIN] EPOCH2-LOSS:0.4159616529941559,ACCURACY:0.8563487529754639\n",
      "\n",
      "EPOCH2-VALIDATING...\n",
      "\t[VALID] LOSS:0.436762273311615,ACCURACY:0.8416353464126587\n",
      "\n",
      "Validation loss decreased (inf -->0.4368). Saving model...\n",
      "==================================================\n",
      "EPOCH3-TRAINING...\n",
      "BATCH 1/1203 - LOSS: 0.2996 - ACCURACY: 0.8750\n",
      "BATCH 21/1203 - LOSS: 0.4364 - ACCURACY: 0.8750\n",
      "BATCH 41/1203 - LOSS: 0.5040 - ACCURACY: 0.8750\n",
      "BATCH 61/1203 - LOSS: 0.5652 - ACCURACY: 0.8125\n",
      "BATCH 81/1203 - LOSS: 0.5074 - ACCURACY: 0.7500\n",
      "BATCH 101/1203 - LOSS: 0.0637 - ACCURACY: 1.0000\n",
      "BATCH 121/1203 - LOSS: 0.2520 - ACCURACY: 0.9375\n",
      "BATCH 141/1203 - LOSS: 0.4167 - ACCURACY: 0.8750\n",
      "BATCH 161/1203 - LOSS: 0.2013 - ACCURACY: 0.9375\n",
      "BATCH 181/1203 - LOSS: 0.2831 - ACCURACY: 0.8750\n",
      "BATCH 201/1203 - LOSS: 0.4056 - ACCURACY: 0.8125\n",
      "BATCH 221/1203 - LOSS: 0.2082 - ACCURACY: 0.8750\n",
      "BATCH 241/1203 - LOSS: 0.1766 - ACCURACY: 0.9375\n",
      "BATCH 261/1203 - LOSS: 0.1825 - ACCURACY: 0.9375\n",
      "BATCH 281/1203 - LOSS: 0.2555 - ACCURACY: 0.9375\n",
      "BATCH 301/1203 - LOSS: 0.6962 - ACCURACY: 0.6875\n",
      "BATCH 321/1203 - LOSS: 0.1993 - ACCURACY: 0.9375\n",
      "BATCH 341/1203 - LOSS: 0.9286 - ACCURACY: 0.6875\n",
      "BATCH 361/1203 - LOSS: 0.4411 - ACCURACY: 0.8125\n",
      "BATCH 381/1203 - LOSS: 0.3216 - ACCURACY: 0.9375\n",
      "BATCH 401/1203 - LOSS: 0.2728 - ACCURACY: 0.9375\n",
      "BATCH 421/1203 - LOSS: 0.2881 - ACCURACY: 0.9375\n",
      "BATCH 441/1203 - LOSS: 0.4662 - ACCURACY: 0.8125\n",
      "BATCH 461/1203 - LOSS: 0.7197 - ACCURACY: 0.7500\n",
      "BATCH 481/1203 - LOSS: 0.8816 - ACCURACY: 0.6875\n",
      "BATCH 501/1203 - LOSS: 0.2326 - ACCURACY: 0.8750\n",
      "BATCH 521/1203 - LOSS: 0.3592 - ACCURACY: 0.8750\n",
      "BATCH 541/1203 - LOSS: 0.2195 - ACCURACY: 0.8750\n",
      "BATCH 561/1203 - LOSS: 0.3230 - ACCURACY: 0.8750\n",
      "BATCH 581/1203 - LOSS: 0.3657 - ACCURACY: 0.8750\n",
      "BATCH 601/1203 - LOSS: 0.2569 - ACCURACY: 0.8750\n",
      "BATCH 621/1203 - LOSS: 0.3646 - ACCURACY: 0.9375\n",
      "BATCH 641/1203 - LOSS: 0.3798 - ACCURACY: 0.8750\n",
      "BATCH 661/1203 - LOSS: 0.3628 - ACCURACY: 0.8125\n",
      "BATCH 681/1203 - LOSS: 0.4044 - ACCURACY: 0.8750\n",
      "BATCH 701/1203 - LOSS: 0.1564 - ACCURACY: 1.0000\n",
      "BATCH 721/1203 - LOSS: 0.2437 - ACCURACY: 0.9375\n",
      "BATCH 741/1203 - LOSS: 0.2940 - ACCURACY: 0.9375\n",
      "BATCH 761/1203 - LOSS: 0.3299 - ACCURACY: 0.9375\n",
      "BATCH 781/1203 - LOSS: 0.1662 - ACCURACY: 1.0000\n",
      "BATCH 801/1203 - LOSS: 0.1508 - ACCURACY: 1.0000\n",
      "BATCH 821/1203 - LOSS: 0.5096 - ACCURACY: 0.8125\n",
      "BATCH 841/1203 - LOSS: 0.2538 - ACCURACY: 0.8750\n",
      "BATCH 861/1203 - LOSS: 0.1411 - ACCURACY: 1.0000\n",
      "BATCH 881/1203 - LOSS: 0.2805 - ACCURACY: 0.8750\n",
      "BATCH 901/1203 - LOSS: 0.2689 - ACCURACY: 0.9375\n",
      "BATCH 921/1203 - LOSS: 0.2511 - ACCURACY: 0.8750\n",
      "BATCH 941/1203 - LOSS: 0.4294 - ACCURACY: 0.8125\n",
      "BATCH 961/1203 - LOSS: 0.1165 - ACCURACY: 1.0000\n",
      "BATCH 981/1203 - LOSS: 0.1217 - ACCURACY: 0.9375\n",
      "BATCH 1001/1203 - LOSS: 0.3012 - ACCURACY: 0.8750\n",
      "BATCH 1021/1203 - LOSS: 0.3785 - ACCURACY: 0.8750\n",
      "BATCH 1041/1203 - LOSS: 0.3905 - ACCURACY: 0.8750\n",
      "BATCH 1061/1203 - LOSS: 0.1406 - ACCURACY: 0.9375\n",
      "BATCH 1081/1203 - LOSS: 0.2782 - ACCURACY: 0.9375\n",
      "BATCH 1101/1203 - LOSS: 0.3113 - ACCURACY: 0.8750\n",
      "BATCH 1121/1203 - LOSS: 0.0949 - ACCURACY: 1.0000\n",
      "BATCH 1141/1203 - LOSS: 0.5711 - ACCURACY: 0.6875\n",
      "BATCH 1161/1203 - LOSS: 0.0724 - ACCURACY: 1.0000\n",
      "BATCH 1181/1203 - LOSS: 0.4797 - ACCURACY: 0.8750\n",
      "BATCH 1201/1203 - LOSS: 0.2044 - ACCURACY: 0.8750\n",
      "\n",
      "\t[TRAIN] EPOCH3-LOSS:0.38367751240730286,ACCURACY:0.8662198781967163\n",
      "\n",
      "EPOCH3-VALIDATING...\n",
      "\t[VALID] LOSS:0.45163530111312866,ACCURACY:0.842575192451477\n",
      "\n",
      "==================================================\n",
      "EPOCH4-TRAINING...\n",
      "BATCH 1/1203 - LOSS: 0.7250 - ACCURACY: 0.7500\n",
      "BATCH 21/1203 - LOSS: 0.4810 - ACCURACY: 0.8125\n",
      "BATCH 41/1203 - LOSS: 0.4973 - ACCURACY: 0.7500\n",
      "BATCH 61/1203 - LOSS: 0.3439 - ACCURACY: 0.8125\n",
      "BATCH 81/1203 - LOSS: 0.5001 - ACCURACY: 0.8125\n",
      "BATCH 101/1203 - LOSS: 0.0531 - ACCURACY: 1.0000\n",
      "BATCH 121/1203 - LOSS: 0.2307 - ACCURACY: 0.9375\n",
      "BATCH 141/1203 - LOSS: 0.2285 - ACCURACY: 0.9375\n",
      "BATCH 161/1203 - LOSS: 0.1696 - ACCURACY: 1.0000\n",
      "BATCH 181/1203 - LOSS: 0.2637 - ACCURACY: 0.8750\n",
      "BATCH 201/1203 - LOSS: 0.6271 - ACCURACY: 0.7500\n",
      "BATCH 221/1203 - LOSS: 0.1221 - ACCURACY: 1.0000\n",
      "BATCH 241/1203 - LOSS: 0.2587 - ACCURACY: 0.9375\n",
      "BATCH 261/1203 - LOSS: 0.2798 - ACCURACY: 0.9375\n",
      "BATCH 281/1203 - LOSS: 0.1464 - ACCURACY: 0.9375\n",
      "BATCH 301/1203 - LOSS: 0.4911 - ACCURACY: 0.8750\n",
      "BATCH 321/1203 - LOSS: 0.1462 - ACCURACY: 1.0000\n",
      "BATCH 341/1203 - LOSS: 0.5224 - ACCURACY: 0.7500\n",
      "BATCH 361/1203 - LOSS: 0.7478 - ACCURACY: 0.7500\n",
      "BATCH 381/1203 - LOSS: 0.2019 - ACCURACY: 0.9375\n",
      "BATCH 401/1203 - LOSS: 0.1852 - ACCURACY: 1.0000\n",
      "BATCH 421/1203 - LOSS: 0.4576 - ACCURACY: 0.8750\n",
      "BATCH 441/1203 - LOSS: 0.2732 - ACCURACY: 0.8750\n",
      "BATCH 461/1203 - LOSS: 0.6838 - ACCURACY: 0.8125\n",
      "BATCH 481/1203 - LOSS: 0.5783 - ACCURACY: 0.8125\n",
      "BATCH 501/1203 - LOSS: 0.0647 - ACCURACY: 1.0000\n",
      "BATCH 521/1203 - LOSS: 0.2125 - ACCURACY: 0.9375\n",
      "BATCH 541/1203 - LOSS: 0.1953 - ACCURACY: 1.0000\n",
      "BATCH 561/1203 - LOSS: 0.3926 - ACCURACY: 0.8750\n",
      "BATCH 581/1203 - LOSS: 0.5683 - ACCURACY: 0.8125\n",
      "BATCH 601/1203 - LOSS: 0.2142 - ACCURACY: 0.9375\n",
      "BATCH 621/1203 - LOSS: 0.2995 - ACCURACY: 0.9375\n",
      "BATCH 641/1203 - LOSS: 0.3544 - ACCURACY: 0.9375\n",
      "BATCH 661/1203 - LOSS: 0.2197 - ACCURACY: 0.9375\n",
      "BATCH 681/1203 - LOSS: 0.1586 - ACCURACY: 0.9375\n",
      "BATCH 701/1203 - LOSS: 0.0874 - ACCURACY: 1.0000\n",
      "BATCH 721/1203 - LOSS: 0.3866 - ACCURACY: 0.8750\n",
      "BATCH 741/1203 - LOSS: 0.2255 - ACCURACY: 0.9375\n",
      "BATCH 761/1203 - LOSS: 0.6516 - ACCURACY: 0.8125\n",
      "BATCH 781/1203 - LOSS: 0.2651 - ACCURACY: 0.8750\n",
      "BATCH 801/1203 - LOSS: 0.1461 - ACCURACY: 1.0000\n",
      "BATCH 821/1203 - LOSS: 0.3637 - ACCURACY: 0.8750\n",
      "BATCH 841/1203 - LOSS: 0.2829 - ACCURACY: 0.8750\n",
      "BATCH 861/1203 - LOSS: 0.3006 - ACCURACY: 0.8750\n",
      "BATCH 881/1203 - LOSS: 0.1222 - ACCURACY: 1.0000\n",
      "BATCH 901/1203 - LOSS: 0.1501 - ACCURACY: 0.9375\n",
      "BATCH 921/1203 - LOSS: 0.2677 - ACCURACY: 0.8750\n",
      "BATCH 941/1203 - LOSS: 0.3622 - ACCURACY: 0.8750\n",
      "BATCH 961/1203 - LOSS: 0.1066 - ACCURACY: 1.0000\n",
      "BATCH 981/1203 - LOSS: 0.1861 - ACCURACY: 0.9375\n",
      "BATCH 1001/1203 - LOSS: 0.1952 - ACCURACY: 0.9375\n",
      "BATCH 1021/1203 - LOSS: 0.3472 - ACCURACY: 0.8750\n",
      "BATCH 1041/1203 - LOSS: 0.2793 - ACCURACY: 0.8750\n",
      "BATCH 1061/1203 - LOSS: 0.0593 - ACCURACY: 1.0000\n",
      "BATCH 1081/1203 - LOSS: 0.1378 - ACCURACY: 0.8750\n",
      "BATCH 1101/1203 - LOSS: 0.3259 - ACCURACY: 0.8750\n",
      "BATCH 1121/1203 - LOSS: 0.0868 - ACCURACY: 1.0000\n",
      "BATCH 1141/1203 - LOSS: 0.5518 - ACCURACY: 0.8125\n",
      "BATCH 1161/1203 - LOSS: 0.1237 - ACCURACY: 0.9375\n",
      "BATCH 1181/1203 - LOSS: 0.6530 - ACCURACY: 0.7500\n",
      "BATCH 1201/1203 - LOSS: 0.1440 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH4-LOSS:0.3519972562789917,ACCURACY:0.8778055310249329\n",
      "\n",
      "EPOCH4-VALIDATING...\n",
      "\t[VALID] LOSS:0.4357466995716095,ACCURACY:0.8486842513084412\n",
      "\n",
      "Validation loss decreased (0.4368 -->0.4357). Saving model...\n",
      "==================================================\n",
      "EPOCH5-TRAINING...\n",
      "BATCH 1/1203 - LOSS: 0.2549 - ACCURACY: 0.9375\n",
      "BATCH 21/1203 - LOSS: 0.2743 - ACCURACY: 0.9375\n",
      "BATCH 41/1203 - LOSS: 0.2370 - ACCURACY: 0.8750\n",
      "BATCH 61/1203 - LOSS: 0.3417 - ACCURACY: 0.9375\n",
      "BATCH 81/1203 - LOSS: 0.7054 - ACCURACY: 0.7500\n",
      "BATCH 101/1203 - LOSS: 0.0901 - ACCURACY: 0.9375\n",
      "BATCH 121/1203 - LOSS: 0.1505 - ACCURACY: 0.9375\n",
      "BATCH 141/1203 - LOSS: 0.3314 - ACCURACY: 0.8125\n",
      "BATCH 161/1203 - LOSS: 0.1992 - ACCURACY: 0.9375\n",
      "BATCH 181/1203 - LOSS: 0.2129 - ACCURACY: 1.0000\n",
      "BATCH 201/1203 - LOSS: 0.4902 - ACCURACY: 0.8125\n",
      "BATCH 221/1203 - LOSS: 0.2115 - ACCURACY: 0.9375\n",
      "BATCH 241/1203 - LOSS: 0.2604 - ACCURACY: 0.9375\n",
      "BATCH 261/1203 - LOSS: 0.0602 - ACCURACY: 1.0000\n",
      "BATCH 281/1203 - LOSS: 0.2662 - ACCURACY: 0.9375\n",
      "BATCH 301/1203 - LOSS: 0.5969 - ACCURACY: 0.7500\n",
      "BATCH 321/1203 - LOSS: 0.0672 - ACCURACY: 1.0000\n",
      "BATCH 341/1203 - LOSS: 0.5718 - ACCURACY: 0.7500\n",
      "BATCH 361/1203 - LOSS: 0.2743 - ACCURACY: 0.8750\n",
      "BATCH 381/1203 - LOSS: 0.2263 - ACCURACY: 0.8750\n",
      "BATCH 401/1203 - LOSS: 0.3045 - ACCURACY: 0.8750\n",
      "BATCH 421/1203 - LOSS: 0.6709 - ACCURACY: 0.8125\n",
      "BATCH 441/1203 - LOSS: 0.2669 - ACCURACY: 0.8125\n",
      "BATCH 461/1203 - LOSS: 0.6903 - ACCURACY: 0.6875\n",
      "BATCH 481/1203 - LOSS: 0.3136 - ACCURACY: 0.8750\n",
      "BATCH 501/1203 - LOSS: 0.1750 - ACCURACY: 0.9375\n",
      "BATCH 521/1203 - LOSS: 0.1833 - ACCURACY: 0.9375\n",
      "BATCH 541/1203 - LOSS: 0.3667 - ACCURACY: 0.8750\n",
      "BATCH 561/1203 - LOSS: 0.4063 - ACCURACY: 0.8125\n",
      "BATCH 581/1203 - LOSS: 0.5909 - ACCURACY: 0.8125\n",
      "BATCH 601/1203 - LOSS: 0.2300 - ACCURACY: 0.8750\n",
      "BATCH 621/1203 - LOSS: 0.2335 - ACCURACY: 0.9375\n",
      "BATCH 641/1203 - LOSS: 0.2157 - ACCURACY: 0.9375\n",
      "BATCH 661/1203 - LOSS: 0.1862 - ACCURACY: 0.9375\n",
      "BATCH 681/1203 - LOSS: 0.2642 - ACCURACY: 0.8750\n",
      "BATCH 701/1203 - LOSS: 0.1214 - ACCURACY: 1.0000\n",
      "BATCH 721/1203 - LOSS: 0.2818 - ACCURACY: 0.8125\n",
      "BATCH 741/1203 - LOSS: 0.3550 - ACCURACY: 0.8750\n",
      "BATCH 761/1203 - LOSS: 0.3773 - ACCURACY: 0.8750\n",
      "BATCH 781/1203 - LOSS: 0.2740 - ACCURACY: 0.9375\n",
      "BATCH 801/1203 - LOSS: 0.1676 - ACCURACY: 1.0000\n",
      "BATCH 821/1203 - LOSS: 0.4741 - ACCURACY: 0.8125\n",
      "BATCH 841/1203 - LOSS: 0.2179 - ACCURACY: 0.9375\n",
      "BATCH 861/1203 - LOSS: 0.2389 - ACCURACY: 0.8750\n",
      "BATCH 881/1203 - LOSS: 0.2096 - ACCURACY: 0.8750\n",
      "BATCH 901/1203 - LOSS: 0.2417 - ACCURACY: 0.8750\n",
      "BATCH 921/1203 - LOSS: 0.0209 - ACCURACY: 1.0000\n",
      "BATCH 941/1203 - LOSS: 0.2442 - ACCURACY: 0.9375\n",
      "BATCH 961/1203 - LOSS: 0.0794 - ACCURACY: 1.0000\n",
      "BATCH 981/1203 - LOSS: 0.1721 - ACCURACY: 0.9375\n",
      "BATCH 1001/1203 - LOSS: 0.3066 - ACCURACY: 0.9375\n",
      "BATCH 1021/1203 - LOSS: 0.5147 - ACCURACY: 0.8750\n",
      "BATCH 1041/1203 - LOSS: 0.3520 - ACCURACY: 0.8750\n",
      "BATCH 1061/1203 - LOSS: 0.0346 - ACCURACY: 1.0000\n",
      "BATCH 1081/1203 - LOSS: 0.1870 - ACCURACY: 0.8750\n",
      "BATCH 1101/1203 - LOSS: 0.3320 - ACCURACY: 0.8750\n",
      "BATCH 1121/1203 - LOSS: 0.0642 - ACCURACY: 1.0000\n",
      "BATCH 1141/1203 - LOSS: 0.4029 - ACCURACY: 0.8750\n",
      "BATCH 1161/1203 - LOSS: 0.4266 - ACCURACY: 0.9375\n",
      "BATCH 1181/1203 - LOSS: 0.1715 - ACCURACY: 0.9375\n",
      "BATCH 1201/1203 - LOSS: 0.1226 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH5-LOSS:0.3258112967014313,ACCURACY:0.8839360475540161\n",
      "\n",
      "EPOCH5-VALIDATING...\n",
      "\t[VALID] LOSS:0.4204906225204468,ACCURACY:0.8524436354637146\n",
      "\n",
      "Validation loss decreased (0.4357 -->0.4205). Saving model...\n",
      "==================================================\n",
      "EPOCH6-TRAINING...\n",
      "BATCH 1/1203 - LOSS: 0.2143 - ACCURACY: 0.8750\n",
      "BATCH 21/1203 - LOSS: 0.3844 - ACCURACY: 0.8125\n",
      "BATCH 41/1203 - LOSS: 0.4267 - ACCURACY: 0.9375\n",
      "BATCH 61/1203 - LOSS: 0.1892 - ACCURACY: 0.8750\n",
      "BATCH 81/1203 - LOSS: 0.6106 - ACCURACY: 0.8125\n",
      "BATCH 101/1203 - LOSS: 0.0135 - ACCURACY: 1.0000\n",
      "BATCH 121/1203 - LOSS: 0.3807 - ACCURACY: 0.8125\n",
      "BATCH 141/1203 - LOSS: 0.3816 - ACCURACY: 0.8125\n",
      "BATCH 161/1203 - LOSS: 0.1230 - ACCURACY: 0.9375\n",
      "BATCH 181/1203 - LOSS: 0.3683 - ACCURACY: 0.9375\n",
      "BATCH 201/1203 - LOSS: 0.3091 - ACCURACY: 0.8750\n",
      "BATCH 221/1203 - LOSS: 0.1134 - ACCURACY: 1.0000\n",
      "BATCH 241/1203 - LOSS: 0.2057 - ACCURACY: 0.9375\n",
      "BATCH 261/1203 - LOSS: 0.0598 - ACCURACY: 1.0000\n",
      "BATCH 281/1203 - LOSS: 0.2151 - ACCURACY: 0.9375\n",
      "BATCH 301/1203 - LOSS: 0.6417 - ACCURACY: 0.7500\n",
      "BATCH 321/1203 - LOSS: 0.1029 - ACCURACY: 1.0000\n",
      "BATCH 341/1203 - LOSS: 0.3423 - ACCURACY: 0.8750\n",
      "BATCH 361/1203 - LOSS: 0.3051 - ACCURACY: 0.9375\n",
      "BATCH 381/1203 - LOSS: 0.2017 - ACCURACY: 1.0000\n",
      "BATCH 401/1203 - LOSS: 0.1204 - ACCURACY: 1.0000\n",
      "BATCH 421/1203 - LOSS: 0.7195 - ACCURACY: 0.6875\n",
      "BATCH 441/1203 - LOSS: 0.1186 - ACCURACY: 0.9375\n",
      "BATCH 461/1203 - LOSS: 0.4346 - ACCURACY: 0.7500\n",
      "BATCH 481/1203 - LOSS: 0.2983 - ACCURACY: 0.8750\n",
      "BATCH 501/1203 - LOSS: 0.1029 - ACCURACY: 0.9375\n",
      "BATCH 521/1203 - LOSS: 0.3069 - ACCURACY: 0.8750\n",
      "BATCH 541/1203 - LOSS: 0.2006 - ACCURACY: 0.9375\n",
      "BATCH 561/1203 - LOSS: 0.2354 - ACCURACY: 0.9375\n",
      "BATCH 581/1203 - LOSS: 0.4352 - ACCURACY: 0.8125\n",
      "BATCH 601/1203 - LOSS: 0.3557 - ACCURACY: 0.8750\n",
      "BATCH 621/1203 - LOSS: 0.1154 - ACCURACY: 0.9375\n",
      "BATCH 641/1203 - LOSS: 0.2578 - ACCURACY: 0.8750\n",
      "BATCH 661/1203 - LOSS: 0.2455 - ACCURACY: 0.8750\n",
      "BATCH 681/1203 - LOSS: 0.1021 - ACCURACY: 1.0000\n",
      "BATCH 701/1203 - LOSS: 0.0843 - ACCURACY: 1.0000\n",
      "BATCH 721/1203 - LOSS: 0.1854 - ACCURACY: 1.0000\n",
      "BATCH 741/1203 - LOSS: 0.2073 - ACCURACY: 0.9375\n",
      "BATCH 761/1203 - LOSS: 0.4374 - ACCURACY: 0.8750\n",
      "BATCH 781/1203 - LOSS: 0.2863 - ACCURACY: 0.8750\n",
      "BATCH 801/1203 - LOSS: 0.1082 - ACCURACY: 1.0000\n",
      "BATCH 821/1203 - LOSS: 0.1540 - ACCURACY: 1.0000\n",
      "BATCH 841/1203 - LOSS: 0.3557 - ACCURACY: 0.8125\n",
      "BATCH 861/1203 - LOSS: 0.2615 - ACCURACY: 0.8750\n",
      "BATCH 881/1203 - LOSS: 0.2606 - ACCURACY: 0.9375\n",
      "BATCH 901/1203 - LOSS: 0.1396 - ACCURACY: 0.9375\n",
      "BATCH 921/1203 - LOSS: 0.1384 - ACCURACY: 0.9375\n",
      "BATCH 941/1203 - LOSS: 0.3368 - ACCURACY: 0.9375\n",
      "BATCH 961/1203 - LOSS: 0.0664 - ACCURACY: 1.0000\n",
      "BATCH 981/1203 - LOSS: 0.0545 - ACCURACY: 1.0000\n",
      "BATCH 1001/1203 - LOSS: 0.2985 - ACCURACY: 0.9375\n",
      "BATCH 1021/1203 - LOSS: 0.2622 - ACCURACY: 0.8750\n",
      "BATCH 1041/1203 - LOSS: 0.1598 - ACCURACY: 0.9375\n",
      "BATCH 1061/1203 - LOSS: 0.0776 - ACCURACY: 1.0000\n",
      "BATCH 1081/1203 - LOSS: 0.1245 - ACCURACY: 0.9375\n",
      "BATCH 1101/1203 - LOSS: 0.1752 - ACCURACY: 0.9375\n",
      "BATCH 1121/1203 - LOSS: 0.0903 - ACCURACY: 1.0000\n",
      "BATCH 1141/1203 - LOSS: 0.5361 - ACCURACY: 0.8125\n",
      "BATCH 1161/1203 - LOSS: 0.2581 - ACCURACY: 0.9375\n",
      "BATCH 1181/1203 - LOSS: 0.1599 - ACCURACY: 0.9375\n",
      "BATCH 1201/1203 - LOSS: 0.1052 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH6-LOSS:0.2967529892921448,ACCURACY:0.8958852887153625\n",
      "\n",
      "EPOCH6-VALIDATING...\n",
      "\t[VALID] LOSS:0.44985803961753845,ACCURACY:0.8463346362113953\n",
      "\n",
      "==================================================\n",
      "EPOCH7-TRAINING...\n",
      "BATCH 1/1203 - LOSS: 0.3669 - ACCURACY: 0.8750\n",
      "BATCH 21/1203 - LOSS: 0.3519 - ACCURACY: 0.8750\n",
      "BATCH 41/1203 - LOSS: 0.3821 - ACCURACY: 0.9375\n",
      "BATCH 61/1203 - LOSS: 0.3824 - ACCURACY: 0.8125\n",
      "BATCH 81/1203 - LOSS: 0.3208 - ACCURACY: 0.9375\n",
      "BATCH 101/1203 - LOSS: 0.1352 - ACCURACY: 0.9375\n",
      "BATCH 121/1203 - LOSS: 0.1277 - ACCURACY: 0.9375\n",
      "BATCH 141/1203 - LOSS: 0.2656 - ACCURACY: 0.9375\n",
      "BATCH 161/1203 - LOSS: 0.1736 - ACCURACY: 0.9375\n",
      "BATCH 181/1203 - LOSS: 0.1939 - ACCURACY: 0.8750\n",
      "BATCH 201/1203 - LOSS: 0.4196 - ACCURACY: 0.8125\n",
      "BATCH 221/1203 - LOSS: 0.2099 - ACCURACY: 0.9375\n",
      "BATCH 241/1203 - LOSS: 0.1409 - ACCURACY: 0.9375\n",
      "BATCH 261/1203 - LOSS: 0.1113 - ACCURACY: 1.0000\n",
      "BATCH 281/1203 - LOSS: 0.1902 - ACCURACY: 0.9375\n",
      "BATCH 301/1203 - LOSS: 0.6258 - ACCURACY: 0.6875\n",
      "BATCH 321/1203 - LOSS: 0.2604 - ACCURACY: 0.8750\n",
      "BATCH 341/1203 - LOSS: 0.2921 - ACCURACY: 0.8750\n",
      "BATCH 361/1203 - LOSS: 0.2775 - ACCURACY: 0.8750\n",
      "BATCH 381/1203 - LOSS: 0.2188 - ACCURACY: 0.9375\n",
      "BATCH 401/1203 - LOSS: 0.1520 - ACCURACY: 0.9375\n",
      "BATCH 421/1203 - LOSS: 0.3131 - ACCURACY: 0.8750\n",
      "BATCH 441/1203 - LOSS: 0.4489 - ACCURACY: 0.8750\n",
      "BATCH 461/1203 - LOSS: 0.3190 - ACCURACY: 0.8125\n",
      "BATCH 481/1203 - LOSS: 0.5169 - ACCURACY: 0.6875\n",
      "BATCH 501/1203 - LOSS: 0.2518 - ACCURACY: 0.9375\n",
      "BATCH 521/1203 - LOSS: 0.2668 - ACCURACY: 0.9375\n",
      "BATCH 541/1203 - LOSS: 0.1234 - ACCURACY: 1.0000\n",
      "BATCH 561/1203 - LOSS: 0.3072 - ACCURACY: 0.9375\n",
      "BATCH 581/1203 - LOSS: 0.4475 - ACCURACY: 0.9375\n",
      "BATCH 601/1203 - LOSS: 0.2326 - ACCURACY: 0.9375\n",
      "BATCH 621/1203 - LOSS: 0.2860 - ACCURACY: 0.8750\n",
      "BATCH 641/1203 - LOSS: 0.4083 - ACCURACY: 0.8750\n",
      "BATCH 661/1203 - LOSS: 0.3704 - ACCURACY: 0.8125\n",
      "BATCH 681/1203 - LOSS: 0.2626 - ACCURACY: 0.8750\n",
      "BATCH 701/1203 - LOSS: 0.0971 - ACCURACY: 1.0000\n",
      "BATCH 721/1203 - LOSS: 0.2219 - ACCURACY: 0.9375\n",
      "BATCH 741/1203 - LOSS: 0.2569 - ACCURACY: 0.8750\n",
      "BATCH 761/1203 - LOSS: 0.3315 - ACCURACY: 0.8750\n",
      "BATCH 781/1203 - LOSS: 0.4291 - ACCURACY: 0.8750\n",
      "BATCH 801/1203 - LOSS: 0.1296 - ACCURACY: 1.0000\n",
      "BATCH 821/1203 - LOSS: 0.2449 - ACCURACY: 0.9375\n",
      "BATCH 841/1203 - LOSS: 0.2153 - ACCURACY: 0.8750\n",
      "BATCH 861/1203 - LOSS: 0.1827 - ACCURACY: 0.9375\n",
      "BATCH 881/1203 - LOSS: 0.3177 - ACCURACY: 0.8125\n",
      "BATCH 901/1203 - LOSS: 0.1019 - ACCURACY: 0.9375\n",
      "BATCH 921/1203 - LOSS: 0.1893 - ACCURACY: 0.9375\n",
      "BATCH 941/1203 - LOSS: 0.3174 - ACCURACY: 0.8750\n",
      "BATCH 961/1203 - LOSS: 0.0456 - ACCURACY: 1.0000\n",
      "BATCH 981/1203 - LOSS: 0.1247 - ACCURACY: 0.9375\n",
      "BATCH 1001/1203 - LOSS: 0.1700 - ACCURACY: 0.9375\n",
      "BATCH 1021/1203 - LOSS: 0.2012 - ACCURACY: 0.8750\n",
      "BATCH 1041/1203 - LOSS: 0.1293 - ACCURACY: 0.9375\n",
      "BATCH 1061/1203 - LOSS: 0.0172 - ACCURACY: 1.0000\n",
      "BATCH 1081/1203 - LOSS: 0.1800 - ACCURACY: 0.9375\n",
      "BATCH 1101/1203 - LOSS: 0.3584 - ACCURACY: 0.7500\n",
      "BATCH 1121/1203 - LOSS: 0.0567 - ACCURACY: 1.0000\n",
      "BATCH 1141/1203 - LOSS: 0.4564 - ACCURACY: 0.8750\n",
      "BATCH 1161/1203 - LOSS: 0.0482 - ACCURACY: 1.0000\n",
      "BATCH 1181/1203 - LOSS: 0.0537 - ACCURACY: 1.0000\n",
      "BATCH 1201/1203 - LOSS: 0.0825 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH7-LOSS:0.27613720297813416,ACCURACY:0.903262734413147\n",
      "\n",
      "EPOCH7-VALIDATING...\n",
      "\t[VALID] LOSS:0.4634649455547333,ACCURACY:0.8421052694320679\n",
      "\n",
      "==================================================\n",
      "EPOCH8-TRAINING...\n",
      "BATCH 1/1203 - LOSS: 0.2761 - ACCURACY: 0.8125\n",
      "BATCH 21/1203 - LOSS: 0.2987 - ACCURACY: 0.8750\n",
      "BATCH 41/1203 - LOSS: 0.2247 - ACCURACY: 0.9375\n",
      "BATCH 61/1203 - LOSS: 0.0970 - ACCURACY: 0.9375\n",
      "BATCH 81/1203 - LOSS: 0.5341 - ACCURACY: 0.8125\n",
      "BATCH 101/1203 - LOSS: 0.0363 - ACCURACY: 1.0000\n",
      "BATCH 121/1203 - LOSS: 0.1418 - ACCURACY: 0.9375\n",
      "BATCH 141/1203 - LOSS: 0.2616 - ACCURACY: 0.8125\n",
      "BATCH 161/1203 - LOSS: 0.0714 - ACCURACY: 1.0000\n",
      "BATCH 181/1203 - LOSS: 0.0912 - ACCURACY: 1.0000\n",
      "BATCH 201/1203 - LOSS: 0.4402 - ACCURACY: 0.9375\n",
      "BATCH 221/1203 - LOSS: 0.0496 - ACCURACY: 1.0000\n",
      "BATCH 241/1203 - LOSS: 0.0811 - ACCURACY: 1.0000\n",
      "BATCH 261/1203 - LOSS: 0.1214 - ACCURACY: 0.9375\n",
      "BATCH 281/1203 - LOSS: 0.1832 - ACCURACY: 0.9375\n",
      "BATCH 301/1203 - LOSS: 0.4877 - ACCURACY: 0.7500\n",
      "BATCH 321/1203 - LOSS: 0.0959 - ACCURACY: 1.0000\n",
      "BATCH 341/1203 - LOSS: 0.7631 - ACCURACY: 0.7500\n",
      "BATCH 361/1203 - LOSS: 0.5802 - ACCURACY: 0.8750\n",
      "BATCH 381/1203 - LOSS: 0.1577 - ACCURACY: 0.9375\n",
      "BATCH 401/1203 - LOSS: 0.1920 - ACCURACY: 0.8750\n",
      "BATCH 421/1203 - LOSS: 0.3749 - ACCURACY: 0.8750\n",
      "BATCH 441/1203 - LOSS: 0.1817 - ACCURACY: 0.9375\n",
      "BATCH 461/1203 - LOSS: 0.3023 - ACCURACY: 0.8750\n",
      "BATCH 481/1203 - LOSS: 0.3619 - ACCURACY: 0.7500\n",
      "BATCH 501/1203 - LOSS: 0.1834 - ACCURACY: 0.9375\n",
      "BATCH 521/1203 - LOSS: 0.2630 - ACCURACY: 0.9375\n",
      "BATCH 541/1203 - LOSS: 0.0906 - ACCURACY: 0.9375\n",
      "BATCH 561/1203 - LOSS: 0.2289 - ACCURACY: 0.9375\n",
      "BATCH 581/1203 - LOSS: 0.4147 - ACCURACY: 0.8750\n",
      "BATCH 601/1203 - LOSS: 0.1296 - ACCURACY: 0.9375\n",
      "BATCH 621/1203 - LOSS: 0.0863 - ACCURACY: 0.9375\n",
      "BATCH 641/1203 - LOSS: 0.4407 - ACCURACY: 0.8750\n",
      "BATCH 661/1203 - LOSS: 0.3147 - ACCURACY: 0.8750\n",
      "BATCH 681/1203 - LOSS: 0.1229 - ACCURACY: 0.9375\n",
      "BATCH 701/1203 - LOSS: 0.2232 - ACCURACY: 0.8750\n",
      "BATCH 721/1203 - LOSS: 0.1528 - ACCURACY: 1.0000\n",
      "BATCH 741/1203 - LOSS: 0.1142 - ACCURACY: 1.0000\n",
      "BATCH 761/1203 - LOSS: 0.3648 - ACCURACY: 0.8125\n",
      "BATCH 781/1203 - LOSS: 0.1580 - ACCURACY: 1.0000\n",
      "BATCH 801/1203 - LOSS: 0.2343 - ACCURACY: 0.8750\n",
      "BATCH 821/1203 - LOSS: 0.3626 - ACCURACY: 0.8750\n",
      "BATCH 841/1203 - LOSS: 0.2242 - ACCURACY: 0.8750\n",
      "BATCH 861/1203 - LOSS: 0.1103 - ACCURACY: 0.9375\n",
      "BATCH 881/1203 - LOSS: 0.1696 - ACCURACY: 0.9375\n",
      "BATCH 901/1203 - LOSS: 0.1434 - ACCURACY: 0.9375\n",
      "BATCH 921/1203 - LOSS: 0.1803 - ACCURACY: 0.9375\n",
      "BATCH 941/1203 - LOSS: 0.4039 - ACCURACY: 0.8750\n",
      "BATCH 961/1203 - LOSS: 0.0241 - ACCURACY: 1.0000\n",
      "BATCH 981/1203 - LOSS: 0.1976 - ACCURACY: 0.9375\n",
      "BATCH 1001/1203 - LOSS: 0.2517 - ACCURACY: 0.8750\n",
      "BATCH 1021/1203 - LOSS: 0.1919 - ACCURACY: 0.9375\n",
      "BATCH 1041/1203 - LOSS: 0.1775 - ACCURACY: 0.8750\n",
      "BATCH 1061/1203 - LOSS: 0.0895 - ACCURACY: 1.0000\n",
      "BATCH 1081/1203 - LOSS: 0.1000 - ACCURACY: 1.0000\n",
      "BATCH 1101/1203 - LOSS: 0.2169 - ACCURACY: 0.9375\n",
      "BATCH 1121/1203 - LOSS: 0.0368 - ACCURACY: 1.0000\n",
      "BATCH 1141/1203 - LOSS: 0.2359 - ACCURACY: 0.8750\n",
      "BATCH 1161/1203 - LOSS: 0.0582 - ACCURACY: 1.0000\n",
      "BATCH 1181/1203 - LOSS: 0.0389 - ACCURACY: 1.0000\n",
      "BATCH 1201/1203 - LOSS: 0.1724 - ACCURACY: 0.8750\n",
      "\n",
      "\t[TRAIN] EPOCH8-LOSS:0.25618410110473633,ACCURACY:0.9115232825279236\n",
      "\n",
      "EPOCH8-VALIDATING...\n",
      "\t[VALID] LOSS:0.47785747051239014,ACCURACY:0.8491541743278503\n",
      "\n",
      "==================================================\n",
      "EPOCH9-TRAINING...\n",
      "BATCH 1/1203 - LOSS: 0.2678 - ACCURACY: 0.8750\n",
      "BATCH 21/1203 - LOSS: 0.0739 - ACCURACY: 1.0000\n",
      "BATCH 41/1203 - LOSS: 0.2858 - ACCURACY: 0.9375\n",
      "BATCH 61/1203 - LOSS: 0.1415 - ACCURACY: 0.9375\n",
      "BATCH 81/1203 - LOSS: 0.4687 - ACCURACY: 0.7500\n",
      "BATCH 101/1203 - LOSS: 0.1284 - ACCURACY: 0.9375\n",
      "BATCH 121/1203 - LOSS: 0.0709 - ACCURACY: 1.0000\n",
      "BATCH 141/1203 - LOSS: 0.2021 - ACCURACY: 0.8750\n",
      "BATCH 161/1203 - LOSS: 0.0883 - ACCURACY: 0.9375\n",
      "BATCH 181/1203 - LOSS: 0.1587 - ACCURACY: 0.9375\n",
      "BATCH 201/1203 - LOSS: 0.6450 - ACCURACY: 0.7500\n",
      "BATCH 221/1203 - LOSS: 0.0485 - ACCURACY: 1.0000\n",
      "BATCH 241/1203 - LOSS: 0.0685 - ACCURACY: 1.0000\n",
      "BATCH 261/1203 - LOSS: 0.0325 - ACCURACY: 1.0000\n",
      "BATCH 281/1203 - LOSS: 0.0836 - ACCURACY: 1.0000\n",
      "BATCH 301/1203 - LOSS: 0.1531 - ACCURACY: 0.9375\n",
      "BATCH 321/1203 - LOSS: 0.0827 - ACCURACY: 1.0000\n",
      "BATCH 341/1203 - LOSS: 0.4092 - ACCURACY: 0.8125\n",
      "BATCH 361/1203 - LOSS: 0.3867 - ACCURACY: 0.6875\n",
      "BATCH 381/1203 - LOSS: 0.1983 - ACCURACY: 0.9375\n",
      "BATCH 401/1203 - LOSS: 0.2154 - ACCURACY: 0.9375\n",
      "BATCH 421/1203 - LOSS: 0.3120 - ACCURACY: 0.8125\n",
      "BATCH 441/1203 - LOSS: 0.1224 - ACCURACY: 1.0000\n",
      "BATCH 461/1203 - LOSS: 0.1681 - ACCURACY: 0.9375\n",
      "BATCH 481/1203 - LOSS: 0.2071 - ACCURACY: 0.9375\n",
      "BATCH 501/1203 - LOSS: 0.0758 - ACCURACY: 1.0000\n",
      "BATCH 521/1203 - LOSS: 0.1201 - ACCURACY: 1.0000\n",
      "BATCH 541/1203 - LOSS: 0.0998 - ACCURACY: 1.0000\n",
      "BATCH 561/1203 - LOSS: 0.0971 - ACCURACY: 1.0000\n",
      "BATCH 581/1203 - LOSS: 0.3162 - ACCURACY: 0.8750\n",
      "BATCH 601/1203 - LOSS: 0.2186 - ACCURACY: 0.9375\n",
      "BATCH 621/1203 - LOSS: 0.0738 - ACCURACY: 0.9375\n",
      "BATCH 641/1203 - LOSS: 0.4399 - ACCURACY: 0.8125\n",
      "BATCH 661/1203 - LOSS: 0.3517 - ACCURACY: 0.8750\n",
      "BATCH 681/1203 - LOSS: 0.0911 - ACCURACY: 1.0000\n",
      "BATCH 701/1203 - LOSS: 0.0508 - ACCURACY: 1.0000\n",
      "BATCH 721/1203 - LOSS: 0.0499 - ACCURACY: 1.0000\n",
      "BATCH 741/1203 - LOSS: 0.1702 - ACCURACY: 1.0000\n",
      "BATCH 761/1203 - LOSS: 0.2346 - ACCURACY: 0.8750\n",
      "BATCH 781/1203 - LOSS: 0.3028 - ACCURACY: 0.8750\n",
      "BATCH 801/1203 - LOSS: 0.1317 - ACCURACY: 0.9375\n",
      "BATCH 821/1203 - LOSS: 0.2209 - ACCURACY: 0.9375\n",
      "BATCH 841/1203 - LOSS: 0.1379 - ACCURACY: 0.9375\n",
      "BATCH 861/1203 - LOSS: 0.1714 - ACCURACY: 1.0000\n",
      "BATCH 881/1203 - LOSS: 0.1097 - ACCURACY: 1.0000\n",
      "BATCH 901/1203 - LOSS: 0.0482 - ACCURACY: 1.0000\n",
      "BATCH 921/1203 - LOSS: 0.2355 - ACCURACY: 0.9375\n",
      "BATCH 941/1203 - LOSS: 0.2922 - ACCURACY: 0.8125\n",
      "BATCH 961/1203 - LOSS: 0.0980 - ACCURACY: 0.9375\n",
      "BATCH 981/1203 - LOSS: 0.1305 - ACCURACY: 0.9375\n",
      "BATCH 1001/1203 - LOSS: 0.4431 - ACCURACY: 0.8750\n",
      "BATCH 1021/1203 - LOSS: 0.2555 - ACCURACY: 0.8750\n",
      "BATCH 1041/1203 - LOSS: 0.1976 - ACCURACY: 0.9375\n",
      "BATCH 1061/1203 - LOSS: 0.0136 - ACCURACY: 1.0000\n",
      "BATCH 1081/1203 - LOSS: 0.0642 - ACCURACY: 1.0000\n",
      "BATCH 1101/1203 - LOSS: 0.1330 - ACCURACY: 0.9375\n",
      "BATCH 1121/1203 - LOSS: 0.0197 - ACCURACY: 1.0000\n",
      "BATCH 1141/1203 - LOSS: 0.2513 - ACCURACY: 0.8750\n",
      "BATCH 1161/1203 - LOSS: 0.0230 - ACCURACY: 1.0000\n",
      "BATCH 1181/1203 - LOSS: 0.1302 - ACCURACY: 0.9375\n",
      "BATCH 1201/1203 - LOSS: 0.0479 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH9-LOSS:0.22919589281082153,ACCURACY:0.9225893616676331\n",
      "\n",
      "EPOCH9-VALIDATING...\n",
      "\t[VALID] LOSS:0.4828007221221924,ACCURACY:0.8463346362113953\n",
      "\n",
      "==================================================\n",
      "EPOCH10-TRAINING...\n",
      "BATCH 1/1203 - LOSS: 0.0525 - ACCURACY: 1.0000\n",
      "BATCH 21/1203 - LOSS: 0.1324 - ACCURACY: 0.9375\n",
      "BATCH 41/1203 - LOSS: 0.1984 - ACCURACY: 0.9375\n",
      "BATCH 61/1203 - LOSS: 0.4121 - ACCURACY: 0.8750\n",
      "BATCH 81/1203 - LOSS: 0.2133 - ACCURACY: 0.8750\n",
      "BATCH 101/1203 - LOSS: 0.0108 - ACCURACY: 1.0000\n",
      "BATCH 121/1203 - LOSS: 0.0967 - ACCURACY: 0.9375\n",
      "BATCH 141/1203 - LOSS: 0.2943 - ACCURACY: 0.8750\n",
      "BATCH 161/1203 - LOSS: 0.1328 - ACCURACY: 0.9375\n",
      "BATCH 181/1203 - LOSS: 0.1640 - ACCURACY: 0.8750\n",
      "BATCH 201/1203 - LOSS: 0.1422 - ACCURACY: 0.9375\n",
      "BATCH 221/1203 - LOSS: 0.2330 - ACCURACY: 0.8750\n",
      "BATCH 241/1203 - LOSS: 0.1026 - ACCURACY: 1.0000\n",
      "BATCH 261/1203 - LOSS: 0.0456 - ACCURACY: 1.0000\n",
      "BATCH 281/1203 - LOSS: 0.1006 - ACCURACY: 0.9375\n",
      "BATCH 301/1203 - LOSS: 0.4869 - ACCURACY: 0.8125\n",
      "BATCH 321/1203 - LOSS: 0.1132 - ACCURACY: 1.0000\n",
      "BATCH 341/1203 - LOSS: 0.2261 - ACCURACY: 0.8750\n",
      "BATCH 361/1203 - LOSS: 0.1688 - ACCURACY: 0.9375\n",
      "BATCH 381/1203 - LOSS: 0.0636 - ACCURACY: 1.0000\n",
      "BATCH 401/1203 - LOSS: 0.1496 - ACCURACY: 1.0000\n",
      "BATCH 421/1203 - LOSS: 0.6048 - ACCURACY: 0.8125\n",
      "BATCH 441/1203 - LOSS: 0.0845 - ACCURACY: 0.9375\n",
      "BATCH 461/1203 - LOSS: 0.2007 - ACCURACY: 0.9375\n",
      "BATCH 481/1203 - LOSS: 0.0831 - ACCURACY: 1.0000\n",
      "BATCH 501/1203 - LOSS: 0.1166 - ACCURACY: 0.9375\n",
      "BATCH 521/1203 - LOSS: 0.0940 - ACCURACY: 1.0000\n",
      "BATCH 541/1203 - LOSS: 0.0711 - ACCURACY: 1.0000\n",
      "BATCH 561/1203 - LOSS: 0.3932 - ACCURACY: 0.8750\n",
      "BATCH 581/1203 - LOSS: 0.3643 - ACCURACY: 0.9375\n",
      "BATCH 601/1203 - LOSS: 0.0474 - ACCURACY: 1.0000\n",
      "BATCH 621/1203 - LOSS: 0.0838 - ACCURACY: 1.0000\n",
      "BATCH 641/1203 - LOSS: 0.2297 - ACCURACY: 0.8750\n",
      "BATCH 661/1203 - LOSS: 0.2284 - ACCURACY: 0.9375\n",
      "BATCH 681/1203 - LOSS: 0.1823 - ACCURACY: 0.9375\n",
      "BATCH 701/1203 - LOSS: 0.1160 - ACCURACY: 0.9375\n",
      "BATCH 721/1203 - LOSS: 0.1832 - ACCURACY: 0.9375\n",
      "BATCH 741/1203 - LOSS: 0.4334 - ACCURACY: 0.8125\n",
      "BATCH 761/1203 - LOSS: 0.2086 - ACCURACY: 0.9375\n",
      "BATCH 781/1203 - LOSS: 0.1882 - ACCURACY: 0.9375\n",
      "BATCH 801/1203 - LOSS: 0.0613 - ACCURACY: 1.0000\n",
      "BATCH 821/1203 - LOSS: 0.1835 - ACCURACY: 0.9375\n",
      "BATCH 841/1203 - LOSS: 0.0789 - ACCURACY: 1.0000\n",
      "BATCH 861/1203 - LOSS: 0.2576 - ACCURACY: 0.8750\n",
      "BATCH 881/1203 - LOSS: 0.2047 - ACCURACY: 0.9375\n",
      "BATCH 901/1203 - LOSS: 0.1005 - ACCURACY: 1.0000\n",
      "BATCH 921/1203 - LOSS: 0.1593 - ACCURACY: 0.9375\n",
      "BATCH 941/1203 - LOSS: 0.2955 - ACCURACY: 0.8750\n",
      "BATCH 961/1203 - LOSS: 0.0461 - ACCURACY: 1.0000\n",
      "BATCH 981/1203 - LOSS: 0.1334 - ACCURACY: 0.9375\n",
      "BATCH 1001/1203 - LOSS: 0.3338 - ACCURACY: 0.8750\n",
      "BATCH 1021/1203 - LOSS: 0.3048 - ACCURACY: 0.8750\n",
      "BATCH 1041/1203 - LOSS: 0.1481 - ACCURACY: 0.8750\n",
      "BATCH 1061/1203 - LOSS: 0.0379 - ACCURACY: 1.0000\n",
      "BATCH 1081/1203 - LOSS: 0.0642 - ACCURACY: 1.0000\n",
      "BATCH 1101/1203 - LOSS: 0.4017 - ACCURACY: 0.8750\n",
      "BATCH 1121/1203 - LOSS: 0.0708 - ACCURACY: 0.9375\n",
      "BATCH 1141/1203 - LOSS: 0.0719 - ACCURACY: 0.9375\n",
      "BATCH 1161/1203 - LOSS: 0.0511 - ACCURACY: 1.0000\n",
      "BATCH 1181/1203 - LOSS: 0.3601 - ACCURACY: 0.9375\n",
      "BATCH 1201/1203 - LOSS: 0.1971 - ACCURACY: 0.9375\n",
      "\n",
      "\t[TRAIN] EPOCH10-LOSS:0.21731768548488617,ACCURACY:0.9225374460220337\n",
      "\n",
      "EPOCH10-VALIDATING...\n",
      "\t[VALID] LOSS:0.5095608830451965,ACCURACY:0.8439849615097046\n",
      "\n",
      "==================================================\n",
      "EPOCH11-TRAINING...\n",
      "BATCH 1/1203 - LOSS: 0.1915 - ACCURACY: 0.9375\n",
      "BATCH 21/1203 - LOSS: 0.1282 - ACCURACY: 0.9375\n",
      "BATCH 41/1203 - LOSS: 0.1005 - ACCURACY: 1.0000\n",
      "BATCH 61/1203 - LOSS: 0.0088 - ACCURACY: 1.0000\n",
      "BATCH 81/1203 - LOSS: 0.1453 - ACCURACY: 0.9375\n",
      "BATCH 101/1203 - LOSS: 0.0301 - ACCURACY: 1.0000\n",
      "BATCH 121/1203 - LOSS: 0.0714 - ACCURACY: 0.9375\n",
      "BATCH 141/1203 - LOSS: 0.0858 - ACCURACY: 1.0000\n",
      "BATCH 161/1203 - LOSS: 0.0247 - ACCURACY: 1.0000\n",
      "BATCH 181/1203 - LOSS: 0.3758 - ACCURACY: 0.9375\n",
      "BATCH 201/1203 - LOSS: 0.1446 - ACCURACY: 0.9375\n",
      "BATCH 221/1203 - LOSS: 0.0114 - ACCURACY: 1.0000\n",
      "BATCH 241/1203 - LOSS: 0.0331 - ACCURACY: 1.0000\n",
      "BATCH 261/1203 - LOSS: 0.0797 - ACCURACY: 0.9375\n",
      "BATCH 281/1203 - LOSS: 0.0574 - ACCURACY: 1.0000\n",
      "BATCH 301/1203 - LOSS: 0.2046 - ACCURACY: 0.9375\n",
      "BATCH 321/1203 - LOSS: 0.0588 - ACCURACY: 1.0000\n",
      "BATCH 341/1203 - LOSS: 0.1036 - ACCURACY: 1.0000\n",
      "BATCH 361/1203 - LOSS: 0.2562 - ACCURACY: 0.9375\n",
      "BATCH 381/1203 - LOSS: 0.1509 - ACCURACY: 0.9375\n",
      "BATCH 401/1203 - LOSS: 0.0761 - ACCURACY: 1.0000\n",
      "BATCH 421/1203 - LOSS: 0.5350 - ACCURACY: 0.8750\n",
      "BATCH 441/1203 - LOSS: 0.2450 - ACCURACY: 0.9375\n",
      "BATCH 461/1203 - LOSS: 0.3860 - ACCURACY: 0.8125\n",
      "BATCH 481/1203 - LOSS: 0.2494 - ACCURACY: 0.8750\n",
      "BATCH 501/1203 - LOSS: 0.2208 - ACCURACY: 0.8750\n",
      "BATCH 521/1203 - LOSS: 0.2054 - ACCURACY: 0.9375\n",
      "BATCH 541/1203 - LOSS: 0.1486 - ACCURACY: 0.9375\n",
      "BATCH 561/1203 - LOSS: 0.2625 - ACCURACY: 0.9375\n",
      "BATCH 581/1203 - LOSS: 0.4522 - ACCURACY: 0.8125\n",
      "BATCH 601/1203 - LOSS: 0.2563 - ACCURACY: 0.8750\n",
      "BATCH 621/1203 - LOSS: 0.0862 - ACCURACY: 1.0000\n",
      "BATCH 641/1203 - LOSS: 0.4091 - ACCURACY: 0.8750\n",
      "BATCH 661/1203 - LOSS: 0.1123 - ACCURACY: 1.0000\n",
      "BATCH 681/1203 - LOSS: 0.0985 - ACCURACY: 1.0000\n",
      "BATCH 701/1203 - LOSS: 0.0801 - ACCURACY: 1.0000\n",
      "BATCH 721/1203 - LOSS: 0.2126 - ACCURACY: 0.9375\n",
      "BATCH 741/1203 - LOSS: 0.3622 - ACCURACY: 0.8750\n",
      "BATCH 761/1203 - LOSS: 0.2229 - ACCURACY: 0.9375\n",
      "BATCH 781/1203 - LOSS: 0.4018 - ACCURACY: 0.8750\n",
      "BATCH 801/1203 - LOSS: 0.1341 - ACCURACY: 0.9375\n",
      "BATCH 821/1203 - LOSS: 0.1409 - ACCURACY: 0.9375\n",
      "BATCH 841/1203 - LOSS: 0.1396 - ACCURACY: 0.9375\n",
      "BATCH 861/1203 - LOSS: 0.1184 - ACCURACY: 1.0000\n",
      "BATCH 881/1203 - LOSS: 0.0579 - ACCURACY: 1.0000\n",
      "BATCH 901/1203 - LOSS: 0.0328 - ACCURACY: 1.0000\n",
      "BATCH 921/1203 - LOSS: 0.0781 - ACCURACY: 1.0000\n",
      "BATCH 941/1203 - LOSS: 0.1688 - ACCURACY: 0.9375\n",
      "BATCH 961/1203 - LOSS: 0.0310 - ACCURACY: 1.0000\n",
      "BATCH 981/1203 - LOSS: 0.0673 - ACCURACY: 1.0000\n",
      "BATCH 1001/1203 - LOSS: 0.1837 - ACCURACY: 0.9375\n",
      "BATCH 1021/1203 - LOSS: 0.4423 - ACCURACY: 0.8750\n",
      "BATCH 1041/1203 - LOSS: 0.1387 - ACCURACY: 0.8750\n",
      "BATCH 1061/1203 - LOSS: 0.0156 - ACCURACY: 1.0000\n",
      "BATCH 1081/1203 - LOSS: 0.0963 - ACCURACY: 0.9375\n",
      "BATCH 1101/1203 - LOSS: 0.2313 - ACCURACY: 0.9375\n",
      "BATCH 1121/1203 - LOSS: 0.0258 - ACCURACY: 1.0000\n",
      "BATCH 1141/1203 - LOSS: 0.2534 - ACCURACY: 0.8750\n",
      "BATCH 1161/1203 - LOSS: 0.0685 - ACCURACY: 1.0000\n",
      "BATCH 1181/1203 - LOSS: 0.0249 - ACCURACY: 1.0000\n",
      "BATCH 1201/1203 - LOSS: 0.0558 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH11-LOSS:0.19789592921733856,ACCURACY:0.9327722787857056\n",
      "\n",
      "EPOCH11-VALIDATING...\n",
      "\t[VALID] LOSS:0.5126603245735168,ACCURACY:0.8453947305679321\n",
      "\n",
      "==================================================\n",
      "EPOCH12-TRAINING...\n",
      "BATCH 1/1203 - LOSS: 0.0437 - ACCURACY: 1.0000\n",
      "BATCH 21/1203 - LOSS: 0.0985 - ACCURACY: 1.0000\n",
      "BATCH 41/1203 - LOSS: 0.1354 - ACCURACY: 0.9375\n",
      "BATCH 61/1203 - LOSS: 0.0650 - ACCURACY: 0.9375\n",
      "BATCH 81/1203 - LOSS: 0.3037 - ACCURACY: 0.8750\n",
      "BATCH 101/1203 - LOSS: 0.0114 - ACCURACY: 1.0000\n",
      "BATCH 121/1203 - LOSS: 0.0878 - ACCURACY: 0.9375\n",
      "BATCH 141/1203 - LOSS: 0.1855 - ACCURACY: 0.8750\n",
      "BATCH 161/1203 - LOSS: 0.0592 - ACCURACY: 1.0000\n",
      "BATCH 181/1203 - LOSS: 0.2776 - ACCURACY: 0.8750\n",
      "BATCH 201/1203 - LOSS: 0.1041 - ACCURACY: 1.0000\n",
      "BATCH 221/1203 - LOSS: 0.0221 - ACCURACY: 1.0000\n",
      "BATCH 241/1203 - LOSS: 0.0953 - ACCURACY: 1.0000\n",
      "BATCH 261/1203 - LOSS: 0.0115 - ACCURACY: 1.0000\n",
      "BATCH 281/1203 - LOSS: 0.0710 - ACCURACY: 1.0000\n",
      "BATCH 301/1203 - LOSS: 0.5810 - ACCURACY: 0.6875\n",
      "BATCH 321/1203 - LOSS: 0.0383 - ACCURACY: 1.0000\n",
      "BATCH 341/1203 - LOSS: 0.2374 - ACCURACY: 0.8750\n",
      "BATCH 361/1203 - LOSS: 0.0648 - ACCURACY: 1.0000\n",
      "BATCH 381/1203 - LOSS: 0.0379 - ACCURACY: 1.0000\n",
      "BATCH 401/1203 - LOSS: 0.1560 - ACCURACY: 0.9375\n",
      "BATCH 421/1203 - LOSS: 0.1520 - ACCURACY: 0.9375\n",
      "BATCH 441/1203 - LOSS: 0.0657 - ACCURACY: 1.0000\n",
      "BATCH 461/1203 - LOSS: 0.2820 - ACCURACY: 0.8750\n",
      "BATCH 481/1203 - LOSS: 0.2380 - ACCURACY: 0.9375\n",
      "BATCH 501/1203 - LOSS: 0.0684 - ACCURACY: 1.0000\n",
      "BATCH 521/1203 - LOSS: 0.1100 - ACCURACY: 1.0000\n",
      "BATCH 541/1203 - LOSS: 0.0789 - ACCURACY: 1.0000\n",
      "BATCH 561/1203 - LOSS: 0.3528 - ACCURACY: 0.9375\n",
      "BATCH 581/1203 - LOSS: 0.3615 - ACCURACY: 0.8125\n",
      "BATCH 601/1203 - LOSS: 0.1809 - ACCURACY: 0.9375\n",
      "BATCH 621/1203 - LOSS: 0.2632 - ACCURACY: 0.9375\n",
      "BATCH 641/1203 - LOSS: 0.1483 - ACCURACY: 0.9375\n",
      "BATCH 661/1203 - LOSS: 0.1541 - ACCURACY: 1.0000\n",
      "BATCH 681/1203 - LOSS: 0.1150 - ACCURACY: 0.9375\n",
      "BATCH 701/1203 - LOSS: 0.1171 - ACCURACY: 0.9375\n",
      "BATCH 721/1203 - LOSS: 0.3171 - ACCURACY: 0.8125\n",
      "BATCH 741/1203 - LOSS: 0.1671 - ACCURACY: 0.9375\n",
      "BATCH 761/1203 - LOSS: 0.1655 - ACCURACY: 0.9375\n",
      "BATCH 781/1203 - LOSS: 0.2384 - ACCURACY: 0.8750\n",
      "BATCH 801/1203 - LOSS: 0.0775 - ACCURACY: 1.0000\n",
      "BATCH 821/1203 - LOSS: 0.1791 - ACCURACY: 0.9375\n",
      "BATCH 841/1203 - LOSS: 0.3810 - ACCURACY: 0.9375\n",
      "BATCH 861/1203 - LOSS: 0.1518 - ACCURACY: 0.9375\n",
      "BATCH 881/1203 - LOSS: 0.1253 - ACCURACY: 0.9375\n",
      "BATCH 901/1203 - LOSS: 0.0511 - ACCURACY: 1.0000\n",
      "BATCH 921/1203 - LOSS: 0.1775 - ACCURACY: 0.9375\n",
      "BATCH 941/1203 - LOSS: 0.2200 - ACCURACY: 0.8750\n",
      "BATCH 961/1203 - LOSS: 0.0470 - ACCURACY: 1.0000\n",
      "BATCH 981/1203 - LOSS: 0.1441 - ACCURACY: 0.9375\n",
      "BATCH 1001/1203 - LOSS: 0.2385 - ACCURACY: 0.8750\n",
      "BATCH 1021/1203 - LOSS: 0.1363 - ACCURACY: 1.0000\n",
      "BATCH 1041/1203 - LOSS: 0.2044 - ACCURACY: 0.9375\n",
      "BATCH 1061/1203 - LOSS: 0.0708 - ACCURACY: 1.0000\n",
      "BATCH 1081/1203 - LOSS: 0.1097 - ACCURACY: 0.9375\n",
      "BATCH 1101/1203 - LOSS: 0.2714 - ACCURACY: 0.9375\n",
      "BATCH 1121/1203 - LOSS: 0.1980 - ACCURACY: 0.9375\n",
      "BATCH 1141/1203 - LOSS: 0.1519 - ACCURACY: 0.9375\n",
      "BATCH 1161/1203 - LOSS: 0.0859 - ACCURACY: 1.0000\n",
      "BATCH 1181/1203 - LOSS: 0.1079 - ACCURACY: 1.0000\n",
      "BATCH 1201/1203 - LOSS: 0.0320 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH12-LOSS:0.179058238863945,ACCURACY:0.93682461977005\n",
      "\n",
      "EPOCH12-VALIDATING...\n",
      "\t[VALID] LOSS:0.5008570551872253,ACCURACY:0.8571428656578064\n",
      "\n",
      "==================================================\n",
      "EPOCH13-TRAINING...\n",
      "BATCH 1/1203 - LOSS: 0.1149 - ACCURACY: 0.9375\n",
      "BATCH 21/1203 - LOSS: 0.1138 - ACCURACY: 0.9375\n",
      "BATCH 41/1203 - LOSS: 0.0663 - ACCURACY: 1.0000\n",
      "BATCH 61/1203 - LOSS: 0.0129 - ACCURACY: 1.0000\n",
      "BATCH 81/1203 - LOSS: 0.3875 - ACCURACY: 0.8750\n",
      "BATCH 101/1203 - LOSS: 0.0057 - ACCURACY: 1.0000\n",
      "BATCH 121/1203 - LOSS: 0.0516 - ACCURACY: 1.0000\n",
      "BATCH 141/1203 - LOSS: 0.2007 - ACCURACY: 0.9375\n",
      "BATCH 161/1203 - LOSS: 0.0956 - ACCURACY: 1.0000\n",
      "BATCH 181/1203 - LOSS: 0.4975 - ACCURACY: 0.8750\n",
      "BATCH 201/1203 - LOSS: 0.4587 - ACCURACY: 0.8750\n",
      "BATCH 221/1203 - LOSS: 0.0062 - ACCURACY: 1.0000\n",
      "BATCH 241/1203 - LOSS: 0.0508 - ACCURACY: 1.0000\n",
      "BATCH 261/1203 - LOSS: 0.0099 - ACCURACY: 1.0000\n",
      "BATCH 281/1203 - LOSS: 0.0215 - ACCURACY: 1.0000\n",
      "BATCH 301/1203 - LOSS: 0.2737 - ACCURACY: 0.9375\n",
      "BATCH 321/1203 - LOSS: 0.0669 - ACCURACY: 1.0000\n",
      "BATCH 341/1203 - LOSS: 0.3385 - ACCURACY: 0.8750\n",
      "BATCH 361/1203 - LOSS: 0.1699 - ACCURACY: 0.8750\n",
      "BATCH 381/1203 - LOSS: 0.1261 - ACCURACY: 0.9375\n",
      "BATCH 401/1203 - LOSS: 0.0394 - ACCURACY: 1.0000\n",
      "BATCH 421/1203 - LOSS: 0.1690 - ACCURACY: 0.9375\n",
      "BATCH 441/1203 - LOSS: 0.0814 - ACCURACY: 1.0000\n",
      "BATCH 461/1203 - LOSS: 0.4246 - ACCURACY: 0.7500\n",
      "BATCH 481/1203 - LOSS: 0.1395 - ACCURACY: 0.9375\n",
      "BATCH 501/1203 - LOSS: 0.0379 - ACCURACY: 1.0000\n",
      "BATCH 521/1203 - LOSS: 0.3815 - ACCURACY: 0.8750\n",
      "BATCH 541/1203 - LOSS: 0.1974 - ACCURACY: 0.9375\n",
      "BATCH 561/1203 - LOSS: 0.1532 - ACCURACY: 0.9375\n",
      "BATCH 581/1203 - LOSS: 0.1772 - ACCURACY: 0.9375\n",
      "BATCH 601/1203 - LOSS: 0.1737 - ACCURACY: 0.9375\n",
      "BATCH 621/1203 - LOSS: 0.1495 - ACCURACY: 0.9375\n",
      "BATCH 641/1203 - LOSS: 0.1636 - ACCURACY: 0.9375\n",
      "BATCH 661/1203 - LOSS: 0.0996 - ACCURACY: 0.9375\n",
      "BATCH 681/1203 - LOSS: 0.1578 - ACCURACY: 0.9375\n",
      "BATCH 701/1203 - LOSS: 0.0824 - ACCURACY: 1.0000\n",
      "BATCH 721/1203 - LOSS: 0.5662 - ACCURACY: 0.8750\n",
      "BATCH 741/1203 - LOSS: 0.1543 - ACCURACY: 0.9375\n",
      "BATCH 761/1203 - LOSS: 0.6160 - ACCURACY: 0.8750\n",
      "BATCH 781/1203 - LOSS: 0.0893 - ACCURACY: 1.0000\n",
      "BATCH 801/1203 - LOSS: 0.0709 - ACCURACY: 1.0000\n",
      "BATCH 821/1203 - LOSS: 0.0724 - ACCURACY: 1.0000\n",
      "BATCH 841/1203 - LOSS: 0.1191 - ACCURACY: 0.9375\n",
      "BATCH 861/1203 - LOSS: 0.0385 - ACCURACY: 1.0000\n",
      "BATCH 881/1203 - LOSS: 0.1787 - ACCURACY: 0.9375\n",
      "BATCH 901/1203 - LOSS: 0.0435 - ACCURACY: 1.0000\n",
      "BATCH 921/1203 - LOSS: 0.0290 - ACCURACY: 1.0000\n",
      "BATCH 941/1203 - LOSS: 0.4257 - ACCURACY: 0.8125\n",
      "BATCH 961/1203 - LOSS: 0.0172 - ACCURACY: 1.0000\n",
      "BATCH 981/1203 - LOSS: 0.0996 - ACCURACY: 0.9375\n",
      "BATCH 1001/1203 - LOSS: 0.0391 - ACCURACY: 1.0000\n",
      "BATCH 1021/1203 - LOSS: 0.2702 - ACCURACY: 0.8750\n",
      "BATCH 1041/1203 - LOSS: 0.1264 - ACCURACY: 0.9375\n",
      "BATCH 1061/1203 - LOSS: 0.0087 - ACCURACY: 1.0000\n",
      "BATCH 1081/1203 - LOSS: 0.0627 - ACCURACY: 1.0000\n",
      "BATCH 1101/1203 - LOSS: 0.0314 - ACCURACY: 1.0000\n",
      "BATCH 1121/1203 - LOSS: 0.0171 - ACCURACY: 1.0000\n",
      "BATCH 1141/1203 - LOSS: 0.0345 - ACCURACY: 1.0000\n",
      "BATCH 1161/1203 - LOSS: 0.0132 - ACCURACY: 1.0000\n",
      "BATCH 1181/1203 - LOSS: 0.1462 - ACCURACY: 0.9375\n",
      "BATCH 1201/1203 - LOSS: 0.0178 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH13-LOSS:0.15928395092487335,ACCURACY:0.9466438293457031\n",
      "\n",
      "EPOCH13-VALIDATING...\n",
      "\t[VALID] LOSS:0.541366457939148,ACCURACY:0.8453947305679321\n",
      "\n",
      "==================================================\n",
      "EPOCH14-TRAINING...\n",
      "BATCH 1/1203 - LOSS: 0.0270 - ACCURACY: 1.0000\n",
      "BATCH 21/1203 - LOSS: 0.1543 - ACCURACY: 0.9375\n",
      "BATCH 41/1203 - LOSS: 0.0977 - ACCURACY: 1.0000\n",
      "BATCH 61/1203 - LOSS: 0.0339 - ACCURACY: 1.0000\n",
      "BATCH 81/1203 - LOSS: 0.3857 - ACCURACY: 0.8750\n",
      "BATCH 101/1203 - LOSS: 0.0055 - ACCURACY: 1.0000\n",
      "BATCH 121/1203 - LOSS: 0.0419 - ACCURACY: 1.0000\n",
      "BATCH 141/1203 - LOSS: 0.1047 - ACCURACY: 0.9375\n",
      "BATCH 161/1203 - LOSS: 0.0778 - ACCURACY: 1.0000\n",
      "BATCH 181/1203 - LOSS: 0.0324 - ACCURACY: 1.0000\n",
      "BATCH 201/1203 - LOSS: 0.1924 - ACCURACY: 0.9375\n",
      "BATCH 221/1203 - LOSS: 0.0441 - ACCURACY: 1.0000\n",
      "BATCH 241/1203 - LOSS: 0.0549 - ACCURACY: 1.0000\n",
      "BATCH 261/1203 - LOSS: 0.0105 - ACCURACY: 1.0000\n",
      "BATCH 281/1203 - LOSS: 0.0884 - ACCURACY: 0.9375\n",
      "BATCH 301/1203 - LOSS: 0.3105 - ACCURACY: 0.8750\n",
      "BATCH 321/1203 - LOSS: 0.0459 - ACCURACY: 1.0000\n",
      "BATCH 341/1203 - LOSS: 0.0429 - ACCURACY: 1.0000\n",
      "BATCH 361/1203 - LOSS: 0.2102 - ACCURACY: 0.8125\n",
      "BATCH 381/1203 - LOSS: 0.0249 - ACCURACY: 1.0000\n",
      "BATCH 401/1203 - LOSS: 0.0300 - ACCURACY: 1.0000\n",
      "BATCH 421/1203 - LOSS: 0.1150 - ACCURACY: 1.0000\n",
      "BATCH 441/1203 - LOSS: 0.1119 - ACCURACY: 0.9375\n",
      "BATCH 461/1203 - LOSS: 0.4730 - ACCURACY: 0.8750\n",
      "BATCH 481/1203 - LOSS: 0.1944 - ACCURACY: 0.8750\n",
      "BATCH 501/1203 - LOSS: 0.0333 - ACCURACY: 1.0000\n",
      "BATCH 521/1203 - LOSS: 0.1779 - ACCURACY: 0.9375\n",
      "BATCH 541/1203 - LOSS: 0.0549 - ACCURACY: 1.0000\n",
      "BATCH 561/1203 - LOSS: 0.0907 - ACCURACY: 1.0000\n",
      "BATCH 581/1203 - LOSS: 0.2370 - ACCURACY: 0.8750\n",
      "BATCH 601/1203 - LOSS: 0.0579 - ACCURACY: 1.0000\n",
      "BATCH 621/1203 - LOSS: 0.0520 - ACCURACY: 1.0000\n",
      "BATCH 641/1203 - LOSS: 0.0802 - ACCURACY: 0.9375\n",
      "BATCH 661/1203 - LOSS: 0.0516 - ACCURACY: 1.0000\n",
      "BATCH 681/1203 - LOSS: 0.0876 - ACCURACY: 0.9375\n",
      "BATCH 701/1203 - LOSS: 0.0215 - ACCURACY: 1.0000\n",
      "BATCH 721/1203 - LOSS: 0.0439 - ACCURACY: 1.0000\n",
      "BATCH 741/1203 - LOSS: 0.0269 - ACCURACY: 1.0000\n",
      "BATCH 761/1203 - LOSS: 0.1368 - ACCURACY: 0.9375\n",
      "BATCH 781/1203 - LOSS: 0.0737 - ACCURACY: 1.0000\n",
      "BATCH 801/1203 - LOSS: 0.1165 - ACCURACY: 1.0000\n",
      "BATCH 821/1203 - LOSS: 0.2204 - ACCURACY: 0.9375\n",
      "BATCH 841/1203 - LOSS: 0.0156 - ACCURACY: 1.0000\n",
      "BATCH 861/1203 - LOSS: 0.0363 - ACCURACY: 1.0000\n",
      "BATCH 881/1203 - LOSS: 0.0632 - ACCURACY: 1.0000\n",
      "BATCH 901/1203 - LOSS: 0.2999 - ACCURACY: 0.8750\n",
      "BATCH 921/1203 - LOSS: 0.0119 - ACCURACY: 1.0000\n",
      "BATCH 941/1203 - LOSS: 0.0291 - ACCURACY: 1.0000\n",
      "BATCH 961/1203 - LOSS: 0.0821 - ACCURACY: 0.9375\n",
      "BATCH 981/1203 - LOSS: 0.0587 - ACCURACY: 1.0000\n",
      "BATCH 1001/1203 - LOSS: 0.1636 - ACCURACY: 0.8750\n",
      "BATCH 1021/1203 - LOSS: 0.3719 - ACCURACY: 0.8750\n",
      "BATCH 1041/1203 - LOSS: 0.1006 - ACCURACY: 0.9375\n",
      "BATCH 1061/1203 - LOSS: 0.0668 - ACCURACY: 1.0000\n",
      "BATCH 1081/1203 - LOSS: 0.0624 - ACCURACY: 1.0000\n",
      "BATCH 1101/1203 - LOSS: 0.3129 - ACCURACY: 0.8750\n",
      "BATCH 1121/1203 - LOSS: 0.0242 - ACCURACY: 1.0000\n",
      "BATCH 1141/1203 - LOSS: 0.1784 - ACCURACY: 0.9375\n",
      "BATCH 1161/1203 - LOSS: 0.0230 - ACCURACY: 1.0000\n",
      "BATCH 1181/1203 - LOSS: 0.1048 - ACCURACY: 0.9375\n",
      "BATCH 1201/1203 - LOSS: 0.0108 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH14-LOSS:0.1506418138742447,ACCURACY:0.9456047415733337\n",
      "\n",
      "EPOCH14-VALIDATING...\n",
      "\t[VALID] LOSS:0.5396567583084106,ACCURACY:0.8496240973472595\n",
      "\n",
      "==================================================\n",
      "EPOCH15-TRAINING...\n",
      "BATCH 1/1203 - LOSS: 0.0568 - ACCURACY: 1.0000\n",
      "BATCH 21/1203 - LOSS: 0.0492 - ACCURACY: 1.0000\n",
      "BATCH 41/1203 - LOSS: 0.1613 - ACCURACY: 0.9375\n",
      "BATCH 61/1203 - LOSS: 0.0821 - ACCURACY: 0.9375\n",
      "BATCH 81/1203 - LOSS: 0.0464 - ACCURACY: 1.0000\n",
      "BATCH 101/1203 - LOSS: 0.0025 - ACCURACY: 1.0000\n",
      "BATCH 121/1203 - LOSS: 0.0523 - ACCURACY: 1.0000\n",
      "BATCH 141/1203 - LOSS: 0.0610 - ACCURACY: 1.0000\n",
      "BATCH 161/1203 - LOSS: 0.2881 - ACCURACY: 0.9375\n",
      "BATCH 181/1203 - LOSS: 0.0611 - ACCURACY: 1.0000\n",
      "BATCH 201/1203 - LOSS: 0.3605 - ACCURACY: 0.9375\n",
      "BATCH 221/1203 - LOSS: 0.0236 - ACCURACY: 1.0000\n",
      "BATCH 241/1203 - LOSS: 0.0520 - ACCURACY: 1.0000\n",
      "BATCH 261/1203 - LOSS: 0.0872 - ACCURACY: 1.0000\n",
      "BATCH 281/1203 - LOSS: 0.0898 - ACCURACY: 0.9375\n",
      "BATCH 301/1203 - LOSS: 0.3761 - ACCURACY: 0.8750\n",
      "BATCH 321/1203 - LOSS: 0.0885 - ACCURACY: 1.0000\n",
      "BATCH 341/1203 - LOSS: 0.0604 - ACCURACY: 1.0000\n",
      "BATCH 361/1203 - LOSS: 0.3227 - ACCURACY: 0.8750\n",
      "BATCH 381/1203 - LOSS: 0.0112 - ACCURACY: 1.0000\n",
      "BATCH 401/1203 - LOSS: 0.0804 - ACCURACY: 1.0000\n",
      "BATCH 421/1203 - LOSS: 0.3181 - ACCURACY: 0.8750\n",
      "BATCH 441/1203 - LOSS: 0.1453 - ACCURACY: 0.9375\n",
      "BATCH 461/1203 - LOSS: 0.0647 - ACCURACY: 1.0000\n",
      "BATCH 481/1203 - LOSS: 0.0539 - ACCURACY: 1.0000\n",
      "BATCH 501/1203 - LOSS: 0.1126 - ACCURACY: 0.9375\n",
      "BATCH 521/1203 - LOSS: 0.0781 - ACCURACY: 1.0000\n",
      "BATCH 541/1203 - LOSS: 0.0986 - ACCURACY: 0.9375\n",
      "BATCH 561/1203 - LOSS: 0.1085 - ACCURACY: 0.9375\n",
      "BATCH 581/1203 - LOSS: 0.2342 - ACCURACY: 0.8125\n",
      "BATCH 601/1203 - LOSS: 0.0357 - ACCURACY: 1.0000\n",
      "BATCH 621/1203 - LOSS: 0.2652 - ACCURACY: 0.9375\n",
      "BATCH 641/1203 - LOSS: 0.1936 - ACCURACY: 0.8750\n",
      "BATCH 661/1203 - LOSS: 0.1491 - ACCURACY: 0.9375\n",
      "BATCH 681/1203 - LOSS: 0.0918 - ACCURACY: 1.0000\n",
      "BATCH 701/1203 - LOSS: 0.1188 - ACCURACY: 0.9375\n",
      "BATCH 721/1203 - LOSS: 0.1805 - ACCURACY: 0.9375\n",
      "BATCH 741/1203 - LOSS: 0.0801 - ACCURACY: 1.0000\n",
      "BATCH 761/1203 - LOSS: 0.3944 - ACCURACY: 0.8750\n",
      "BATCH 781/1203 - LOSS: 0.1120 - ACCURACY: 0.9375\n",
      "BATCH 801/1203 - LOSS: 0.1800 - ACCURACY: 0.8750\n",
      "BATCH 821/1203 - LOSS: 0.0532 - ACCURACY: 1.0000\n",
      "BATCH 841/1203 - LOSS: 0.2141 - ACCURACY: 0.9375\n",
      "BATCH 861/1203 - LOSS: 0.0233 - ACCURACY: 1.0000\n",
      "BATCH 881/1203 - LOSS: 0.2884 - ACCURACY: 0.8750\n",
      "BATCH 901/1203 - LOSS: 0.0902 - ACCURACY: 1.0000\n",
      "BATCH 921/1203 - LOSS: 0.0885 - ACCURACY: 1.0000\n",
      "BATCH 941/1203 - LOSS: 0.0952 - ACCURACY: 1.0000\n",
      "BATCH 961/1203 - LOSS: 0.0110 - ACCURACY: 1.0000\n",
      "BATCH 981/1203 - LOSS: 0.0287 - ACCURACY: 1.0000\n",
      "BATCH 1001/1203 - LOSS: 0.1708 - ACCURACY: 0.9375\n",
      "BATCH 1021/1203 - LOSS: 0.0235 - ACCURACY: 1.0000\n",
      "BATCH 1041/1203 - LOSS: 0.1931 - ACCURACY: 0.9375\n",
      "BATCH 1061/1203 - LOSS: 0.0095 - ACCURACY: 1.0000\n",
      "BATCH 1081/1203 - LOSS: 0.0557 - ACCURACY: 1.0000\n",
      "BATCH 1101/1203 - LOSS: 0.0348 - ACCURACY: 1.0000\n",
      "BATCH 1121/1203 - LOSS: 0.0472 - ACCURACY: 1.0000\n",
      "BATCH 1141/1203 - LOSS: 0.0940 - ACCURACY: 1.0000\n",
      "BATCH 1161/1203 - LOSS: 0.0105 - ACCURACY: 1.0000\n",
      "BATCH 1181/1203 - LOSS: 0.1012 - ACCURACY: 0.9375\n",
      "BATCH 1201/1203 - LOSS: 0.1408 - ACCURACY: 0.8750\n",
      "\n",
      "\t[TRAIN] EPOCH15-LOSS:0.14540383219718933,ACCURACY:0.9508001208305359\n",
      "\n",
      "EPOCH15-VALIDATING...\n",
      "\t[VALID] LOSS:0.6326674818992615,ACCURACY:0.8388158082962036\n",
      "\n",
      "Execution time:2:37:54.046786\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "a = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f8739d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T10:22:01.509909Z",
     "iopub.status.busy": "2024-06-05T10:22:01.509047Z",
     "iopub.status.idle": "2024-06-05T10:22:03.569948Z",
     "shell.execute_reply": "2024-06-05T10:22:03.568855Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 2.155501,
     "end_time": "2024-06-05T10:22:03.572056",
     "exception": false,
     "start_time": "2024-06-05T10:22:01.416555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "BEST_MODEL=\"/kaggle/working/best_model.pth\"\n",
    "test_df = pd.read_csv(\"/kaggle/input/cassava-leaf-disease-classification/sample_submission.csv\")\n",
    "transforms_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_dataset = CassavaDataset(test_df, transforms=transforms_test, mode=\"test\")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pretrained_model = ViTBase16(n_classes=5)\n",
    "pretrained_model.load_state_dict(torch.load(BEST_MODEL, map_location=device))\n",
    "pretrained_model =pretrained_model.to(device)\n",
    "pretrained_model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = pretrained_model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        \n",
    "test_df['label'] = predictions\n",
    "\n",
    "# Save to CSV\n",
    "test_df.to_csv(SUBMISSION_FILE, index=False)\n",
    "print(f\"Submission file saved to {SUBMISSION_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bbe73c",
   "metadata": {
    "papermill": {
     "duration": 0.089556,
     "end_time": "2024-06-05T10:22:03.750818",
     "exception": false,
     "start_time": "2024-06-05T10:22:03.661262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d36c97dd",
   "metadata": {
    "papermill": {
     "duration": 0.088362,
     "end_time": "2024-06-05T10:22:03.928899",
     "exception": false,
     "start_time": "2024-06-05T10:22:03.840537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(report)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 加载最好的模型\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mViTBase16\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m best_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(BEST_MODEL))\n\u001b[1;32m     27\u001b[0m best_model \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m, in \u001b[0;36mViTBase16.__init__\u001b[0;34m(self, n_classes, pretrained)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_classes, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28msuper\u001b[39m(ViTBase16, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mtimm\u001b[49m\u001b[38;5;241m.\u001b[39mcreate_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvit_base_patch16_224\u001b[39m\u001b[38;5;124m\"\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pretrained:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(MODEL_PATH))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timm' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def generate_classification_report(model, valid_loader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # 生成分类报告\n",
    "    report = classification_report(all_labels, all_preds, target_names=[str(i) for i in range(5)])\n",
    "    print(\"Classification Report on Validation Set:\")\n",
    "    print(report)\n",
    "\n",
    "# 加载最好的模型\n",
    "best_model = ViTBase16(n_classes=5)\n",
    "best_model.load_state_dict(torch.load(BEST_MODEL))\n",
    "best_model = best_model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# 验证集的数据加载器\n",
    "valid_dataset = CassavaDataset(valid_df, transforms=transforms_valid)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, drop_last=True, num_workers=4)\n",
    "\n",
    "# 生成分类报告\n",
    "generate_classification_report(best_model, valid_loader, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1dd966",
   "metadata": {
    "papermill": {
     "duration": 0.09218,
     "end_time": "2024-06-05T10:22:04.111738",
     "exception": false,
     "start_time": "2024-06-05T10:22:04.019558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 1718836,
     "sourceId": 13836,
     "sourceType": "competition"
    },
    {
     "datasetId": 993628,
     "sourceId": 1677248,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30715,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9522.039423,
   "end_time": "2024-06-05T10:22:07.560664",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-05T07:43:25.521241",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
