{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d6b8f14-2a07-49ae-94f2-1af5e4361e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c389f0f-b28d-4400-a61c-f00642cbf9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f6858b3-1ac7-4277-bff2-549239b741ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general global variables\n",
    "DATA_PATH = \"data/\"\n",
    "TRAIN_PATH = \"data/train_images\"\n",
    "TEST_PATH = \"data/test_images/\"\n",
    "BEST_MODEL = \"weights/Vgg16.pth\"\n",
    "SUBMISSION_FILE = \"submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991d62fa-fb54-41d0-85b6-a2b346e69bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model specific global variables\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "LR = 2e-05\n",
    "N_EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d96ca3-9e6c-4262-8154-2bcf11fb6d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Helper Class to create the pytorch dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, data_path=DATA_PATH, mode=\"train\", transforms=None):\n",
    "        super().__init__()\n",
    "        self.df_data = df.values\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        self.data_dir = \"train_images\" if mode == \"train\" else \"test_images\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name, label = self.df_data[index]\n",
    "        img_path = os.path.join(self.data_path, self.data_dir, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(img)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd59b344-4f59-46cc-ad59-9522197e8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image augmentations\n",
    "transforms_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_valid = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a2f82f7-103a-468e-aa25-4c7aee08c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def train_one_epoch(self, train_loader, criterion, optimizer, device, writer, epoch):\n",
    "        self.train()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_accuracy = 0.0\n",
    "\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = self.forward(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            accuracy = (output.argmax(dim=1) == target).float().mean().item()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_accuracy += accuracy\n",
    "\n",
    "            if i % 20 == 0:\n",
    "                print(f\"BATCH {i+1}/{len(train_loader)} - LOSS: {loss.item():.4f} - ACCURACY: {accuracy:.4f}\")\n",
    "                writer.add_scalar('Training Loss', loss.item(), epoch * len(train_loader) + i)\n",
    "                writer.add_scalar('Training Accuracy', accuracy, epoch * len(train_loader) + i)\n",
    "\n",
    "        return epoch_loss / len(train_loader), epoch_accuracy / len(train_loader)\n",
    "\n",
    "    def valid_one_epoch(self, valid_loader, criterion, device, writer, epoch):\n",
    "        self.eval()\n",
    "        valid_loss = 0.0\n",
    "        valid_accuracy = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in valid_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = self.forward(data)\n",
    "                loss = criterion(output, target)\n",
    "                accuracy = (output.argmax(dim=1) == target).float().mean().item()\n",
    "\n",
    "                valid_loss += loss.item()\n",
    "                valid_accuracy += accuracy\n",
    "\n",
    "            writer.add_scalar('Validation Loss', valid_loss / len(valid_loader), epoch)\n",
    "            writer.add_scalar('Validation Accuracy', valid_accuracy / len(valid_loader), epoch)\n",
    "\n",
    "        return valid_loss / len(valid_loader), valid_accuracy / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7009a36c-15e4-44f9-b980-f470f7e7c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gpu(model, epochs, device, criterion, optimizer, train_loader, valid_loader=None):\n",
    "    writer = SummaryWriter()\n",
    "    valid_loss_min = np.Inf\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        gc.collect()\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"EPOCH {epoch} - TRAINING...\")\n",
    "\n",
    "        train_loss, train_acc = model.train_one_epoch(train_loader, criterion, optimizer, device, writer, epoch)\n",
    "        print(f\"\\n\\t[TRAIN] EPOCH {epoch} - LOSS: {train_loss}, ACCURACY: {train_acc}\\n\")\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        gc.collect()\n",
    "\n",
    "        if valid_loader is not None:\n",
    "            gc.collect()\n",
    "            print(f\"EPOCH {epoch} - VALIDATING...\")\n",
    "            valid_loss, valid_acc = model.valid_one_epoch(valid_loader, criterion, device, writer, epoch)\n",
    "            print(f\"\\t[VALID] LOSS: {valid_loss}, ACCURACY: {valid_acc}\\n\")\n",
    "            valid_losses.append(valid_loss)\n",
    "            valid_accs.append(valid_acc)\n",
    "            gc.collect()\n",
    "\n",
    "            if valid_loss <= valid_loss_min and epoch != 1:\n",
    "                print(f\"Validation loss decreased ({valid_loss_min:.4f} --> {valid_loss:.4f}). Saving model...\")\n",
    "                torch.save(model.state_dict(), BEST_MODEL)\n",
    "                valid_loss_min = valid_loss\n",
    "\n",
    "    writer.close()\n",
    "    return {\n",
    "        \"train_loss\": train_losses,\n",
    "        \"valid_losses\": valid_losses,\n",
    "        \"train_acc\": train_accs,\n",
    "        \"valid_accs\": valid_accs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71e83744-a1a9-481b-8110-bf092998e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "    train_df, test_df = model_selection.train_test_split(df, test_size=0.1, random_state=42, shuffle=True, stratify=df.label.values)\n",
    "    train_df, valid_df = model_selection.train_test_split(train_df, test_size=0.2, random_state=42, shuffle=True, stratify=train_df.label.values)\n",
    "\n",
    "    train_dataset = CassavaDataset(train_df, transforms=transforms_train)\n",
    "    valid_dataset = CassavaDataset(valid_df, transforms=transforms_valid)\n",
    "    test_dataset = CassavaDataset(test_df, transforms=transforms_valid)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, drop_last=True, num_workers=4)\n",
    "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, drop_last=True, num_workers=4)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, drop_last=True, num_workers=4)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    lr = LR\n",
    "    model = VGG16(n_classes=5)\n",
    "    model = model.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training\n",
    "    start_time = datetime.now()\n",
    "    logs = fit_gpu(model=model, epochs=N_EPOCHS, device=device, criterion=criterion, optimizer=optimizer, train_loader=train_loader, valid_loader=valid_loader)\n",
    "    print(f\"Execution time: {datetime.now() - start_time}\")\n",
    "\n",
    "    # Load the best model and evaluate on test set\n",
    "    best_model = VGG16(n_classes=5)\n",
    "    best_model.load_state_dict(torch.load(BEST_MODEL))\n",
    "    best_model = best_model.to(device)\n",
    "    best_model.eval()\n",
    "\n",
    "    test_labels = []\n",
    "    test_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = best_model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "            test_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(test_labels, test_preds, target_names=[str(i) for i in range(5)]))\n",
    "    print(f\"Test Accuracy: {accuracy_score(test_labels, test_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da40b41d-86f9-4187-9612-45da7b0d1b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EPOCH 1 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.6051 - ACCURACY: 0.4688\n",
      "BATCH 21/481 - LOSS: 1.3051 - ACCURACY: 0.5938\n",
      "BATCH 41/481 - LOSS: 1.1499 - ACCURACY: 0.6250\n",
      "BATCH 61/481 - LOSS: 1.2480 - ACCURACY: 0.5938\n",
      "BATCH 81/481 - LOSS: 1.2649 - ACCURACY: 0.5938\n",
      "BATCH 101/481 - LOSS: 1.4714 - ACCURACY: 0.4688\n",
      "BATCH 121/481 - LOSS: 1.1028 - ACCURACY: 0.6562\n",
      "BATCH 141/481 - LOSS: 1.3806 - ACCURACY: 0.4688\n",
      "BATCH 161/481 - LOSS: 1.0701 - ACCURACY: 0.6562\n",
      "BATCH 181/481 - LOSS: 1.5020 - ACCURACY: 0.4062\n",
      "BATCH 201/481 - LOSS: 1.0102 - ACCURACY: 0.6875\n",
      "BATCH 221/481 - LOSS: 1.1543 - ACCURACY: 0.6250\n",
      "BATCH 241/481 - LOSS: 0.9295 - ACCURACY: 0.7188\n",
      "BATCH 261/481 - LOSS: 1.5832 - ACCURACY: 0.4062\n",
      "BATCH 281/481 - LOSS: 1.4400 - ACCURACY: 0.4688\n",
      "BATCH 301/481 - LOSS: 0.9472 - ACCURACY: 0.6875\n",
      "BATCH 321/481 - LOSS: 1.2144 - ACCURACY: 0.5625\n",
      "BATCH 341/481 - LOSS: 1.4225 - ACCURACY: 0.4688\n",
      "BATCH 361/481 - LOSS: 1.1631 - ACCURACY: 0.5938\n",
      "BATCH 381/481 - LOSS: 1.0681 - ACCURACY: 0.6562\n",
      "BATCH 401/481 - LOSS: 1.0434 - ACCURACY: 0.6562\n",
      "BATCH 421/481 - LOSS: 1.0477 - ACCURACY: 0.6562\n",
      "BATCH 441/481 - LOSS: 1.1326 - ACCURACY: 0.5938\n",
      "BATCH 461/481 - LOSS: 0.9898 - ACCURACY: 0.6250\n",
      "BATCH 481/481 - LOSS: 0.9837 - ACCURACY: 0.6875\n",
      "\n",
      "\t[TRAIN] EPOCH 1 - LOSS: 1.1592019321764828, ACCURACY: 0.6188279625779626\n",
      "\n",
      "EPOCH 1 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.0717097530762354, ACCURACY: 0.61796875\n",
      "\n",
      "==================================================\n",
      "EPOCH 2 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.1617 - ACCURACY: 0.5000\n",
      "BATCH 21/481 - LOSS: 1.1279 - ACCURACY: 0.5938\n",
      "BATCH 41/481 - LOSS: 1.0706 - ACCURACY: 0.5938\n",
      "BATCH 61/481 - LOSS: 1.0877 - ACCURACY: 0.6562\n",
      "BATCH 81/481 - LOSS: 1.0184 - ACCURACY: 0.6562\n",
      "BATCH 101/481 - LOSS: 1.2249 - ACCURACY: 0.5312\n",
      "BATCH 121/481 - LOSS: 0.8459 - ACCURACY: 0.6562\n",
      "BATCH 141/481 - LOSS: 1.2482 - ACCURACY: 0.5312\n",
      "BATCH 161/481 - LOSS: 0.9787 - ACCURACY: 0.6875\n",
      "BATCH 181/481 - LOSS: 1.1971 - ACCURACY: 0.5000\n",
      "BATCH 201/481 - LOSS: 0.8588 - ACCURACY: 0.7500\n",
      "BATCH 221/481 - LOSS: 1.0231 - ACCURACY: 0.6250\n",
      "BATCH 241/481 - LOSS: 0.9053 - ACCURACY: 0.7188\n",
      "BATCH 261/481 - LOSS: 1.3188 - ACCURACY: 0.4375\n",
      "BATCH 281/481 - LOSS: 1.2704 - ACCURACY: 0.5000\n",
      "BATCH 301/481 - LOSS: 0.9290 - ACCURACY: 0.6562\n",
      "BATCH 321/481 - LOSS: 1.1212 - ACCURACY: 0.6562\n",
      "BATCH 341/481 - LOSS: 1.2523 - ACCURACY: 0.5000\n",
      "BATCH 361/481 - LOSS: 0.9733 - ACCURACY: 0.6250\n",
      "BATCH 381/481 - LOSS: 0.9074 - ACCURACY: 0.7188\n",
      "BATCH 401/481 - LOSS: 0.8920 - ACCURACY: 0.7188\n",
      "BATCH 421/481 - LOSS: 0.9771 - ACCURACY: 0.5938\n",
      "BATCH 441/481 - LOSS: 1.0161 - ACCURACY: 0.6250\n",
      "BATCH 461/481 - LOSS: 0.9398 - ACCURACY: 0.6250\n",
      "BATCH 481/481 - LOSS: 0.8205 - ACCURACY: 0.6875\n",
      "\n",
      "\t[TRAIN] EPOCH 2 - LOSS: 0.9975200219238622, ACCURACY: 0.6405275467775468\n",
      "\n",
      "EPOCH 2 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.9729427516460418, ACCURACY: 0.6401041666666667\n",
      "\n",
      "Validation loss decreased (inf --> 0.9729). Saving model...\n",
      "==================================================\n",
      "EPOCH 3 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.1148 - ACCURACY: 0.4688\n",
      "BATCH 21/481 - LOSS: 1.0762 - ACCURACY: 0.5625\n",
      "BATCH 41/481 - LOSS: 1.0593 - ACCURACY: 0.6250\n",
      "BATCH 61/481 - LOSS: 1.0206 - ACCURACY: 0.5938\n",
      "BATCH 81/481 - LOSS: 0.9659 - ACCURACY: 0.6250\n",
      "BATCH 101/481 - LOSS: 1.2161 - ACCURACY: 0.5938\n",
      "BATCH 121/481 - LOSS: 0.8292 - ACCURACY: 0.6562\n",
      "BATCH 141/481 - LOSS: 1.2420 - ACCURACY: 0.5000\n",
      "BATCH 161/481 - LOSS: 0.9045 - ACCURACY: 0.7188\n",
      "BATCH 181/481 - LOSS: 1.1655 - ACCURACY: 0.5625\n",
      "BATCH 201/481 - LOSS: 0.8116 - ACCURACY: 0.7500\n",
      "BATCH 221/481 - LOSS: 0.9931 - ACCURACY: 0.6250\n",
      "BATCH 241/481 - LOSS: 0.8769 - ACCURACY: 0.7188\n",
      "BATCH 261/481 - LOSS: 1.1973 - ACCURACY: 0.4688\n",
      "BATCH 281/481 - LOSS: 1.3301 - ACCURACY: 0.5000\n",
      "BATCH 301/481 - LOSS: 0.8890 - ACCURACY: 0.6875\n",
      "BATCH 321/481 - LOSS: 1.1637 - ACCURACY: 0.5938\n",
      "BATCH 341/481 - LOSS: 1.1928 - ACCURACY: 0.5625\n",
      "BATCH 361/481 - LOSS: 0.9722 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.8342 - ACCURACY: 0.7188\n",
      "BATCH 401/481 - LOSS: 0.8529 - ACCURACY: 0.6875\n",
      "BATCH 421/481 - LOSS: 0.9570 - ACCURACY: 0.6562\n",
      "BATCH 441/481 - LOSS: 0.9791 - ACCURACY: 0.6562\n",
      "BATCH 461/481 - LOSS: 0.9507 - ACCURACY: 0.6562\n",
      "BATCH 481/481 - LOSS: 0.7975 - ACCURACY: 0.7188\n",
      "\n",
      "\t[TRAIN] EPOCH 3 - LOSS: 0.9660010801283585, ACCURACY: 0.645010395010395\n",
      "\n",
      "EPOCH 3 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.9538113151987394, ACCURACY: 0.64296875\n",
      "\n",
      "Validation loss decreased (0.9729 --> 0.9538). Saving model...\n",
      "==================================================\n",
      "EPOCH 4 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.1090 - ACCURACY: 0.5000\n",
      "BATCH 21/481 - LOSS: 1.0679 - ACCURACY: 0.5938\n",
      "BATCH 41/481 - LOSS: 1.0868 - ACCURACY: 0.6250\n",
      "BATCH 61/481 - LOSS: 1.0060 - ACCURACY: 0.6875\n",
      "BATCH 81/481 - LOSS: 0.9426 - ACCURACY: 0.5938\n",
      "BATCH 101/481 - LOSS: 1.2503 - ACCURACY: 0.6250\n",
      "BATCH 121/481 - LOSS: 0.8011 - ACCURACY: 0.6875\n",
      "BATCH 141/481 - LOSS: 1.2236 - ACCURACY: 0.5312\n",
      "BATCH 161/481 - LOSS: 0.8732 - ACCURACY: 0.7188\n",
      "BATCH 181/481 - LOSS: 1.1700 - ACCURACY: 0.5312\n",
      "BATCH 201/481 - LOSS: 0.7849 - ACCURACY: 0.7500\n",
      "BATCH 221/481 - LOSS: 0.9823 - ACCURACY: 0.6250\n",
      "BATCH 241/481 - LOSS: 0.8287 - ACCURACY: 0.7188\n",
      "BATCH 261/481 - LOSS: 1.1674 - ACCURACY: 0.5000\n",
      "BATCH 281/481 - LOSS: 1.3526 - ACCURACY: 0.5000\n",
      "BATCH 301/481 - LOSS: 0.9158 - ACCURACY: 0.7188\n",
      "BATCH 321/481 - LOSS: 1.0848 - ACCURACY: 0.5938\n",
      "BATCH 341/481 - LOSS: 1.1714 - ACCURACY: 0.5312\n",
      "BATCH 361/481 - LOSS: 0.9928 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.8282 - ACCURACY: 0.7812\n",
      "BATCH 401/481 - LOSS: 0.8571 - ACCURACY: 0.6250\n",
      "BATCH 421/481 - LOSS: 0.9465 - ACCURACY: 0.6875\n",
      "BATCH 441/481 - LOSS: 0.9303 - ACCURACY: 0.6250\n",
      "BATCH 461/481 - LOSS: 0.9216 - ACCURACY: 0.6875\n",
      "BATCH 481/481 - LOSS: 0.7501 - ACCURACY: 0.6875\n",
      "\n",
      "\t[TRAIN] EPOCH 4 - LOSS: 0.9447392577193136, ACCURACY: 0.6535862785862786\n",
      "\n",
      "EPOCH 4 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.9361940150459608, ACCURACY: 0.6494791666666667\n",
      "\n",
      "Validation loss decreased (0.9538 --> 0.9362). Saving model...\n",
      "==================================================\n",
      "EPOCH 5 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.0825 - ACCURACY: 0.5312\n",
      "BATCH 21/481 - LOSS: 1.0361 - ACCURACY: 0.5938\n",
      "BATCH 41/481 - LOSS: 1.0783 - ACCURACY: 0.6562\n",
      "BATCH 61/481 - LOSS: 0.9910 - ACCURACY: 0.6250\n",
      "BATCH 81/481 - LOSS: 0.9528 - ACCURACY: 0.5938\n",
      "BATCH 101/481 - LOSS: 1.1747 - ACCURACY: 0.6250\n",
      "BATCH 121/481 - LOSS: 0.7974 - ACCURACY: 0.7188\n",
      "BATCH 141/481 - LOSS: 1.2083 - ACCURACY: 0.5000\n",
      "BATCH 161/481 - LOSS: 0.8561 - ACCURACY: 0.7188\n",
      "BATCH 181/481 - LOSS: 1.1517 - ACCURACY: 0.5625\n",
      "BATCH 201/481 - LOSS: 0.7441 - ACCURACY: 0.7500\n",
      "BATCH 221/481 - LOSS: 0.9264 - ACCURACY: 0.6250\n",
      "BATCH 241/481 - LOSS: 0.8476 - ACCURACY: 0.7500\n",
      "BATCH 261/481 - LOSS: 1.1088 - ACCURACY: 0.5000\n",
      "BATCH 281/481 - LOSS: 1.4000 - ACCURACY: 0.5312\n",
      "BATCH 301/481 - LOSS: 0.8506 - ACCURACY: 0.7188\n",
      "BATCH 321/481 - LOSS: 1.0505 - ACCURACY: 0.5938\n",
      "BATCH 341/481 - LOSS: 1.1333 - ACCURACY: 0.5625\n",
      "BATCH 361/481 - LOSS: 0.9973 - ACCURACY: 0.6562\n",
      "BATCH 381/481 - LOSS: 0.8394 - ACCURACY: 0.7500\n",
      "BATCH 401/481 - LOSS: 0.8176 - ACCURACY: 0.6562\n",
      "BATCH 421/481 - LOSS: 0.9338 - ACCURACY: 0.6875\n",
      "BATCH 441/481 - LOSS: 0.8917 - ACCURACY: 0.6250\n",
      "BATCH 461/481 - LOSS: 0.9145 - ACCURACY: 0.6250\n",
      "BATCH 481/481 - LOSS: 0.7073 - ACCURACY: 0.6875\n",
      "\n",
      "\t[TRAIN] EPOCH 5 - LOSS: 0.9250152620976779, ACCURACY: 0.6584589397089398\n",
      "\n",
      "EPOCH 5 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.9194374854365984, ACCURACY: 0.65546875\n",
      "\n",
      "Validation loss decreased (0.9362 --> 0.9194). Saving model...\n",
      "==================================================\n",
      "EPOCH 6 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.0469 - ACCURACY: 0.5312\n",
      "BATCH 21/481 - LOSS: 1.0429 - ACCURACY: 0.5938\n",
      "BATCH 41/481 - LOSS: 1.0612 - ACCURACY: 0.6875\n",
      "BATCH 61/481 - LOSS: 0.9747 - ACCURACY: 0.6250\n",
      "BATCH 81/481 - LOSS: 0.9241 - ACCURACY: 0.5938\n",
      "BATCH 101/481 - LOSS: 1.1254 - ACCURACY: 0.6875\n",
      "BATCH 121/481 - LOSS: 0.7771 - ACCURACY: 0.7188\n",
      "BATCH 141/481 - LOSS: 1.1345 - ACCURACY: 0.5625\n",
      "BATCH 161/481 - LOSS: 0.8016 - ACCURACY: 0.7188\n",
      "BATCH 181/481 - LOSS: 1.1780 - ACCURACY: 0.5625\n",
      "BATCH 201/481 - LOSS: 0.7396 - ACCURACY: 0.7500\n",
      "BATCH 221/481 - LOSS: 0.9352 - ACCURACY: 0.6250\n",
      "BATCH 241/481 - LOSS: 0.7930 - ACCURACY: 0.7500\n",
      "BATCH 261/481 - LOSS: 1.0875 - ACCURACY: 0.5312\n",
      "BATCH 281/481 - LOSS: 1.4426 - ACCURACY: 0.5625\n",
      "BATCH 301/481 - LOSS: 0.8542 - ACCURACY: 0.7188\n",
      "BATCH 321/481 - LOSS: 0.9763 - ACCURACY: 0.5938\n",
      "BATCH 341/481 - LOSS: 1.1004 - ACCURACY: 0.5000\n",
      "BATCH 361/481 - LOSS: 0.9777 - ACCURACY: 0.6250\n",
      "BATCH 381/481 - LOSS: 0.8667 - ACCURACY: 0.7500\n",
      "BATCH 401/481 - LOSS: 0.7870 - ACCURACY: 0.6562\n",
      "BATCH 421/481 - LOSS: 0.9232 - ACCURACY: 0.6562\n",
      "BATCH 441/481 - LOSS: 0.8258 - ACCURACY: 0.6875\n",
      "BATCH 461/481 - LOSS: 0.8322 - ACCURACY: 0.6250\n",
      "BATCH 481/481 - LOSS: 0.6871 - ACCURACY: 0.7812\n",
      "\n",
      "\t[TRAIN] EPOCH 6 - LOSS: 0.9019310039442938, ACCURACY: 0.6656704781704782\n",
      "\n",
      "EPOCH 6 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.9339962358276049, ACCURACY: 0.64609375\n",
      "\n",
      "==================================================\n",
      "EPOCH 7 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.0286 - ACCURACY: 0.4688\n",
      "BATCH 21/481 - LOSS: 1.0003 - ACCURACY: 0.6562\n",
      "BATCH 41/481 - LOSS: 1.0155 - ACCURACY: 0.6875\n",
      "BATCH 61/481 - LOSS: 1.0008 - ACCURACY: 0.6562\n",
      "BATCH 81/481 - LOSS: 0.9308 - ACCURACY: 0.6562\n",
      "BATCH 101/481 - LOSS: 1.0084 - ACCURACY: 0.6562\n",
      "BATCH 121/481 - LOSS: 0.7347 - ACCURACY: 0.7188\n",
      "BATCH 141/481 - LOSS: 1.0244 - ACCURACY: 0.5938\n",
      "BATCH 161/481 - LOSS: 0.7648 - ACCURACY: 0.7188\n",
      "BATCH 181/481 - LOSS: 1.1719 - ACCURACY: 0.5625\n",
      "BATCH 201/481 - LOSS: 0.6956 - ACCURACY: 0.7500\n",
      "BATCH 221/481 - LOSS: 0.9020 - ACCURACY: 0.6562\n",
      "BATCH 241/481 - LOSS: 0.7495 - ACCURACY: 0.7500\n",
      "BATCH 261/481 - LOSS: 1.0692 - ACCURACY: 0.5312\n",
      "BATCH 281/481 - LOSS: 1.4104 - ACCURACY: 0.5312\n",
      "BATCH 301/481 - LOSS: 0.7562 - ACCURACY: 0.7188\n",
      "BATCH 321/481 - LOSS: 0.8644 - ACCURACY: 0.6250\n",
      "BATCH 341/481 - LOSS: 1.0302 - ACCURACY: 0.5312\n",
      "BATCH 361/481 - LOSS: 0.9396 - ACCURACY: 0.6562\n",
      "BATCH 381/481 - LOSS: 0.9459 - ACCURACY: 0.6250\n",
      "BATCH 401/481 - LOSS: 0.7483 - ACCURACY: 0.6875\n",
      "BATCH 421/481 - LOSS: 0.8879 - ACCURACY: 0.6562\n",
      "BATCH 441/481 - LOSS: 0.7307 - ACCURACY: 0.6875\n",
      "BATCH 461/481 - LOSS: 0.8428 - ACCURACY: 0.5938\n",
      "BATCH 481/481 - LOSS: 0.6443 - ACCURACY: 0.8125\n",
      "\n",
      "\t[TRAIN] EPOCH 7 - LOSS: 0.8691245065285609, ACCURACY: 0.675545738045738\n",
      "\n",
      "EPOCH 7 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.9167925402522087, ACCURACY: 0.6536458333333334\n",
      "\n",
      "Validation loss decreased (0.9194 --> 0.9168). Saving model...\n",
      "==================================================\n",
      "EPOCH 8 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.0449 - ACCURACY: 0.5000\n",
      "BATCH 21/481 - LOSS: 0.9373 - ACCURACY: 0.6250\n",
      "BATCH 41/481 - LOSS: 1.0490 - ACCURACY: 0.6875\n",
      "BATCH 61/481 - LOSS: 0.9474 - ACCURACY: 0.6875\n",
      "BATCH 81/481 - LOSS: 0.8982 - ACCURACY: 0.6562\n",
      "BATCH 101/481 - LOSS: 0.9219 - ACCURACY: 0.6562\n",
      "BATCH 121/481 - LOSS: 0.7764 - ACCURACY: 0.7188\n",
      "BATCH 141/481 - LOSS: 0.9063 - ACCURACY: 0.5625\n",
      "BATCH 161/481 - LOSS: 0.6879 - ACCURACY: 0.7812\n",
      "BATCH 181/481 - LOSS: 1.1547 - ACCURACY: 0.5938\n",
      "BATCH 201/481 - LOSS: 0.6262 - ACCURACY: 0.7500\n",
      "BATCH 221/481 - LOSS: 0.8425 - ACCURACY: 0.6250\n",
      "BATCH 241/481 - LOSS: 0.7285 - ACCURACY: 0.7500\n",
      "BATCH 261/481 - LOSS: 1.0301 - ACCURACY: 0.6250\n",
      "BATCH 281/481 - LOSS: 1.4722 - ACCURACY: 0.5625\n",
      "BATCH 301/481 - LOSS: 0.7216 - ACCURACY: 0.7500\n",
      "BATCH 321/481 - LOSS: 0.7990 - ACCURACY: 0.6562\n",
      "BATCH 341/481 - LOSS: 1.0145 - ACCURACY: 0.5312\n",
      "BATCH 361/481 - LOSS: 0.8209 - ACCURACY: 0.7188\n",
      "BATCH 381/481 - LOSS: 1.0241 - ACCURACY: 0.6250\n",
      "BATCH 401/481 - LOSS: 0.6446 - ACCURACY: 0.7500\n",
      "BATCH 421/481 - LOSS: 0.8080 - ACCURACY: 0.6875\n",
      "BATCH 441/481 - LOSS: 0.7239 - ACCURACY: 0.7188\n",
      "BATCH 461/481 - LOSS: 0.8310 - ACCURACY: 0.5938\n",
      "BATCH 481/481 - LOSS: 0.5595 - ACCURACY: 0.8125\n",
      "\n",
      "\t[TRAIN] EPOCH 8 - LOSS: 0.8276311400774363, ACCURACY: 0.6868503118503119\n",
      "\n",
      "EPOCH 8 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.8320613702138265, ACCURACY: 0.6877604166666667\n",
      "\n",
      "Validation loss decreased (0.9168 --> 0.8321). Saving model...\n",
      "==================================================\n",
      "EPOCH 9 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.0057 - ACCURACY: 0.5938\n",
      "BATCH 21/481 - LOSS: 0.8645 - ACCURACY: 0.6562\n",
      "BATCH 41/481 - LOSS: 0.9118 - ACCURACY: 0.7500\n",
      "BATCH 61/481 - LOSS: 0.9049 - ACCURACY: 0.5938\n",
      "BATCH 81/481 - LOSS: 0.7798 - ACCURACY: 0.6562\n",
      "BATCH 101/481 - LOSS: 0.9175 - ACCURACY: 0.6562\n",
      "BATCH 121/481 - LOSS: 0.7599 - ACCURACY: 0.7188\n",
      "BATCH 141/481 - LOSS: 0.9987 - ACCURACY: 0.5312\n",
      "BATCH 161/481 - LOSS: 0.6401 - ACCURACY: 0.7500\n",
      "BATCH 181/481 - LOSS: 1.0903 - ACCURACY: 0.5938\n",
      "BATCH 201/481 - LOSS: 0.5316 - ACCURACY: 0.8125\n",
      "BATCH 221/481 - LOSS: 0.7766 - ACCURACY: 0.6562\n",
      "BATCH 241/481 - LOSS: 0.6743 - ACCURACY: 0.7812\n",
      "BATCH 261/481 - LOSS: 1.0070 - ACCURACY: 0.6875\n",
      "BATCH 281/481 - LOSS: 1.3625 - ACCURACY: 0.5000\n",
      "BATCH 301/481 - LOSS: 0.7528 - ACCURACY: 0.7500\n",
      "BATCH 321/481 - LOSS: 0.7608 - ACCURACY: 0.7188\n",
      "BATCH 341/481 - LOSS: 0.9601 - ACCURACY: 0.5312\n",
      "BATCH 361/481 - LOSS: 0.8185 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.9638 - ACCURACY: 0.6562\n",
      "BATCH 401/481 - LOSS: 0.6807 - ACCURACY: 0.7812\n",
      "BATCH 421/481 - LOSS: 0.7627 - ACCURACY: 0.6875\n",
      "BATCH 441/481 - LOSS: 0.6963 - ACCURACY: 0.7188\n",
      "BATCH 461/481 - LOSS: 0.7781 - ACCURACY: 0.5938\n",
      "BATCH 481/481 - LOSS: 0.6306 - ACCURACY: 0.7812\n",
      "\n",
      "\t[TRAIN] EPOCH 9 - LOSS: 0.793531242254618, ACCURACY: 0.6954261954261954\n",
      "\n",
      "EPOCH 9 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.8172223411500454, ACCURACY: 0.6893229166666667\n",
      "\n",
      "Validation loss decreased (0.8321 --> 0.8172). Saving model...\n",
      "==================================================\n",
      "EPOCH 10 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.0528 - ACCURACY: 0.5938\n",
      "BATCH 21/481 - LOSS: 0.8719 - ACCURACY: 0.7188\n",
      "BATCH 41/481 - LOSS: 0.9188 - ACCURACY: 0.7500\n",
      "BATCH 61/481 - LOSS: 0.8776 - ACCURACY: 0.6250\n",
      "BATCH 81/481 - LOSS: 0.8232 - ACCURACY: 0.6250\n",
      "BATCH 101/481 - LOSS: 0.9333 - ACCURACY: 0.6562\n",
      "BATCH 121/481 - LOSS: 0.7748 - ACCURACY: 0.7188\n",
      "BATCH 141/481 - LOSS: 0.9577 - ACCURACY: 0.5625\n",
      "BATCH 161/481 - LOSS: 0.6214 - ACCURACY: 0.7500\n",
      "BATCH 181/481 - LOSS: 0.9903 - ACCURACY: 0.6562\n",
      "BATCH 201/481 - LOSS: 0.5018 - ACCURACY: 0.7812\n",
      "BATCH 221/481 - LOSS: 0.7342 - ACCURACY: 0.6562\n",
      "BATCH 241/481 - LOSS: 0.6058 - ACCURACY: 0.8438\n",
      "BATCH 261/481 - LOSS: 0.9887 - ACCURACY: 0.6250\n",
      "BATCH 281/481 - LOSS: 1.1988 - ACCURACY: 0.5000\n",
      "BATCH 301/481 - LOSS: 0.7244 - ACCURACY: 0.7188\n",
      "BATCH 321/481 - LOSS: 0.6800 - ACCURACY: 0.7188\n",
      "BATCH 341/481 - LOSS: 0.9898 - ACCURACY: 0.5625\n",
      "BATCH 361/481 - LOSS: 0.8607 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.8758 - ACCURACY: 0.7500\n",
      "BATCH 401/481 - LOSS: 0.6779 - ACCURACY: 0.7500\n",
      "BATCH 421/481 - LOSS: 0.7067 - ACCURACY: 0.6875\n",
      "BATCH 441/481 - LOSS: 0.7051 - ACCURACY: 0.7188\n",
      "BATCH 461/481 - LOSS: 0.6969 - ACCURACY: 0.7188\n",
      "BATCH 481/481 - LOSS: 0.6022 - ACCURACY: 0.8125\n",
      "\n",
      "\t[TRAIN] EPOCH 10 - LOSS: 0.7699505339169452, ACCURACY: 0.7036122661122661\n",
      "\n",
      "EPOCH 10 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.7933796408275763, ACCURACY: 0.7\n",
      "\n",
      "Validation loss decreased (0.8172 --> 0.7934). Saving model...\n",
      "==================================================\n",
      "EPOCH 11 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.0071 - ACCURACY: 0.6250\n",
      "BATCH 21/481 - LOSS: 0.8078 - ACCURACY: 0.6875\n",
      "BATCH 41/481 - LOSS: 0.8706 - ACCURACY: 0.7500\n",
      "BATCH 61/481 - LOSS: 0.8511 - ACCURACY: 0.6875\n",
      "BATCH 81/481 - LOSS: 0.8453 - ACCURACY: 0.6250\n",
      "BATCH 101/481 - LOSS: 0.9094 - ACCURACY: 0.6562\n",
      "BATCH 121/481 - LOSS: 0.7549 - ACCURACY: 0.7188\n",
      "BATCH 141/481 - LOSS: 0.9365 - ACCURACY: 0.5000\n",
      "BATCH 161/481 - LOSS: 0.5956 - ACCURACY: 0.8125\n",
      "BATCH 181/481 - LOSS: 0.9270 - ACCURACY: 0.7188\n",
      "BATCH 201/481 - LOSS: 0.4504 - ACCURACY: 0.8125\n",
      "BATCH 221/481 - LOSS: 0.7363 - ACCURACY: 0.6562\n",
      "BATCH 241/481 - LOSS: 0.6041 - ACCURACY: 0.7812\n",
      "BATCH 261/481 - LOSS: 1.0311 - ACCURACY: 0.6562\n",
      "BATCH 281/481 - LOSS: 1.1746 - ACCURACY: 0.5312\n",
      "BATCH 301/481 - LOSS: 0.7610 - ACCURACY: 0.7500\n",
      "BATCH 321/481 - LOSS: 0.6895 - ACCURACY: 0.7188\n",
      "BATCH 341/481 - LOSS: 0.9710 - ACCURACY: 0.5625\n",
      "BATCH 361/481 - LOSS: 0.8126 - ACCURACY: 0.6562\n",
      "BATCH 381/481 - LOSS: 0.7808 - ACCURACY: 0.6562\n",
      "BATCH 401/481 - LOSS: 0.6389 - ACCURACY: 0.7500\n",
      "BATCH 421/481 - LOSS: 0.6874 - ACCURACY: 0.6562\n",
      "BATCH 441/481 - LOSS: 0.6533 - ACCURACY: 0.8438\n",
      "BATCH 461/481 - LOSS: 0.6747 - ACCURACY: 0.7500\n",
      "BATCH 481/481 - LOSS: 0.6130 - ACCURACY: 0.8125\n",
      "\n",
      "\t[TRAIN] EPOCH 11 - LOSS: 0.7481940210856916, ACCURACY: 0.7127728690228691\n",
      "\n",
      "EPOCH 11 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.8063288606703282, ACCURACY: 0.7013020833333333\n",
      "\n",
      "==================================================\n",
      "EPOCH 12 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.0470 - ACCURACY: 0.5938\n",
      "BATCH 21/481 - LOSS: 0.7717 - ACCURACY: 0.6875\n",
      "BATCH 41/481 - LOSS: 0.7669 - ACCURACY: 0.7812\n",
      "BATCH 61/481 - LOSS: 0.8203 - ACCURACY: 0.6562\n",
      "BATCH 81/481 - LOSS: 0.8782 - ACCURACY: 0.6562\n",
      "BATCH 101/481 - LOSS: 0.9497 - ACCURACY: 0.6250\n",
      "BATCH 121/481 - LOSS: 0.6784 - ACCURACY: 0.7188\n",
      "BATCH 141/481 - LOSS: 0.8797 - ACCURACY: 0.6250\n",
      "BATCH 161/481 - LOSS: 0.5666 - ACCURACY: 0.8125\n",
      "BATCH 181/481 - LOSS: 0.8867 - ACCURACY: 0.6562\n",
      "BATCH 201/481 - LOSS: 0.4585 - ACCURACY: 0.8438\n",
      "BATCH 221/481 - LOSS: 0.7142 - ACCURACY: 0.6562\n",
      "BATCH 241/481 - LOSS: 0.5963 - ACCURACY: 0.7812\n",
      "BATCH 261/481 - LOSS: 1.0115 - ACCURACY: 0.6875\n",
      "BATCH 281/481 - LOSS: 1.1120 - ACCURACY: 0.5625\n",
      "BATCH 301/481 - LOSS: 0.7331 - ACCURACY: 0.7188\n",
      "BATCH 321/481 - LOSS: 0.6763 - ACCURACY: 0.7500\n",
      "BATCH 341/481 - LOSS: 0.9833 - ACCURACY: 0.5625\n",
      "BATCH 361/481 - LOSS: 0.8005 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.7558 - ACCURACY: 0.6875\n",
      "BATCH 401/481 - LOSS: 0.6402 - ACCURACY: 0.7500\n",
      "BATCH 421/481 - LOSS: 0.6605 - ACCURACY: 0.6875\n",
      "BATCH 441/481 - LOSS: 0.6691 - ACCURACY: 0.7812\n",
      "BATCH 461/481 - LOSS: 0.6165 - ACCURACY: 0.7500\n",
      "BATCH 481/481 - LOSS: 0.6030 - ACCURACY: 0.8125\n",
      "\n",
      "\t[TRAIN] EPOCH 12 - LOSS: 0.7288815830204938, ACCURACY: 0.7228430353430353\n",
      "\n",
      "EPOCH 12 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.8071742075184981, ACCURACY: 0.703125\n",
      "\n",
      "==================================================\n",
      "EPOCH 13 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.0372 - ACCURACY: 0.5625\n",
      "BATCH 21/481 - LOSS: 0.7642 - ACCURACY: 0.6562\n",
      "BATCH 41/481 - LOSS: 0.8295 - ACCURACY: 0.7188\n",
      "BATCH 61/481 - LOSS: 0.7750 - ACCURACY: 0.6562\n",
      "BATCH 81/481 - LOSS: 0.9045 - ACCURACY: 0.6250\n",
      "BATCH 101/481 - LOSS: 0.9008 - ACCURACY: 0.7188\n",
      "BATCH 121/481 - LOSS: 0.6756 - ACCURACY: 0.7500\n",
      "BATCH 141/481 - LOSS: 0.8438 - ACCURACY: 0.6562\n",
      "BATCH 161/481 - LOSS: 0.5212 - ACCURACY: 0.8438\n",
      "BATCH 181/481 - LOSS: 0.8777 - ACCURACY: 0.7500\n",
      "BATCH 201/481 - LOSS: 0.4408 - ACCURACY: 0.8125\n",
      "BATCH 221/481 - LOSS: 0.6855 - ACCURACY: 0.6875\n",
      "BATCH 241/481 - LOSS: 0.5479 - ACCURACY: 0.8438\n",
      "BATCH 261/481 - LOSS: 0.9870 - ACCURACY: 0.6875\n",
      "BATCH 281/481 - LOSS: 1.0341 - ACCURACY: 0.5625\n",
      "BATCH 301/481 - LOSS: 0.7169 - ACCURACY: 0.7500\n",
      "BATCH 321/481 - LOSS: 0.6669 - ACCURACY: 0.7500\n",
      "BATCH 341/481 - LOSS: 0.9561 - ACCURACY: 0.5938\n",
      "BATCH 361/481 - LOSS: 0.7986 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.7221 - ACCURACY: 0.7188\n",
      "BATCH 401/481 - LOSS: 0.6608 - ACCURACY: 0.7500\n",
      "BATCH 421/481 - LOSS: 0.6351 - ACCURACY: 0.6875\n",
      "BATCH 441/481 - LOSS: 0.6472 - ACCURACY: 0.7812\n",
      "BATCH 461/481 - LOSS: 0.5936 - ACCURACY: 0.7500\n",
      "BATCH 481/481 - LOSS: 0.5284 - ACCURACY: 0.8438\n",
      "\n",
      "\t[TRAIN] EPOCH 13 - LOSS: 0.7106083260380552, ACCURACY: 0.7306392931392931\n",
      "\n",
      "EPOCH 13 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.7882393260796865, ACCURACY: 0.70859375\n",
      "\n",
      "Validation loss decreased (0.7934 --> 0.7882). Saving model...\n",
      "==================================================\n",
      "EPOCH 14 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.0304 - ACCURACY: 0.5625\n",
      "BATCH 21/481 - LOSS: 0.7067 - ACCURACY: 0.7812\n",
      "BATCH 41/481 - LOSS: 0.7238 - ACCURACY: 0.7500\n",
      "BATCH 61/481 - LOSS: 0.7631 - ACCURACY: 0.6875\n",
      "BATCH 81/481 - LOSS: 0.8734 - ACCURACY: 0.6562\n",
      "BATCH 101/481 - LOSS: 0.9293 - ACCURACY: 0.6562\n",
      "BATCH 121/481 - LOSS: 0.6489 - ACCURACY: 0.7500\n",
      "BATCH 141/481 - LOSS: 0.8683 - ACCURACY: 0.6875\n",
      "BATCH 161/481 - LOSS: 0.5055 - ACCURACY: 0.8125\n",
      "BATCH 181/481 - LOSS: 0.8566 - ACCURACY: 0.7188\n",
      "BATCH 201/481 - LOSS: 0.4053 - ACCURACY: 0.8438\n",
      "BATCH 221/481 - LOSS: 0.6920 - ACCURACY: 0.6875\n",
      "BATCH 241/481 - LOSS: 0.5529 - ACCURACY: 0.8438\n",
      "BATCH 261/481 - LOSS: 0.9455 - ACCURACY: 0.7188\n",
      "BATCH 281/481 - LOSS: 0.9712 - ACCURACY: 0.6875\n",
      "BATCH 301/481 - LOSS: 0.6617 - ACCURACY: 0.7188\n",
      "BATCH 321/481 - LOSS: 0.6032 - ACCURACY: 0.8125\n",
      "BATCH 341/481 - LOSS: 0.9668 - ACCURACY: 0.5000\n",
      "BATCH 361/481 - LOSS: 0.8370 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.7160 - ACCURACY: 0.6875\n",
      "BATCH 401/481 - LOSS: 0.6600 - ACCURACY: 0.7188\n",
      "BATCH 421/481 - LOSS: 0.6127 - ACCURACY: 0.6875\n",
      "BATCH 441/481 - LOSS: 0.7036 - ACCURACY: 0.7812\n",
      "BATCH 461/481 - LOSS: 0.5111 - ACCURACY: 0.8125\n",
      "BATCH 481/481 - LOSS: 0.5208 - ACCURACY: 0.8125\n",
      "\n",
      "\t[TRAIN] EPOCH 14 - LOSS: 0.6901162543688395, ACCURACY: 0.7394750519750519\n",
      "\n",
      "EPOCH 14 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.782077622661988, ACCURACY: 0.7151041666666667\n",
      "\n",
      "Validation loss decreased (0.7882 --> 0.7821). Saving model...\n",
      "==================================================\n",
      "EPOCH 15 - TRAINING...\n",
      "BATCH 1/481 - LOSS: 0.9431 - ACCURACY: 0.6562\n",
      "BATCH 21/481 - LOSS: 0.6519 - ACCURACY: 0.7188\n",
      "BATCH 41/481 - LOSS: 0.7844 - ACCURACY: 0.7812\n",
      "BATCH 61/481 - LOSS: 0.7311 - ACCURACY: 0.6875\n",
      "BATCH 81/481 - LOSS: 0.8403 - ACCURACY: 0.7188\n",
      "BATCH 101/481 - LOSS: 0.8498 - ACCURACY: 0.7500\n",
      "BATCH 121/481 - LOSS: 0.6126 - ACCURACY: 0.7812\n",
      "BATCH 141/481 - LOSS: 0.7830 - ACCURACY: 0.6250\n",
      "BATCH 161/481 - LOSS: 0.4875 - ACCURACY: 0.8125\n",
      "BATCH 181/481 - LOSS: 0.7611 - ACCURACY: 0.8125\n",
      "BATCH 201/481 - LOSS: 0.3956 - ACCURACY: 0.8438\n",
      "BATCH 221/481 - LOSS: 0.6926 - ACCURACY: 0.6875\n",
      "BATCH 241/481 - LOSS: 0.5357 - ACCURACY: 0.8438\n",
      "BATCH 261/481 - LOSS: 0.9388 - ACCURACY: 0.7188\n",
      "BATCH 281/481 - LOSS: 0.9370 - ACCURACY: 0.6875\n",
      "BATCH 301/481 - LOSS: 0.6664 - ACCURACY: 0.7188\n",
      "BATCH 321/481 - LOSS: 0.6195 - ACCURACY: 0.7812\n",
      "BATCH 341/481 - LOSS: 0.9582 - ACCURACY: 0.6562\n",
      "BATCH 361/481 - LOSS: 0.7815 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.6732 - ACCURACY: 0.6875\n",
      "BATCH 401/481 - LOSS: 0.6664 - ACCURACY: 0.7188\n",
      "BATCH 421/481 - LOSS: 0.5552 - ACCURACY: 0.7500\n",
      "BATCH 441/481 - LOSS: 0.6517 - ACCURACY: 0.7812\n",
      "BATCH 461/481 - LOSS: 0.4934 - ACCURACY: 0.8438\n",
      "BATCH 481/481 - LOSS: 0.5299 - ACCURACY: 0.8125\n",
      "\n",
      "\t[TRAIN] EPOCH 15 - LOSS: 0.6713684577951808, ACCURACY: 0.7462318087318087\n",
      "\n",
      "EPOCH 15 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.7720598481595516, ACCURACY: 0.7184895833333333\n",
      "\n",
      "Validation loss decreased (0.7821 --> 0.7721). Saving model...\n",
      "Execution time: 0:21:49.735521\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.27      0.31       108\n",
      "           1       0.48      0.45      0.46       214\n",
      "           2       0.46      0.36      0.40       237\n",
      "           3       0.83      0.96      0.89      1299\n",
      "           4       0.49      0.27      0.35       254\n",
      "\n",
      "    accuracy                           0.72      2112\n",
      "   macro avg       0.52      0.46      0.48      2112\n",
      "weighted avg       0.69      0.72      0.70      2112\n",
      "\n",
      "Test Accuracy: 0.7220643939393939\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "a = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107f6176-b562-434c-9b92-32be1324b84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
