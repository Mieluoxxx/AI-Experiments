{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af56b29f",
   "metadata": {
    "papermill": {
     "duration": 8.558093,
     "end_time": "2024-06-05T09:44:29.366106",
     "exception": false,
     "start_time": "2024-06-05T09:44:20.808013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3d7465f",
   "metadata": {
    "papermill": {
     "duration": 0.013764,
     "end_time": "2024-06-05T09:44:29.382833",
     "exception": false,
     "start_time": "2024-06-05T09:44:29.369069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e0df23b",
   "metadata": {
    "papermill": {
     "duration": 0.00919,
     "end_time": "2024-06-05T09:44:29.394487",
     "exception": false,
     "start_time": "2024-06-05T09:44:29.385297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# general global variables\n",
    "DATA_PATH = \"data/\"\n",
    "TRAIN_PATH = \"data/train_images\"\n",
    "TEST_PATH = \"data/test_images/\"\n",
    "BEST_MODEL = \"ResNet16.pth\"\n",
    "SUBMISSION_FILE = \"submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b528b59",
   "metadata": {
    "papermill": {
     "duration": 0.008884,
     "end_time": "2024-06-05T09:44:29.405883",
     "exception": false,
     "start_time": "2024-06-05T09:44:29.396999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model specific global variables\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "LR = 2e-05\n",
    "N_EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52301264-07c8-4e23-ad26-6716ab80c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Helper Class to create the pytorch dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, data_path=DATA_PATH, mode=\"train\", transforms=None):\n",
    "        super().__init__()\n",
    "        self.df_data = df.values\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        self.data_dir = \"train_images\" if mode == \"train\" else \"test_images\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name, label = self.df_data[index]\n",
    "        img_path = os.path.join(self.data_path, self.data_dir, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(img)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# create image augmentations\n",
    "transforms_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_valid = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet16(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(ResNet16, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(64, 2)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(BasicBlock(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock(out_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def train_one_epoch(self, train_loader, criterion, optimizer, device, writer, epoch):\n",
    "        self.train()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_accuracy = 0.0\n",
    "\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = self.forward(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            accuracy = (output.argmax(dim=1) == target).float().mean().item()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_accuracy += accuracy\n",
    "\n",
    "            if i % 20 == 0:\n",
    "                print(f\"BATCH {i+1}/{len(train_loader)} - LOSS: {loss.item():.4f} - ACCURACY: {accuracy:.4f}\")\n",
    "                writer.add_scalar('Training Loss', loss.item(), epoch * len(train_loader) + i)\n",
    "                writer.add_scalar('Training Accuracy', accuracy, epoch * len(train_loader) + i)\n",
    "\n",
    "        return epoch_loss / len(train_loader), epoch_accuracy / len(train_loader)\n",
    "\n",
    "    def valid_one_epoch(self, valid_loader, criterion, device, writer, epoch):\n",
    "        self.eval()\n",
    "        valid_loss = 0.0\n",
    "        valid_accuracy = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in valid_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = self.forward(data)\n",
    "                loss = criterion(output, target)\n",
    "                accuracy = (output.argmax(dim=1) == target).float().mean().item()\n",
    "\n",
    "                valid_loss += loss.item()\n",
    "                valid_accuracy += accuracy\n",
    "\n",
    "            writer.add_scalar('Validation Loss', valid_loss / len(valid_loader), epoch)\n",
    "            writer.add_scalar('Validation Accuracy', valid_accuracy / len(valid_loader), epoch)\n",
    "\n",
    "        return valid_loss / len(valid_loader), valid_accuracy / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28979bfd",
   "metadata": {
    "papermill": {
     "duration": 13.039953,
     "end_time": "2024-06-05T09:44:42.448391",
     "exception": false,
     "start_time": "2024-06-05T09:44:29.408438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_gpu(model, epochs, device, criterion, optimizer, train_loader, valid_loader=None):\n",
    "    writer = SummaryWriter()\n",
    "    valid_loss_min = np.Inf\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        gc.collect()\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"EPOCH {epoch} - TRAINING...\")\n",
    "\n",
    "        train_loss, train_acc = model.train_one_epoch(train_loader, criterion, optimizer, device, writer, epoch)\n",
    "        print(f\"\\n\\t[TRAIN] EPOCH {epoch} - LOSS: {train_loss}, ACCURACY: {train_acc}\\n\")\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        gc.collect()\n",
    "\n",
    "        if valid_loader is not None:\n",
    "            gc.collect()\n",
    "            print(f\"EPOCH {epoch} - VALIDATING...\")\n",
    "            valid_loss, valid_acc = model.valid_one_epoch(valid_loader, criterion, device, writer, epoch)\n",
    "            print(f\"\\t[VALID] LOSS: {valid_loss}, ACCURACY: {valid_acc}\\n\")\n",
    "            valid_losses.append(valid_loss)\n",
    "            valid_accs.append(valid_acc)\n",
    "            gc.collect()\n",
    "\n",
    "            if valid_loss <= valid_loss_min and epoch != 1:\n",
    "                print(f\"Validation loss decreased ({valid_loss_min:.4f} --> {valid_loss:.4f}). Saving model...\")\n",
    "                torch.save(model.state_dict(), BEST_MODEL)\n",
    "                valid_loss_min = valid_loss\n",
    "\n",
    "    writer.close()\n",
    "    return {\n",
    "        \"train_loss\": train_losses,\n",
    "        \"valid_losses\": valid_losses,\n",
    "        \"train_acc\": train_accs,\n",
    "        \"valid_accs\": valid_accs,\n",
    "    }\n",
    "\n",
    "def run():\n",
    "    df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "    train_df, test_df = model_selection.train_test_split(df, test_size=0.1, random_state=42, shuffle=True, stratify=df.label.values)\n",
    "    train_df, valid_df = model_selection.train_test_split(train_df, test_size=0.2, random_state=42, shuffle=True, stratify=train_df.label.values)\n",
    "\n",
    "    train_dataset = CassavaDataset(train_df, transforms=transforms_train)\n",
    "    valid_dataset = CassavaDataset(valid_df, transforms=transforms_valid)\n",
    "    test_dataset = CassavaDataset(test_df, transforms=transforms_valid)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, drop_last=True, num_workers=4)\n",
    "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, drop_last=True, num_workers=4)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, drop_last=True, num_workers=4)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    lr = LR\n",
    "    model = ResNet16(num_classes=5)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    logs = fit_gpu(model=model, epochs=N_EPOCHS, device=device, criterion=criterion, optimizer=optimizer, train_loader=train_loader, valid_loader=valid_loader)\n",
    "    print(f\"Execution time: {datetime.now() - start_time}\")\n",
    "    torch.save(model.state_dict(), f'end_model.pth')\n",
    "\n",
    "    best_model = ResNet16(num_classes=5)\n",
    "    best_model.load_state_dict(torch.load(BEST_MODEL))\n",
    "    best_model = best_model.to(device)\n",
    "    best_model.eval()\n",
    "\n",
    "    test_labels = []\n",
    "    test_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = best_model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "            test_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(test_labels, test_preds, target_names=[str(i) for i in range(5)]))\n",
    "    print(f\"Test Accuracy: {accuracy_score(test_labels, test_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7112ad66",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-05T09:44:42.456637Z",
     "iopub.status.busy": "2024-06-05T09:44:42.455805Z",
     "iopub.status.idle": "2024-06-05T12:54:19.846086Z",
     "shell.execute_reply": "2024-06-05T12:54:19.845061Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 11377.396678,
     "end_time": "2024-06-05T12:54:19.848538",
     "exception": false,
     "start_time": "2024-06-05T09:44:42.451860",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EPOCH 1 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 1.8639 - ACCURACY: 0.3125\n",
      "BATCH 21/962 - LOSS: 1.4886 - ACCURACY: 0.3125\n",
      "BATCH 41/962 - LOSS: 1.2624 - ACCURACY: 0.6250\n",
      "BATCH 61/962 - LOSS: 1.2136 - ACCURACY: 0.5000\n",
      "BATCH 81/962 - LOSS: 1.5758 - ACCURACY: 0.4375\n",
      "BATCH 101/962 - LOSS: 1.1546 - ACCURACY: 0.6875\n",
      "BATCH 121/962 - LOSS: 1.0939 - ACCURACY: 0.6250\n",
      "BATCH 141/962 - LOSS: 0.8509 - ACCURACY: 0.7500\n",
      "BATCH 161/962 - LOSS: 1.0582 - ACCURACY: 0.5625\n",
      "BATCH 181/962 - LOSS: 1.3373 - ACCURACY: 0.4375\n",
      "BATCH 201/962 - LOSS: 1.2647 - ACCURACY: 0.5000\n",
      "BATCH 221/962 - LOSS: 0.9606 - ACCURACY: 0.7500\n",
      "BATCH 241/962 - LOSS: 0.9626 - ACCURACY: 0.6250\n",
      "BATCH 261/962 - LOSS: 1.1919 - ACCURACY: 0.5000\n",
      "BATCH 281/962 - LOSS: 1.0621 - ACCURACY: 0.5625\n",
      "BATCH 301/962 - LOSS: 1.3797 - ACCURACY: 0.5000\n",
      "BATCH 321/962 - LOSS: 0.9363 - ACCURACY: 0.6875\n",
      "BATCH 341/962 - LOSS: 1.1717 - ACCURACY: 0.5625\n",
      "BATCH 361/962 - LOSS: 1.2280 - ACCURACY: 0.5625\n",
      "BATCH 381/962 - LOSS: 0.8493 - ACCURACY: 0.6250\n",
      "BATCH 401/962 - LOSS: 0.8796 - ACCURACY: 0.6250\n",
      "BATCH 421/962 - LOSS: 0.9013 - ACCURACY: 0.6875\n",
      "BATCH 441/962 - LOSS: 0.9887 - ACCURACY: 0.6250\n",
      "BATCH 461/962 - LOSS: 0.6953 - ACCURACY: 0.6875\n",
      "BATCH 481/962 - LOSS: 0.6278 - ACCURACY: 0.7500\n",
      "BATCH 501/962 - LOSS: 0.8062 - ACCURACY: 0.7500\n",
      "BATCH 521/962 - LOSS: 1.2749 - ACCURACY: 0.5000\n",
      "BATCH 541/962 - LOSS: 1.2224 - ACCURACY: 0.5000\n",
      "BATCH 561/962 - LOSS: 1.2151 - ACCURACY: 0.5625\n",
      "BATCH 581/962 - LOSS: 0.8989 - ACCURACY: 0.6250\n",
      "BATCH 601/962 - LOSS: 0.8806 - ACCURACY: 0.6875\n",
      "BATCH 621/962 - LOSS: 1.1512 - ACCURACY: 0.5000\n",
      "BATCH 641/962 - LOSS: 0.7113 - ACCURACY: 0.8125\n",
      "BATCH 661/962 - LOSS: 0.8715 - ACCURACY: 0.6250\n",
      "BATCH 681/962 - LOSS: 1.4574 - ACCURACY: 0.3750\n",
      "BATCH 701/962 - LOSS: 0.8318 - ACCURACY: 0.6250\n",
      "BATCH 721/962 - LOSS: 0.8254 - ACCURACY: 0.7500\n",
      "BATCH 741/962 - LOSS: 0.8953 - ACCURACY: 0.6250\n",
      "BATCH 761/962 - LOSS: 1.2637 - ACCURACY: 0.5625\n",
      "BATCH 781/962 - LOSS: 0.9513 - ACCURACY: 0.5625\n",
      "BATCH 801/962 - LOSS: 0.8619 - ACCURACY: 0.5625\n",
      "BATCH 821/962 - LOSS: 0.9298 - ACCURACY: 0.6875\n",
      "BATCH 841/962 - LOSS: 0.5399 - ACCURACY: 0.7500\n",
      "BATCH 861/962 - LOSS: 1.0677 - ACCURACY: 0.6250\n",
      "BATCH 881/962 - LOSS: 0.8746 - ACCURACY: 0.5625\n",
      "BATCH 901/962 - LOSS: 1.3300 - ACCURACY: 0.5000\n",
      "BATCH 921/962 - LOSS: 0.6622 - ACCURACY: 0.7500\n",
      "BATCH 941/962 - LOSS: 1.3405 - ACCURACY: 0.3125\n",
      "BATCH 961/962 - LOSS: 1.0330 - ACCURACY: 0.6250\n",
      "\n",
      "\t[TRAIN] EPOCH 1 - LOSS: 1.004398170014429, ACCURACY: 0.6291580041580042\n",
      "\n",
      "EPOCH 1 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.9716137014329433, ACCURACY: 0.6291666666666667\n",
      "\n",
      "==================================================\n",
      "EPOCH 2 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 1.3488 - ACCURACY: 0.5000\n",
      "BATCH 21/962 - LOSS: 0.6168 - ACCURACY: 0.8125\n",
      "BATCH 41/962 - LOSS: 1.0575 - ACCURACY: 0.5625\n",
      "BATCH 61/962 - LOSS: 1.1592 - ACCURACY: 0.5000\n",
      "BATCH 81/962 - LOSS: 1.8497 - ACCURACY: 0.5625\n",
      "BATCH 101/962 - LOSS: 0.9792 - ACCURACY: 0.6875\n",
      "BATCH 121/962 - LOSS: 0.9340 - ACCURACY: 0.5625\n",
      "BATCH 141/962 - LOSS: 0.6852 - ACCURACY: 0.8750\n",
      "BATCH 161/962 - LOSS: 0.8423 - ACCURACY: 0.5625\n",
      "BATCH 181/962 - LOSS: 1.1514 - ACCURACY: 0.5000\n",
      "BATCH 201/962 - LOSS: 1.1472 - ACCURACY: 0.6250\n",
      "BATCH 221/962 - LOSS: 0.8548 - ACCURACY: 0.8750\n",
      "BATCH 241/962 - LOSS: 0.8078 - ACCURACY: 0.7500\n",
      "BATCH 261/962 - LOSS: 1.0286 - ACCURACY: 0.6250\n",
      "BATCH 281/962 - LOSS: 0.8289 - ACCURACY: 0.6875\n",
      "BATCH 301/962 - LOSS: 1.0609 - ACCURACY: 0.5000\n",
      "BATCH 321/962 - LOSS: 0.8689 - ACCURACY: 0.6875\n",
      "BATCH 341/962 - LOSS: 0.9637 - ACCURACY: 0.5625\n",
      "BATCH 361/962 - LOSS: 1.1465 - ACCURACY: 0.5625\n",
      "BATCH 381/962 - LOSS: 0.6819 - ACCURACY: 0.7500\n",
      "BATCH 401/962 - LOSS: 0.6427 - ACCURACY: 0.6875\n",
      "BATCH 421/962 - LOSS: 0.7197 - ACCURACY: 0.6250\n",
      "BATCH 441/962 - LOSS: 0.7775 - ACCURACY: 0.6875\n",
      "BATCH 461/962 - LOSS: 0.4837 - ACCURACY: 0.8750\n",
      "BATCH 481/962 - LOSS: 0.5734 - ACCURACY: 0.8125\n",
      "BATCH 501/962 - LOSS: 0.8351 - ACCURACY: 0.6875\n",
      "BATCH 521/962 - LOSS: 1.0650 - ACCURACY: 0.5625\n",
      "BATCH 541/962 - LOSS: 1.0289 - ACCURACY: 0.6250\n",
      "BATCH 561/962 - LOSS: 0.9386 - ACCURACY: 0.6250\n",
      "BATCH 581/962 - LOSS: 0.6876 - ACCURACY: 0.8125\n",
      "BATCH 601/962 - LOSS: 0.8301 - ACCURACY: 0.6875\n",
      "BATCH 621/962 - LOSS: 1.0578 - ACCURACY: 0.6875\n",
      "BATCH 641/962 - LOSS: 0.6392 - ACCURACY: 0.7500\n",
      "BATCH 661/962 - LOSS: 0.7200 - ACCURACY: 0.6250\n",
      "BATCH 681/962 - LOSS: 1.2992 - ACCURACY: 0.4375\n",
      "BATCH 701/962 - LOSS: 0.8337 - ACCURACY: 0.7500\n",
      "BATCH 721/962 - LOSS: 0.6082 - ACCURACY: 0.8125\n",
      "BATCH 741/962 - LOSS: 0.8140 - ACCURACY: 0.6875\n",
      "BATCH 761/962 - LOSS: 1.2053 - ACCURACY: 0.5000\n",
      "BATCH 781/962 - LOSS: 0.7725 - ACCURACY: 0.6875\n",
      "BATCH 801/962 - LOSS: 0.7558 - ACCURACY: 0.6875\n",
      "BATCH 821/962 - LOSS: 0.7573 - ACCURACY: 0.6875\n",
      "BATCH 841/962 - LOSS: 0.4337 - ACCURACY: 0.8125\n",
      "BATCH 861/962 - LOSS: 1.0704 - ACCURACY: 0.5625\n",
      "BATCH 881/962 - LOSS: 0.8349 - ACCURACY: 0.6250\n",
      "BATCH 901/962 - LOSS: 1.1424 - ACCURACY: 0.5000\n",
      "BATCH 921/962 - LOSS: 0.4939 - ACCURACY: 0.8125\n",
      "BATCH 941/962 - LOSS: 1.3064 - ACCURACY: 0.5000\n",
      "BATCH 961/962 - LOSS: 0.7831 - ACCURACY: 0.6250\n",
      "\n",
      "\t[TRAIN] EPOCH 2 - LOSS: 0.8411978849688092, ACCURACY: 0.6813929313929314\n",
      "\n",
      "EPOCH 2 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.8030853519837061, ACCURACY: 0.6903645833333333\n",
      "\n",
      "Validation loss decreased (inf --> 0.8031). Saving model...\n",
      "==================================================\n",
      "EPOCH 3 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 1.2934 - ACCURACY: 0.5625\n",
      "BATCH 21/962 - LOSS: 0.5390 - ACCURACY: 0.8750\n",
      "BATCH 41/962 - LOSS: 0.9927 - ACCURACY: 0.6250\n",
      "BATCH 61/962 - LOSS: 1.0323 - ACCURACY: 0.6250\n",
      "BATCH 81/962 - LOSS: 1.6697 - ACCURACY: 0.5625\n",
      "BATCH 101/962 - LOSS: 0.8359 - ACCURACY: 0.8125\n",
      "BATCH 121/962 - LOSS: 0.7176 - ACCURACY: 0.7500\n",
      "BATCH 141/962 - LOSS: 0.5594 - ACCURACY: 0.7500\n",
      "BATCH 161/962 - LOSS: 0.8397 - ACCURACY: 0.5625\n",
      "BATCH 181/962 - LOSS: 1.0598 - ACCURACY: 0.5625\n",
      "BATCH 201/962 - LOSS: 0.9885 - ACCURACY: 0.6875\n",
      "BATCH 221/962 - LOSS: 0.9304 - ACCURACY: 0.7500\n",
      "BATCH 241/962 - LOSS: 0.7610 - ACCURACY: 0.6875\n",
      "BATCH 261/962 - LOSS: 0.8349 - ACCURACY: 0.6875\n",
      "BATCH 281/962 - LOSS: 0.6375 - ACCURACY: 0.6875\n",
      "BATCH 301/962 - LOSS: 0.8188 - ACCURACY: 0.6875\n",
      "BATCH 321/962 - LOSS: 0.7155 - ACCURACY: 0.7500\n",
      "BATCH 341/962 - LOSS: 0.7208 - ACCURACY: 0.7500\n",
      "BATCH 361/962 - LOSS: 0.9095 - ACCURACY: 0.6250\n",
      "BATCH 381/962 - LOSS: 0.5056 - ACCURACY: 0.7500\n",
      "BATCH 401/962 - LOSS: 0.6106 - ACCURACY: 0.6250\n",
      "BATCH 421/962 - LOSS: 0.7501 - ACCURACY: 0.6875\n",
      "BATCH 441/962 - LOSS: 0.6858 - ACCURACY: 0.7500\n",
      "BATCH 461/962 - LOSS: 0.3976 - ACCURACY: 0.9375\n",
      "BATCH 481/962 - LOSS: 0.5698 - ACCURACY: 0.8125\n",
      "BATCH 501/962 - LOSS: 0.7623 - ACCURACY: 0.8125\n",
      "BATCH 521/962 - LOSS: 0.8482 - ACCURACY: 0.6875\n",
      "BATCH 541/962 - LOSS: 0.9867 - ACCURACY: 0.6875\n",
      "BATCH 561/962 - LOSS: 0.8219 - ACCURACY: 0.6875\n",
      "BATCH 581/962 - LOSS: 0.5697 - ACCURACY: 0.8125\n",
      "BATCH 601/962 - LOSS: 0.7135 - ACCURACY: 0.6875\n",
      "BATCH 621/962 - LOSS: 1.0393 - ACCURACY: 0.6250\n",
      "BATCH 641/962 - LOSS: 0.5997 - ACCURACY: 0.7500\n",
      "BATCH 661/962 - LOSS: 0.7121 - ACCURACY: 0.7500\n",
      "BATCH 681/962 - LOSS: 1.2414 - ACCURACY: 0.5000\n",
      "BATCH 701/962 - LOSS: 0.8640 - ACCURACY: 0.6875\n",
      "BATCH 721/962 - LOSS: 0.4196 - ACCURACY: 0.8750\n",
      "BATCH 741/962 - LOSS: 0.7513 - ACCURACY: 0.6875\n",
      "BATCH 761/962 - LOSS: 1.0577 - ACCURACY: 0.6875\n",
      "BATCH 781/962 - LOSS: 0.6169 - ACCURACY: 0.8125\n",
      "BATCH 801/962 - LOSS: 0.7124 - ACCURACY: 0.6875\n",
      "BATCH 821/962 - LOSS: 0.6994 - ACCURACY: 0.6875\n",
      "BATCH 841/962 - LOSS: 0.4412 - ACCURACY: 0.8125\n",
      "BATCH 861/962 - LOSS: 1.0239 - ACCURACY: 0.6250\n",
      "BATCH 881/962 - LOSS: 0.8368 - ACCURACY: 0.6875\n",
      "BATCH 901/962 - LOSS: 0.9749 - ACCURACY: 0.5625\n",
      "BATCH 921/962 - LOSS: 0.4317 - ACCURACY: 0.8125\n",
      "BATCH 941/962 - LOSS: 1.2639 - ACCURACY: 0.4375\n",
      "BATCH 961/962 - LOSS: 0.7319 - ACCURACY: 0.6250\n",
      "\n",
      "\t[TRAIN] EPOCH 3 - LOSS: 0.7439219236002147, ACCURACY: 0.72258316008316\n",
      "\n",
      "EPOCH 3 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.7701258825759093, ACCURACY: 0.7119791666666667\n",
      "\n",
      "Validation loss decreased (0.8031 --> 0.7701). Saving model...\n",
      "==================================================\n",
      "EPOCH 4 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 1.2291 - ACCURACY: 0.5625\n",
      "BATCH 21/962 - LOSS: 0.5344 - ACCURACY: 0.8125\n",
      "BATCH 41/962 - LOSS: 0.8403 - ACCURACY: 0.6250\n",
      "BATCH 61/962 - LOSS: 0.8600 - ACCURACY: 0.6250\n",
      "BATCH 81/962 - LOSS: 1.5397 - ACCURACY: 0.6250\n",
      "BATCH 101/962 - LOSS: 0.8070 - ACCURACY: 0.8125\n",
      "BATCH 121/962 - LOSS: 0.5797 - ACCURACY: 0.8750\n",
      "BATCH 141/962 - LOSS: 0.4651 - ACCURACY: 0.8750\n",
      "BATCH 161/962 - LOSS: 0.8170 - ACCURACY: 0.6250\n",
      "BATCH 181/962 - LOSS: 0.9481 - ACCURACY: 0.6250\n",
      "BATCH 201/962 - LOSS: 0.8291 - ACCURACY: 0.6875\n",
      "BATCH 221/962 - LOSS: 1.0537 - ACCURACY: 0.7500\n",
      "BATCH 241/962 - LOSS: 0.6511 - ACCURACY: 0.6875\n",
      "BATCH 261/962 - LOSS: 0.6892 - ACCURACY: 0.7500\n",
      "BATCH 281/962 - LOSS: 0.5895 - ACCURACY: 0.6875\n",
      "BATCH 301/962 - LOSS: 0.7957 - ACCURACY: 0.6250\n",
      "BATCH 321/962 - LOSS: 0.5820 - ACCURACY: 0.8750\n",
      "BATCH 341/962 - LOSS: 0.5860 - ACCURACY: 0.8125\n",
      "BATCH 361/962 - LOSS: 0.7954 - ACCURACY: 0.6875\n",
      "BATCH 381/962 - LOSS: 0.4390 - ACCURACY: 0.8125\n",
      "BATCH 401/962 - LOSS: 0.5379 - ACCURACY: 0.8125\n",
      "BATCH 421/962 - LOSS: 0.7505 - ACCURACY: 0.6875\n",
      "BATCH 441/962 - LOSS: 0.6660 - ACCURACY: 0.7500\n",
      "BATCH 461/962 - LOSS: 0.3510 - ACCURACY: 0.9375\n",
      "BATCH 481/962 - LOSS: 0.5018 - ACCURACY: 0.8125\n",
      "BATCH 501/962 - LOSS: 0.6884 - ACCURACY: 0.7500\n",
      "BATCH 521/962 - LOSS: 0.6954 - ACCURACY: 0.6875\n",
      "BATCH 541/962 - LOSS: 0.8093 - ACCURACY: 0.6875\n",
      "BATCH 561/962 - LOSS: 0.7774 - ACCURACY: 0.8125\n",
      "BATCH 581/962 - LOSS: 0.5049 - ACCURACY: 0.7500\n",
      "BATCH 601/962 - LOSS: 0.6502 - ACCURACY: 0.6875\n",
      "BATCH 621/962 - LOSS: 0.9974 - ACCURACY: 0.6875\n",
      "BATCH 641/962 - LOSS: 0.5578 - ACCURACY: 0.7500\n",
      "BATCH 661/962 - LOSS: 0.7094 - ACCURACY: 0.7500\n",
      "BATCH 681/962 - LOSS: 1.1130 - ACCURACY: 0.5000\n",
      "BATCH 701/962 - LOSS: 0.9746 - ACCURACY: 0.6875\n",
      "BATCH 721/962 - LOSS: 0.3478 - ACCURACY: 0.9375\n",
      "BATCH 741/962 - LOSS: 0.6105 - ACCURACY: 0.6250\n",
      "BATCH 761/962 - LOSS: 0.9609 - ACCURACY: 0.6875\n",
      "BATCH 781/962 - LOSS: 0.5828 - ACCURACY: 0.8125\n",
      "BATCH 801/962 - LOSS: 0.7170 - ACCURACY: 0.6875\n",
      "BATCH 821/962 - LOSS: 0.6727 - ACCURACY: 0.6875\n",
      "BATCH 841/962 - LOSS: 0.4182 - ACCURACY: 0.8750\n",
      "BATCH 861/962 - LOSS: 0.9180 - ACCURACY: 0.6250\n",
      "BATCH 881/962 - LOSS: 0.7801 - ACCURACY: 0.7500\n",
      "BATCH 901/962 - LOSS: 0.8512 - ACCURACY: 0.5625\n",
      "BATCH 921/962 - LOSS: 0.3863 - ACCURACY: 0.8125\n",
      "BATCH 941/962 - LOSS: 1.0999 - ACCURACY: 0.5625\n",
      "BATCH 961/962 - LOSS: 0.6856 - ACCURACY: 0.6250\n",
      "\n",
      "\t[TRAIN] EPOCH 4 - LOSS: 0.6723471047693628, ACCURACY: 0.752079002079002\n",
      "\n",
      "EPOCH 4 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.7765571732074023, ACCURACY: 0.7171875\n",
      "\n",
      "==================================================\n",
      "EPOCH 5 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 1.1870 - ACCURACY: 0.5625\n",
      "BATCH 21/962 - LOSS: 0.4245 - ACCURACY: 0.8125\n",
      "BATCH 41/962 - LOSS: 0.7672 - ACCURACY: 0.6875\n",
      "BATCH 61/962 - LOSS: 0.7625 - ACCURACY: 0.6250\n",
      "BATCH 81/962 - LOSS: 1.2408 - ACCURACY: 0.6250\n",
      "BATCH 101/962 - LOSS: 0.7889 - ACCURACY: 0.8125\n",
      "BATCH 121/962 - LOSS: 0.5059 - ACCURACY: 0.8750\n",
      "BATCH 141/962 - LOSS: 0.4409 - ACCURACY: 0.8750\n",
      "BATCH 161/962 - LOSS: 0.7991 - ACCURACY: 0.7500\n",
      "BATCH 181/962 - LOSS: 0.8943 - ACCURACY: 0.6250\n",
      "BATCH 201/962 - LOSS: 0.7250 - ACCURACY: 0.6875\n",
      "BATCH 221/962 - LOSS: 1.0722 - ACCURACY: 0.7500\n",
      "BATCH 241/962 - LOSS: 0.6436 - ACCURACY: 0.6875\n",
      "BATCH 261/962 - LOSS: 0.6186 - ACCURACY: 0.7500\n",
      "BATCH 281/962 - LOSS: 0.5895 - ACCURACY: 0.6875\n",
      "BATCH 301/962 - LOSS: 0.7746 - ACCURACY: 0.6250\n",
      "BATCH 321/962 - LOSS: 0.5122 - ACCURACY: 0.8750\n",
      "BATCH 341/962 - LOSS: 0.4564 - ACCURACY: 0.8125\n",
      "BATCH 361/962 - LOSS: 0.7208 - ACCURACY: 0.6875\n",
      "BATCH 381/962 - LOSS: 0.3935 - ACCURACY: 0.8125\n",
      "BATCH 401/962 - LOSS: 0.4494 - ACCURACY: 0.8750\n",
      "BATCH 421/962 - LOSS: 0.7366 - ACCURACY: 0.6875\n",
      "BATCH 441/962 - LOSS: 0.6353 - ACCURACY: 0.7500\n",
      "BATCH 461/962 - LOSS: 0.3276 - ACCURACY: 0.9375\n",
      "BATCH 481/962 - LOSS: 0.4731 - ACCURACY: 0.8125\n",
      "BATCH 501/962 - LOSS: 0.6545 - ACCURACY: 0.8125\n",
      "BATCH 521/962 - LOSS: 0.6220 - ACCURACY: 0.7500\n",
      "BATCH 541/962 - LOSS: 0.6421 - ACCURACY: 0.7500\n",
      "BATCH 561/962 - LOSS: 0.8018 - ACCURACY: 0.8125\n",
      "BATCH 581/962 - LOSS: 0.4546 - ACCURACY: 0.8125\n",
      "BATCH 601/962 - LOSS: 0.5816 - ACCURACY: 0.7500\n",
      "BATCH 621/962 - LOSS: 0.9425 - ACCURACY: 0.7500\n",
      "BATCH 641/962 - LOSS: 0.4981 - ACCURACY: 0.8125\n",
      "BATCH 661/962 - LOSS: 0.6976 - ACCURACY: 0.6875\n",
      "BATCH 681/962 - LOSS: 0.9432 - ACCURACY: 0.6250\n",
      "BATCH 701/962 - LOSS: 0.8366 - ACCURACY: 0.7500\n",
      "BATCH 721/962 - LOSS: 0.2629 - ACCURACY: 1.0000\n",
      "BATCH 741/962 - LOSS: 0.5124 - ACCURACY: 0.8750\n",
      "BATCH 761/962 - LOSS: 0.8879 - ACCURACY: 0.7500\n",
      "BATCH 781/962 - LOSS: 0.5819 - ACCURACY: 0.8125\n",
      "BATCH 801/962 - LOSS: 0.7131 - ACCURACY: 0.6875\n",
      "BATCH 821/962 - LOSS: 0.6525 - ACCURACY: 0.6875\n",
      "BATCH 841/962 - LOSS: 0.3803 - ACCURACY: 0.8750\n",
      "BATCH 861/962 - LOSS: 0.8351 - ACCURACY: 0.6875\n",
      "BATCH 881/962 - LOSS: 0.7344 - ACCURACY: 0.8125\n",
      "BATCH 901/962 - LOSS: 0.7471 - ACCURACY: 0.6875\n",
      "BATCH 921/962 - LOSS: 0.3492 - ACCURACY: 0.8750\n",
      "BATCH 941/962 - LOSS: 0.9355 - ACCURACY: 0.6250\n",
      "BATCH 961/962 - LOSS: 0.6515 - ACCURACY: 0.6250\n",
      "\n",
      "\t[TRAIN] EPOCH 5 - LOSS: 0.6135133830772368, ACCURACY: 0.7757276507276507\n",
      "\n",
      "EPOCH 5 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.7039312991624077, ACCURACY: 0.7466145833333333\n",
      "\n",
      "Validation loss decreased (0.7701 --> 0.7039). Saving model...\n",
      "==================================================\n",
      "EPOCH 6 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 1.1165 - ACCURACY: 0.5625\n",
      "BATCH 21/962 - LOSS: 0.3385 - ACCURACY: 0.9375\n",
      "BATCH 41/962 - LOSS: 0.6615 - ACCURACY: 0.6875\n",
      "BATCH 61/962 - LOSS: 0.6551 - ACCURACY: 0.5625\n",
      "BATCH 81/962 - LOSS: 0.9520 - ACCURACY: 0.7500\n",
      "BATCH 101/962 - LOSS: 0.8190 - ACCURACY: 0.8125\n",
      "BATCH 121/962 - LOSS: 0.4476 - ACCURACY: 0.8750\n",
      "BATCH 141/962 - LOSS: 0.4286 - ACCURACY: 0.8750\n",
      "BATCH 161/962 - LOSS: 0.7435 - ACCURACY: 0.8125\n",
      "BATCH 181/962 - LOSS: 0.8276 - ACCURACY: 0.6250\n",
      "BATCH 201/962 - LOSS: 0.6583 - ACCURACY: 0.6875\n",
      "BATCH 221/962 - LOSS: 1.0265 - ACCURACY: 0.8125\n",
      "BATCH 241/962 - LOSS: 0.6044 - ACCURACY: 0.6875\n",
      "BATCH 261/962 - LOSS: 0.5999 - ACCURACY: 0.7500\n",
      "BATCH 281/962 - LOSS: 0.6038 - ACCURACY: 0.6875\n",
      "BATCH 301/962 - LOSS: 0.7167 - ACCURACY: 0.6250\n",
      "BATCH 321/962 - LOSS: 0.4930 - ACCURACY: 0.8750\n",
      "BATCH 341/962 - LOSS: 0.3699 - ACCURACY: 0.8750\n",
      "BATCH 361/962 - LOSS: 0.6647 - ACCURACY: 0.6875\n",
      "BATCH 381/962 - LOSS: 0.3507 - ACCURACY: 0.8750\n",
      "BATCH 401/962 - LOSS: 0.3494 - ACCURACY: 0.8750\n",
      "BATCH 421/962 - LOSS: 0.7508 - ACCURACY: 0.6875\n",
      "BATCH 441/962 - LOSS: 0.5311 - ACCURACY: 0.8125\n",
      "BATCH 461/962 - LOSS: 0.3061 - ACCURACY: 0.9375\n",
      "BATCH 481/962 - LOSS: 0.4402 - ACCURACY: 0.8125\n",
      "BATCH 501/962 - LOSS: 0.6440 - ACCURACY: 0.8750\n",
      "BATCH 521/962 - LOSS: 0.5781 - ACCURACY: 0.7500\n",
      "BATCH 541/962 - LOSS: 0.4549 - ACCURACY: 0.8125\n",
      "BATCH 561/962 - LOSS: 0.7174 - ACCURACY: 0.8125\n",
      "BATCH 581/962 - LOSS: 0.3928 - ACCURACY: 0.8125\n",
      "BATCH 601/962 - LOSS: 0.5057 - ACCURACY: 0.7500\n",
      "BATCH 621/962 - LOSS: 0.8839 - ACCURACY: 0.7500\n",
      "BATCH 641/962 - LOSS: 0.3793 - ACCURACY: 0.8750\n",
      "BATCH 661/962 - LOSS: 0.6174 - ACCURACY: 0.6875\n",
      "BATCH 681/962 - LOSS: 0.7470 - ACCURACY: 0.6250\n",
      "BATCH 701/962 - LOSS: 0.7658 - ACCURACY: 0.7500\n",
      "BATCH 721/962 - LOSS: 0.1874 - ACCURACY: 1.0000\n",
      "BATCH 741/962 - LOSS: 0.5044 - ACCURACY: 0.8125\n",
      "BATCH 761/962 - LOSS: 0.8335 - ACCURACY: 0.8125\n",
      "BATCH 781/962 - LOSS: 0.5378 - ACCURACY: 0.8125\n",
      "BATCH 801/962 - LOSS: 0.7311 - ACCURACY: 0.7500\n",
      "BATCH 821/962 - LOSS: 0.5977 - ACCURACY: 0.6875\n",
      "BATCH 841/962 - LOSS: 0.3015 - ACCURACY: 0.8750\n",
      "BATCH 861/962 - LOSS: 0.7992 - ACCURACY: 0.6875\n",
      "BATCH 881/962 - LOSS: 0.6638 - ACCURACY: 0.7500\n",
      "BATCH 901/962 - LOSS: 0.7134 - ACCURACY: 0.7500\n",
      "BATCH 921/962 - LOSS: 0.2925 - ACCURACY: 0.9375\n",
      "BATCH 941/962 - LOSS: 0.7035 - ACCURACY: 0.7500\n",
      "BATCH 961/962 - LOSS: 0.5566 - ACCURACY: 0.7500\n",
      "\n",
      "\t[TRAIN] EPOCH 6 - LOSS: 0.5472652434745102, ACCURACY: 0.8014553014553014\n",
      "\n",
      "EPOCH 6 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.7413771182919542, ACCURACY: 0.7408854166666666\n",
      "\n",
      "==================================================\n",
      "EPOCH 7 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 0.9872 - ACCURACY: 0.5625\n",
      "BATCH 21/962 - LOSS: 0.2631 - ACCURACY: 0.8750\n",
      "BATCH 41/962 - LOSS: 0.4840 - ACCURACY: 0.8750\n",
      "BATCH 61/962 - LOSS: 0.5180 - ACCURACY: 0.8125\n",
      "BATCH 81/962 - LOSS: 0.7809 - ACCURACY: 0.8125\n",
      "BATCH 101/962 - LOSS: 0.6206 - ACCURACY: 0.8750\n",
      "BATCH 121/962 - LOSS: 0.3774 - ACCURACY: 0.8750\n",
      "BATCH 141/962 - LOSS: 0.4199 - ACCURACY: 0.9375\n",
      "BATCH 161/962 - LOSS: 0.6935 - ACCURACY: 0.8125\n",
      "BATCH 181/962 - LOSS: 0.7653 - ACCURACY: 0.6875\n",
      "BATCH 201/962 - LOSS: 0.6309 - ACCURACY: 0.7500\n",
      "BATCH 221/962 - LOSS: 0.8922 - ACCURACY: 0.7500\n",
      "BATCH 241/962 - LOSS: 0.5223 - ACCURACY: 0.8125\n",
      "BATCH 261/962 - LOSS: 0.6039 - ACCURACY: 0.6875\n",
      "BATCH 281/962 - LOSS: 0.5455 - ACCURACY: 0.8125\n",
      "BATCH 301/962 - LOSS: 0.5823 - ACCURACY: 0.8125\n",
      "BATCH 321/962 - LOSS: 0.4838 - ACCURACY: 0.8750\n",
      "BATCH 341/962 - LOSS: 0.2828 - ACCURACY: 0.8750\n",
      "BATCH 361/962 - LOSS: 0.5945 - ACCURACY: 0.6875\n",
      "BATCH 381/962 - LOSS: 0.3458 - ACCURACY: 0.8750\n",
      "BATCH 401/962 - LOSS: 0.2767 - ACCURACY: 0.9375\n",
      "BATCH 421/962 - LOSS: 0.6232 - ACCURACY: 0.6875\n",
      "BATCH 441/962 - LOSS: 0.3753 - ACCURACY: 0.8125\n",
      "BATCH 461/962 - LOSS: 0.2933 - ACCURACY: 0.9375\n",
      "BATCH 481/962 - LOSS: 0.3960 - ACCURACY: 0.8125\n",
      "BATCH 501/962 - LOSS: 0.6391 - ACCURACY: 0.8750\n",
      "BATCH 521/962 - LOSS: 0.4982 - ACCURACY: 0.7500\n",
      "BATCH 541/962 - LOSS: 0.2794 - ACCURACY: 0.9375\n",
      "BATCH 561/962 - LOSS: 0.4855 - ACCURACY: 0.8125\n",
      "BATCH 581/962 - LOSS: 0.3478 - ACCURACY: 0.8125\n",
      "BATCH 601/962 - LOSS: 0.3739 - ACCURACY: 0.8125\n",
      "BATCH 621/962 - LOSS: 0.7877 - ACCURACY: 0.6875\n",
      "BATCH 641/962 - LOSS: 0.2745 - ACCURACY: 1.0000\n",
      "BATCH 661/962 - LOSS: 0.4970 - ACCURACY: 0.8125\n",
      "BATCH 681/962 - LOSS: 0.4582 - ACCURACY: 0.8750\n",
      "BATCH 701/962 - LOSS: 0.4814 - ACCURACY: 0.8125\n",
      "BATCH 721/962 - LOSS: 0.1198 - ACCURACY: 1.0000\n",
      "BATCH 741/962 - LOSS: 0.3877 - ACCURACY: 0.8750\n",
      "BATCH 761/962 - LOSS: 0.7509 - ACCURACY: 0.8125\n",
      "BATCH 781/962 - LOSS: 0.4569 - ACCURACY: 0.8125\n",
      "BATCH 801/962 - LOSS: 0.7129 - ACCURACY: 0.7500\n",
      "BATCH 821/962 - LOSS: 0.5055 - ACCURACY: 0.7500\n",
      "BATCH 841/962 - LOSS: 0.2309 - ACCURACY: 0.9375\n",
      "BATCH 861/962 - LOSS: 0.6650 - ACCURACY: 0.6875\n",
      "BATCH 881/962 - LOSS: 0.6485 - ACCURACY: 0.7500\n",
      "BATCH 901/962 - LOSS: 0.5463 - ACCURACY: 0.8125\n",
      "BATCH 921/962 - LOSS: 0.2433 - ACCURACY: 0.9375\n",
      "BATCH 941/962 - LOSS: 0.4823 - ACCURACY: 0.8125\n",
      "BATCH 961/962 - LOSS: 0.4525 - ACCURACY: 0.8125\n",
      "\n",
      "\t[TRAIN] EPOCH 7 - LOSS: 0.4429466681489082, ACCURACY: 0.84375\n",
      "\n",
      "EPOCH 7 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.9179674511154493, ACCURACY: 0.7013020833333333\n",
      "\n",
      "==================================================\n",
      "EPOCH 8 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 0.6726 - ACCURACY: 0.6875\n",
      "BATCH 21/962 - LOSS: 0.1591 - ACCURACY: 1.0000\n",
      "BATCH 41/962 - LOSS: 0.3681 - ACCURACY: 0.8750\n",
      "BATCH 61/962 - LOSS: 0.3795 - ACCURACY: 0.9375\n",
      "BATCH 81/962 - LOSS: 0.7347 - ACCURACY: 0.7500\n",
      "BATCH 101/962 - LOSS: 0.3462 - ACCURACY: 0.8750\n",
      "BATCH 121/962 - LOSS: 0.2928 - ACCURACY: 0.8750\n",
      "BATCH 141/962 - LOSS: 0.2647 - ACCURACY: 1.0000\n",
      "BATCH 161/962 - LOSS: 0.7443 - ACCURACY: 0.8125\n",
      "BATCH 181/962 - LOSS: 0.5639 - ACCURACY: 0.7500\n",
      "BATCH 201/962 - LOSS: 0.4375 - ACCURACY: 0.8125\n",
      "BATCH 221/962 - LOSS: 0.4307 - ACCURACY: 0.7500\n",
      "BATCH 241/962 - LOSS: 0.3579 - ACCURACY: 0.8750\n",
      "BATCH 261/962 - LOSS: 0.5067 - ACCURACY: 0.7500\n",
      "BATCH 281/962 - LOSS: 0.4585 - ACCURACY: 0.8125\n",
      "BATCH 301/962 - LOSS: 0.3247 - ACCURACY: 0.8750\n",
      "BATCH 321/962 - LOSS: 0.3337 - ACCURACY: 0.8750\n",
      "BATCH 341/962 - LOSS: 0.2530 - ACCURACY: 0.9375\n",
      "BATCH 361/962 - LOSS: 0.4883 - ACCURACY: 0.7500\n",
      "BATCH 381/962 - LOSS: 0.2802 - ACCURACY: 0.8750\n",
      "BATCH 401/962 - LOSS: 0.2117 - ACCURACY: 0.9375\n",
      "BATCH 421/962 - LOSS: 0.4541 - ACCURACY: 0.6875\n",
      "BATCH 441/962 - LOSS: 0.3029 - ACCURACY: 0.8750\n",
      "BATCH 461/962 - LOSS: 0.2008 - ACCURACY: 0.9375\n",
      "BATCH 481/962 - LOSS: 0.2768 - ACCURACY: 0.8750\n",
      "BATCH 501/962 - LOSS: 0.4745 - ACCURACY: 0.8750\n",
      "BATCH 521/962 - LOSS: 0.3975 - ACCURACY: 0.8125\n",
      "BATCH 541/962 - LOSS: 0.1917 - ACCURACY: 0.9375\n",
      "BATCH 561/962 - LOSS: 0.2655 - ACCURACY: 0.8750\n",
      "BATCH 581/962 - LOSS: 0.2247 - ACCURACY: 0.9375\n",
      "BATCH 601/962 - LOSS: 0.2834 - ACCURACY: 0.8750\n",
      "BATCH 621/962 - LOSS: 0.6859 - ACCURACY: 0.7500\n",
      "BATCH 641/962 - LOSS: 0.1637 - ACCURACY: 1.0000\n",
      "BATCH 661/962 - LOSS: 0.4125 - ACCURACY: 0.8125\n",
      "BATCH 681/962 - LOSS: 0.3529 - ACCURACY: 0.9375\n",
      "BATCH 701/962 - LOSS: 0.3023 - ACCURACY: 0.8750\n",
      "BATCH 721/962 - LOSS: 0.0952 - ACCURACY: 1.0000\n",
      "BATCH 741/962 - LOSS: 0.3027 - ACCURACY: 0.8750\n",
      "BATCH 761/962 - LOSS: 0.5512 - ACCURACY: 0.8750\n",
      "BATCH 781/962 - LOSS: 0.3475 - ACCURACY: 0.8750\n",
      "BATCH 801/962 - LOSS: 0.5444 - ACCURACY: 0.8125\n",
      "BATCH 821/962 - LOSS: 0.3812 - ACCURACY: 0.8750\n",
      "BATCH 841/962 - LOSS: 0.1494 - ACCURACY: 1.0000\n",
      "BATCH 861/962 - LOSS: 0.4968 - ACCURACY: 0.7500\n",
      "BATCH 881/962 - LOSS: 0.5106 - ACCURACY: 0.7500\n",
      "BATCH 901/962 - LOSS: 0.4209 - ACCURACY: 0.8750\n",
      "BATCH 921/962 - LOSS: 0.1971 - ACCURACY: 0.8750\n",
      "BATCH 941/962 - LOSS: 0.4373 - ACCURACY: 0.8750\n",
      "BATCH 961/962 - LOSS: 0.2995 - ACCURACY: 0.9375\n",
      "\n",
      "\t[TRAIN] EPOCH 8 - LOSS: 0.322935031854747, ACCURACY: 0.8905925155925156\n",
      "\n",
      "EPOCH 8 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.2563928304240108, ACCURACY: 0.6192708333333333\n",
      "\n",
      "==================================================\n",
      "EPOCH 9 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 0.5795 - ACCURACY: 0.7500\n",
      "BATCH 21/962 - LOSS: 0.0821 - ACCURACY: 1.0000\n",
      "BATCH 41/962 - LOSS: 0.2299 - ACCURACY: 0.9375\n",
      "BATCH 61/962 - LOSS: 0.2718 - ACCURACY: 0.9375\n",
      "BATCH 81/962 - LOSS: 0.3998 - ACCURACY: 0.8750\n",
      "BATCH 101/962 - LOSS: 0.2817 - ACCURACY: 0.9375\n",
      "BATCH 121/962 - LOSS: 0.1732 - ACCURACY: 0.9375\n",
      "BATCH 141/962 - LOSS: 0.3002 - ACCURACY: 0.9375\n",
      "BATCH 161/962 - LOSS: 0.6266 - ACCURACY: 0.8750\n",
      "BATCH 181/962 - LOSS: 0.4145 - ACCURACY: 0.8125\n",
      "BATCH 201/962 - LOSS: 0.3115 - ACCURACY: 0.8750\n",
      "BATCH 221/962 - LOSS: 0.2557 - ACCURACY: 0.9375\n",
      "BATCH 241/962 - LOSS: 0.3274 - ACCURACY: 0.8125\n",
      "BATCH 261/962 - LOSS: 0.4321 - ACCURACY: 0.7500\n",
      "BATCH 281/962 - LOSS: 0.3751 - ACCURACY: 0.8750\n",
      "BATCH 301/962 - LOSS: 0.2920 - ACCURACY: 0.9375\n",
      "BATCH 321/962 - LOSS: 0.3137 - ACCURACY: 0.9375\n",
      "BATCH 341/962 - LOSS: 0.1682 - ACCURACY: 0.9375\n",
      "BATCH 361/962 - LOSS: 0.4392 - ACCURACY: 0.8125\n",
      "BATCH 381/962 - LOSS: 0.2312 - ACCURACY: 0.8750\n",
      "BATCH 401/962 - LOSS: 0.1272 - ACCURACY: 1.0000\n",
      "BATCH 421/962 - LOSS: 0.2348 - ACCURACY: 0.8750\n",
      "BATCH 441/962 - LOSS: 0.2412 - ACCURACY: 0.9375\n",
      "BATCH 461/962 - LOSS: 0.1213 - ACCURACY: 0.9375\n",
      "BATCH 481/962 - LOSS: 0.1182 - ACCURACY: 1.0000\n",
      "BATCH 501/962 - LOSS: 0.2194 - ACCURACY: 0.8750\n",
      "BATCH 521/962 - LOSS: 0.2989 - ACCURACY: 0.8750\n",
      "BATCH 541/962 - LOSS: 0.0818 - ACCURACY: 1.0000\n",
      "BATCH 561/962 - LOSS: 0.1459 - ACCURACY: 1.0000\n",
      "BATCH 581/962 - LOSS: 0.1263 - ACCURACY: 1.0000\n",
      "BATCH 601/962 - LOSS: 0.1750 - ACCURACY: 0.9375\n",
      "BATCH 621/962 - LOSS: 0.5691 - ACCURACY: 0.7500\n",
      "BATCH 641/962 - LOSS: 0.0967 - ACCURACY: 1.0000\n",
      "BATCH 661/962 - LOSS: 0.2697 - ACCURACY: 0.9375\n",
      "BATCH 681/962 - LOSS: 0.2662 - ACCURACY: 0.9375\n",
      "BATCH 701/962 - LOSS: 0.1429 - ACCURACY: 1.0000\n",
      "BATCH 721/962 - LOSS: 0.0837 - ACCURACY: 1.0000\n",
      "BATCH 741/962 - LOSS: 0.2295 - ACCURACY: 0.9375\n",
      "BATCH 761/962 - LOSS: 0.3162 - ACCURACY: 0.9375\n",
      "BATCH 781/962 - LOSS: 0.2288 - ACCURACY: 0.8750\n",
      "BATCH 801/962 - LOSS: 0.3253 - ACCURACY: 0.8750\n",
      "BATCH 821/962 - LOSS: 0.1852 - ACCURACY: 0.9375\n",
      "BATCH 841/962 - LOSS: 0.0659 - ACCURACY: 1.0000\n",
      "BATCH 861/962 - LOSS: 0.4092 - ACCURACY: 0.8125\n",
      "BATCH 881/962 - LOSS: 0.3020 - ACCURACY: 0.8750\n",
      "BATCH 901/962 - LOSS: 0.3653 - ACCURACY: 0.8750\n",
      "BATCH 921/962 - LOSS: 0.1204 - ACCURACY: 1.0000\n",
      "BATCH 941/962 - LOSS: 0.3200 - ACCURACY: 0.9375\n",
      "BATCH 961/962 - LOSS: 0.1847 - ACCURACY: 0.8750\n",
      "\n",
      "\t[TRAIN] EPOCH 9 - LOSS: 0.2259773418322794, ACCURACY: 0.9314579002079002\n",
      "\n",
      "EPOCH 9 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.604182057082653, ACCURACY: 0.5369791666666667\n",
      "\n",
      "==================================================\n",
      "EPOCH 10 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 0.4543 - ACCURACY: 0.7500\n",
      "BATCH 21/962 - LOSS: 0.0905 - ACCURACY: 1.0000\n",
      "BATCH 41/962 - LOSS: 0.1192 - ACCURACY: 1.0000\n",
      "BATCH 61/962 - LOSS: 0.1766 - ACCURACY: 0.9375\n",
      "BATCH 81/962 - LOSS: 0.1356 - ACCURACY: 0.9375\n",
      "BATCH 101/962 - LOSS: 0.1986 - ACCURACY: 0.9375\n",
      "BATCH 121/962 - LOSS: 0.1037 - ACCURACY: 1.0000\n",
      "BATCH 141/962 - LOSS: 0.0838 - ACCURACY: 1.0000\n",
      "BATCH 161/962 - LOSS: 0.4650 - ACCURACY: 0.8125\n",
      "BATCH 181/962 - LOSS: 0.2500 - ACCURACY: 0.9375\n",
      "BATCH 201/962 - LOSS: 0.1147 - ACCURACY: 1.0000\n",
      "BATCH 221/962 - LOSS: 0.1246 - ACCURACY: 1.0000\n",
      "BATCH 241/962 - LOSS: 0.1925 - ACCURACY: 0.9375\n",
      "BATCH 261/962 - LOSS: 0.3331 - ACCURACY: 0.8125\n",
      "BATCH 281/962 - LOSS: 0.2029 - ACCURACY: 0.9375\n",
      "BATCH 301/962 - LOSS: 0.2468 - ACCURACY: 0.8750\n",
      "BATCH 321/962 - LOSS: 0.1986 - ACCURACY: 0.9375\n",
      "BATCH 341/962 - LOSS: 0.0685 - ACCURACY: 1.0000\n",
      "BATCH 361/962 - LOSS: 0.3779 - ACCURACY: 0.8125\n",
      "BATCH 381/962 - LOSS: 0.1131 - ACCURACY: 1.0000\n",
      "BATCH 401/962 - LOSS: 0.0694 - ACCURACY: 1.0000\n",
      "BATCH 421/962 - LOSS: 0.2189 - ACCURACY: 0.9375\n",
      "BATCH 441/962 - LOSS: 0.1170 - ACCURACY: 1.0000\n",
      "BATCH 461/962 - LOSS: 0.0765 - ACCURACY: 1.0000\n",
      "BATCH 481/962 - LOSS: 0.0565 - ACCURACY: 1.0000\n",
      "BATCH 501/962 - LOSS: 0.1380 - ACCURACY: 0.9375\n",
      "BATCH 521/962 - LOSS: 0.2750 - ACCURACY: 0.9375\n",
      "BATCH 541/962 - LOSS: 0.0623 - ACCURACY: 1.0000\n",
      "BATCH 561/962 - LOSS: 0.0945 - ACCURACY: 1.0000\n",
      "BATCH 581/962 - LOSS: 0.1145 - ACCURACY: 0.9375\n",
      "BATCH 601/962 - LOSS: 0.1512 - ACCURACY: 0.9375\n",
      "BATCH 621/962 - LOSS: 0.3951 - ACCURACY: 0.9375\n",
      "BATCH 641/962 - LOSS: 0.0678 - ACCURACY: 1.0000\n",
      "BATCH 661/962 - LOSS: 0.1520 - ACCURACY: 0.9375\n",
      "BATCH 681/962 - LOSS: 0.1649 - ACCURACY: 1.0000\n",
      "BATCH 701/962 - LOSS: 0.0688 - ACCURACY: 1.0000\n",
      "BATCH 721/962 - LOSS: 0.0695 - ACCURACY: 1.0000\n",
      "BATCH 741/962 - LOSS: 0.0627 - ACCURACY: 1.0000\n",
      "BATCH 761/962 - LOSS: 0.1493 - ACCURACY: 0.9375\n",
      "BATCH 781/962 - LOSS: 0.0881 - ACCURACY: 1.0000\n",
      "BATCH 801/962 - LOSS: 0.1818 - ACCURACY: 0.9375\n",
      "BATCH 821/962 - LOSS: 0.0568 - ACCURACY: 1.0000\n",
      "BATCH 841/962 - LOSS: 0.0273 - ACCURACY: 1.0000\n",
      "BATCH 861/962 - LOSS: 0.2363 - ACCURACY: 0.8750\n",
      "BATCH 881/962 - LOSS: 0.1519 - ACCURACY: 0.9375\n",
      "BATCH 901/962 - LOSS: 0.2328 - ACCURACY: 0.8750\n",
      "BATCH 921/962 - LOSS: 0.0518 - ACCURACY: 1.0000\n",
      "BATCH 941/962 - LOSS: 0.1383 - ACCURACY: 1.0000\n",
      "BATCH 961/962 - LOSS: 0.0771 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH 10 - LOSS: 0.13580919806254937, ACCURACY: 0.9667359667359667\n",
      "\n",
      "EPOCH 10 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.9980734754043321, ACCURACY: 0.6895833333333333\n",
      "\n",
      "==================================================\n",
      "EPOCH 11 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 0.3890 - ACCURACY: 0.8750\n",
      "BATCH 21/962 - LOSS: 0.0719 - ACCURACY: 1.0000\n",
      "BATCH 41/962 - LOSS: 0.0738 - ACCURACY: 1.0000\n",
      "BATCH 61/962 - LOSS: 0.0855 - ACCURACY: 1.0000\n",
      "BATCH 81/962 - LOSS: 0.0343 - ACCURACY: 1.0000\n",
      "BATCH 101/962 - LOSS: 0.1168 - ACCURACY: 0.9375\n",
      "BATCH 121/962 - LOSS: 0.0362 - ACCURACY: 1.0000\n",
      "BATCH 141/962 - LOSS: 0.0536 - ACCURACY: 1.0000\n",
      "BATCH 161/962 - LOSS: 0.1922 - ACCURACY: 0.9375\n",
      "BATCH 181/962 - LOSS: 0.0904 - ACCURACY: 1.0000\n",
      "BATCH 201/962 - LOSS: 0.0707 - ACCURACY: 1.0000\n",
      "BATCH 221/962 - LOSS: 0.0467 - ACCURACY: 1.0000\n",
      "BATCH 241/962 - LOSS: 0.0643 - ACCURACY: 1.0000\n",
      "BATCH 261/962 - LOSS: 0.1647 - ACCURACY: 0.9375\n",
      "BATCH 281/962 - LOSS: 0.0653 - ACCURACY: 1.0000\n",
      "BATCH 301/962 - LOSS: 0.0583 - ACCURACY: 1.0000\n",
      "BATCH 321/962 - LOSS: 0.0975 - ACCURACY: 1.0000\n",
      "BATCH 341/962 - LOSS: 0.1425 - ACCURACY: 0.9375\n",
      "BATCH 361/962 - LOSS: 0.0947 - ACCURACY: 1.0000\n",
      "BATCH 381/962 - LOSS: 0.0407 - ACCURACY: 1.0000\n",
      "BATCH 401/962 - LOSS: 0.0300 - ACCURACY: 1.0000\n",
      "BATCH 421/962 - LOSS: 0.1024 - ACCURACY: 0.9375\n",
      "BATCH 441/962 - LOSS: 0.0551 - ACCURACY: 1.0000\n",
      "BATCH 461/962 - LOSS: 0.1356 - ACCURACY: 0.9375\n",
      "BATCH 481/962 - LOSS: 0.0611 - ACCURACY: 1.0000\n",
      "BATCH 501/962 - LOSS: 0.0284 - ACCURACY: 1.0000\n",
      "BATCH 521/962 - LOSS: 0.0534 - ACCURACY: 1.0000\n",
      "BATCH 541/962 - LOSS: 0.0253 - ACCURACY: 1.0000\n",
      "BATCH 561/962 - LOSS: 0.0669 - ACCURACY: 1.0000\n",
      "BATCH 581/962 - LOSS: 0.0398 - ACCURACY: 1.0000\n",
      "BATCH 601/962 - LOSS: 0.0546 - ACCURACY: 1.0000\n",
      "BATCH 621/962 - LOSS: 0.1855 - ACCURACY: 0.9375\n",
      "BATCH 641/962 - LOSS: 0.0711 - ACCURACY: 1.0000\n",
      "BATCH 661/962 - LOSS: 0.1004 - ACCURACY: 0.9375\n",
      "BATCH 681/962 - LOSS: 0.1128 - ACCURACY: 1.0000\n",
      "BATCH 701/962 - LOSS: 0.0325 - ACCURACY: 1.0000\n",
      "BATCH 721/962 - LOSS: 0.0381 - ACCURACY: 1.0000\n",
      "BATCH 741/962 - LOSS: 0.0318 - ACCURACY: 1.0000\n",
      "BATCH 761/962 - LOSS: 0.0327 - ACCURACY: 1.0000\n",
      "BATCH 781/962 - LOSS: 0.0533 - ACCURACY: 1.0000\n",
      "BATCH 801/962 - LOSS: 0.0692 - ACCURACY: 1.0000\n",
      "BATCH 821/962 - LOSS: 0.0347 - ACCURACY: 1.0000\n",
      "BATCH 841/962 - LOSS: 0.0255 - ACCURACY: 1.0000\n",
      "BATCH 861/962 - LOSS: 0.1406 - ACCURACY: 1.0000\n",
      "BATCH 881/962 - LOSS: 0.0563 - ACCURACY: 1.0000\n",
      "BATCH 901/962 - LOSS: 0.1367 - ACCURACY: 0.9375\n",
      "BATCH 921/962 - LOSS: 0.0567 - ACCURACY: 1.0000\n",
      "BATCH 941/962 - LOSS: 0.1061 - ACCURACY: 1.0000\n",
      "BATCH 961/962 - LOSS: 0.0139 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH 11 - LOSS: 0.07248516889141869, ACCURACY: 0.988760395010395\n",
      "\n",
      "EPOCH 11 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.0652237923815846, ACCURACY: 0.6875\n",
      "\n",
      "==================================================\n",
      "EPOCH 12 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 0.1558 - ACCURACY: 1.0000\n",
      "BATCH 21/962 - LOSS: 0.0130 - ACCURACY: 1.0000\n",
      "BATCH 41/962 - LOSS: 0.0373 - ACCURACY: 1.0000\n",
      "BATCH 61/962 - LOSS: 0.0881 - ACCURACY: 0.9375\n",
      "BATCH 81/962 - LOSS: 0.0176 - ACCURACY: 1.0000\n",
      "BATCH 101/962 - LOSS: 0.0393 - ACCURACY: 1.0000\n",
      "BATCH 121/962 - LOSS: 0.0305 - ACCURACY: 1.0000\n",
      "BATCH 141/962 - LOSS: 0.0783 - ACCURACY: 1.0000\n",
      "BATCH 161/962 - LOSS: 0.0743 - ACCURACY: 1.0000\n",
      "BATCH 181/962 - LOSS: 0.0429 - ACCURACY: 1.0000\n",
      "BATCH 201/962 - LOSS: 0.0358 - ACCURACY: 1.0000\n",
      "BATCH 221/962 - LOSS: 0.0336 - ACCURACY: 1.0000\n",
      "BATCH 241/962 - LOSS: 0.0180 - ACCURACY: 1.0000\n",
      "BATCH 261/962 - LOSS: 0.0902 - ACCURACY: 1.0000\n",
      "BATCH 281/962 - LOSS: 0.0295 - ACCURACY: 1.0000\n",
      "BATCH 301/962 - LOSS: 0.0350 - ACCURACY: 1.0000\n",
      "BATCH 321/962 - LOSS: 0.0636 - ACCURACY: 1.0000\n",
      "BATCH 341/962 - LOSS: 0.0901 - ACCURACY: 0.9375\n",
      "BATCH 361/962 - LOSS: 0.0354 - ACCURACY: 1.0000\n",
      "BATCH 381/962 - LOSS: 0.0140 - ACCURACY: 1.0000\n",
      "BATCH 401/962 - LOSS: 0.0732 - ACCURACY: 0.9375\n",
      "BATCH 421/962 - LOSS: 0.0465 - ACCURACY: 1.0000\n",
      "BATCH 441/962 - LOSS: 0.0358 - ACCURACY: 1.0000\n",
      "BATCH 461/962 - LOSS: 0.0340 - ACCURACY: 1.0000\n",
      "BATCH 481/962 - LOSS: 0.0308 - ACCURACY: 1.0000\n",
      "BATCH 501/962 - LOSS: 0.0265 - ACCURACY: 1.0000\n",
      "BATCH 521/962 - LOSS: 0.0368 - ACCURACY: 1.0000\n",
      "BATCH 541/962 - LOSS: 0.0098 - ACCURACY: 1.0000\n",
      "BATCH 561/962 - LOSS: 0.0322 - ACCURACY: 1.0000\n",
      "BATCH 581/962 - LOSS: 0.0307 - ACCURACY: 1.0000\n",
      "BATCH 601/962 - LOSS: 0.0236 - ACCURACY: 1.0000\n",
      "BATCH 621/962 - LOSS: 0.0745 - ACCURACY: 1.0000\n",
      "BATCH 641/962 - LOSS: 0.0150 - ACCURACY: 1.0000\n",
      "BATCH 661/962 - LOSS: 0.0732 - ACCURACY: 1.0000\n",
      "BATCH 681/962 - LOSS: 0.0548 - ACCURACY: 1.0000\n",
      "BATCH 701/962 - LOSS: 0.0091 - ACCURACY: 1.0000\n",
      "BATCH 721/962 - LOSS: 0.0179 - ACCURACY: 1.0000\n",
      "BATCH 741/962 - LOSS: 0.0254 - ACCURACY: 1.0000\n",
      "BATCH 761/962 - LOSS: 0.0159 - ACCURACY: 1.0000\n",
      "BATCH 781/962 - LOSS: 0.0569 - ACCURACY: 1.0000\n",
      "BATCH 801/962 - LOSS: 0.0354 - ACCURACY: 1.0000\n",
      "BATCH 821/962 - LOSS: 0.0196 - ACCURACY: 1.0000\n",
      "BATCH 841/962 - LOSS: 0.0113 - ACCURACY: 1.0000\n",
      "BATCH 861/962 - LOSS: 0.2210 - ACCURACY: 0.9375\n",
      "BATCH 881/962 - LOSS: 0.0316 - ACCURACY: 1.0000\n",
      "BATCH 901/962 - LOSS: 0.0360 - ACCURACY: 1.0000\n",
      "BATCH 921/962 - LOSS: 0.0116 - ACCURACY: 1.0000\n",
      "BATCH 941/962 - LOSS: 0.2194 - ACCURACY: 0.9375\n",
      "BATCH 961/962 - LOSS: 0.0304 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH 12 - LOSS: 0.03972289997652529, ACCURACY: 0.9955821205821206\n",
      "\n",
      "EPOCH 12 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.642072257399559, ACCURACY: 0.61171875\n",
      "\n",
      "==================================================\n",
      "EPOCH 13 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 0.0661 - ACCURACY: 1.0000\n",
      "BATCH 21/962 - LOSS: 0.0130 - ACCURACY: 1.0000\n",
      "BATCH 41/962 - LOSS: 0.0169 - ACCURACY: 1.0000\n",
      "BATCH 61/962 - LOSS: 0.0254 - ACCURACY: 1.0000\n",
      "BATCH 81/962 - LOSS: 0.0275 - ACCURACY: 1.0000\n",
      "BATCH 101/962 - LOSS: 0.0408 - ACCURACY: 1.0000\n",
      "BATCH 121/962 - LOSS: 0.0111 - ACCURACY: 1.0000\n",
      "BATCH 141/962 - LOSS: 0.0317 - ACCURACY: 1.0000\n",
      "BATCH 161/962 - LOSS: 0.0864 - ACCURACY: 0.9375\n",
      "BATCH 181/962 - LOSS: 0.0251 - ACCURACY: 1.0000\n",
      "BATCH 201/962 - LOSS: 0.0722 - ACCURACY: 1.0000\n",
      "BATCH 221/962 - LOSS: 0.0268 - ACCURACY: 1.0000\n",
      "BATCH 241/962 - LOSS: 0.0263 - ACCURACY: 1.0000\n",
      "BATCH 261/962 - LOSS: 0.0603 - ACCURACY: 0.9375\n",
      "BATCH 281/962 - LOSS: 0.0100 - ACCURACY: 1.0000\n",
      "BATCH 301/962 - LOSS: 0.0126 - ACCURACY: 1.0000\n",
      "BATCH 321/962 - LOSS: 0.0391 - ACCURACY: 1.0000\n",
      "BATCH 341/962 - LOSS: 0.0536 - ACCURACY: 1.0000\n",
      "BATCH 361/962 - LOSS: 0.0547 - ACCURACY: 1.0000\n",
      "BATCH 381/962 - LOSS: 0.0135 - ACCURACY: 1.0000\n",
      "BATCH 401/962 - LOSS: 0.0721 - ACCURACY: 1.0000\n",
      "BATCH 421/962 - LOSS: 0.0107 - ACCURACY: 1.0000\n",
      "BATCH 441/962 - LOSS: 0.1000 - ACCURACY: 0.9375\n",
      "BATCH 461/962 - LOSS: 0.0295 - ACCURACY: 1.0000\n",
      "BATCH 481/962 - LOSS: 0.0112 - ACCURACY: 1.0000\n",
      "BATCH 501/962 - LOSS: 0.0296 - ACCURACY: 1.0000\n",
      "BATCH 521/962 - LOSS: 0.0491 - ACCURACY: 1.0000\n",
      "BATCH 541/962 - LOSS: 0.0374 - ACCURACY: 1.0000\n",
      "BATCH 561/962 - LOSS: 0.0623 - ACCURACY: 1.0000\n",
      "BATCH 581/962 - LOSS: 0.1033 - ACCURACY: 0.9375\n",
      "BATCH 601/962 - LOSS: 0.1342 - ACCURACY: 0.9375\n",
      "BATCH 621/962 - LOSS: 0.0304 - ACCURACY: 1.0000\n",
      "BATCH 641/962 - LOSS: 0.0220 - ACCURACY: 1.0000\n",
      "BATCH 661/962 - LOSS: 0.0485 - ACCURACY: 1.0000\n",
      "BATCH 681/962 - LOSS: 0.0470 - ACCURACY: 1.0000\n",
      "BATCH 701/962 - LOSS: 0.0095 - ACCURACY: 1.0000\n",
      "BATCH 721/962 - LOSS: 0.0081 - ACCURACY: 1.0000\n",
      "BATCH 741/962 - LOSS: 0.0177 - ACCURACY: 1.0000\n",
      "BATCH 761/962 - LOSS: 0.0125 - ACCURACY: 1.0000\n",
      "BATCH 781/962 - LOSS: 0.0149 - ACCURACY: 1.0000\n",
      "BATCH 801/962 - LOSS: 0.0263 - ACCURACY: 1.0000\n",
      "BATCH 821/962 - LOSS: 0.0099 - ACCURACY: 1.0000\n",
      "BATCH 841/962 - LOSS: 0.0105 - ACCURACY: 1.0000\n",
      "BATCH 861/962 - LOSS: 0.0669 - ACCURACY: 1.0000\n",
      "BATCH 881/962 - LOSS: 0.0093 - ACCURACY: 1.0000\n",
      "BATCH 901/962 - LOSS: 0.0153 - ACCURACY: 1.0000\n",
      "BATCH 921/962 - LOSS: 0.0113 - ACCURACY: 1.0000\n",
      "BATCH 941/962 - LOSS: 0.2552 - ACCURACY: 0.8750\n",
      "BATCH 961/962 - LOSS: 0.0237 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH 13 - LOSS: 0.03307023301324662, ACCURACY: 0.995452182952183\n",
      "\n",
      "EPOCH 13 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.4346233253677687, ACCURACY: 0.7018229166666666\n",
      "\n",
      "==================================================\n",
      "EPOCH 14 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 0.0530 - ACCURACY: 1.0000\n",
      "BATCH 21/962 - LOSS: 0.0089 - ACCURACY: 1.0000\n",
      "BATCH 41/962 - LOSS: 0.0469 - ACCURACY: 1.0000\n",
      "BATCH 61/962 - LOSS: 0.0332 - ACCURACY: 1.0000\n",
      "BATCH 81/962 - LOSS: 0.0110 - ACCURACY: 1.0000\n",
      "BATCH 101/962 - LOSS: 0.1047 - ACCURACY: 0.9375\n",
      "BATCH 121/962 - LOSS: 0.0077 - ACCURACY: 1.0000\n",
      "BATCH 141/962 - LOSS: 0.0119 - ACCURACY: 1.0000\n",
      "BATCH 161/962 - LOSS: 0.0461 - ACCURACY: 1.0000\n",
      "BATCH 181/962 - LOSS: 0.0184 - ACCURACY: 1.0000\n",
      "BATCH 201/962 - LOSS: 0.0253 - ACCURACY: 1.0000\n",
      "BATCH 221/962 - LOSS: 0.0100 - ACCURACY: 1.0000\n",
      "BATCH 241/962 - LOSS: 0.0261 - ACCURACY: 1.0000\n",
      "BATCH 261/962 - LOSS: 0.0453 - ACCURACY: 1.0000\n",
      "BATCH 281/962 - LOSS: 0.0165 - ACCURACY: 1.0000\n",
      "BATCH 301/962 - LOSS: 0.0201 - ACCURACY: 1.0000\n",
      "BATCH 321/962 - LOSS: 0.0191 - ACCURACY: 1.0000\n",
      "BATCH 341/962 - LOSS: 0.0187 - ACCURACY: 1.0000\n",
      "BATCH 361/962 - LOSS: 0.0443 - ACCURACY: 1.0000\n",
      "BATCH 381/962 - LOSS: 0.0307 - ACCURACY: 1.0000\n",
      "BATCH 401/962 - LOSS: 0.0096 - ACCURACY: 1.0000\n",
      "BATCH 421/962 - LOSS: 0.0143 - ACCURACY: 1.0000\n",
      "BATCH 441/962 - LOSS: 0.0262 - ACCURACY: 1.0000\n",
      "BATCH 461/962 - LOSS: 0.0104 - ACCURACY: 1.0000\n",
      "BATCH 481/962 - LOSS: 0.0089 - ACCURACY: 1.0000\n",
      "BATCH 501/962 - LOSS: 0.0083 - ACCURACY: 1.0000\n",
      "BATCH 521/962 - LOSS: 0.0071 - ACCURACY: 1.0000\n",
      "BATCH 541/962 - LOSS: 0.0117 - ACCURACY: 1.0000\n",
      "BATCH 561/962 - LOSS: 0.0108 - ACCURACY: 1.0000\n",
      "BATCH 581/962 - LOSS: 0.0090 - ACCURACY: 1.0000\n",
      "BATCH 601/962 - LOSS: 0.0254 - ACCURACY: 1.0000\n",
      "BATCH 621/962 - LOSS: 0.0640 - ACCURACY: 1.0000\n",
      "BATCH 641/962 - LOSS: 0.0117 - ACCURACY: 1.0000\n",
      "BATCH 661/962 - LOSS: 0.0134 - ACCURACY: 1.0000\n",
      "BATCH 681/962 - LOSS: 0.0825 - ACCURACY: 0.9375\n",
      "BATCH 701/962 - LOSS: 0.0101 - ACCURACY: 1.0000\n",
      "BATCH 721/962 - LOSS: 0.0041 - ACCURACY: 1.0000\n",
      "BATCH 741/962 - LOSS: 0.0147 - ACCURACY: 1.0000\n",
      "BATCH 761/962 - LOSS: 0.0281 - ACCURACY: 1.0000\n",
      "BATCH 781/962 - LOSS: 0.0013 - ACCURACY: 1.0000\n",
      "BATCH 801/962 - LOSS: 0.0424 - ACCURACY: 1.0000\n",
      "BATCH 821/962 - LOSS: 0.0141 - ACCURACY: 1.0000\n",
      "BATCH 841/962 - LOSS: 0.0136 - ACCURACY: 1.0000\n",
      "BATCH 861/962 - LOSS: 0.0256 - ACCURACY: 1.0000\n",
      "BATCH 881/962 - LOSS: 0.0280 - ACCURACY: 1.0000\n",
      "BATCH 901/962 - LOSS: 0.0244 - ACCURACY: 1.0000\n",
      "BATCH 921/962 - LOSS: 0.0146 - ACCURACY: 1.0000\n",
      "BATCH 941/962 - LOSS: 0.1164 - ACCURACY: 0.9375\n",
      "BATCH 961/962 - LOSS: 0.0093 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH 14 - LOSS: 0.024670528808125564, ACCURACY: 0.9968165280665281\n",
      "\n",
      "EPOCH 14 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.105878296494484, ACCURACY: 0.7348958333333333\n",
      "\n",
      "==================================================\n",
      "EPOCH 15 - TRAINING...\n",
      "BATCH 1/962 - LOSS: 0.0358 - ACCURACY: 1.0000\n",
      "BATCH 21/962 - LOSS: 0.0115 - ACCURACY: 1.0000\n",
      "BATCH 41/962 - LOSS: 0.0097 - ACCURACY: 1.0000\n",
      "BATCH 61/962 - LOSS: 0.0132 - ACCURACY: 1.0000\n",
      "BATCH 81/962 - LOSS: 0.0216 - ACCURACY: 1.0000\n",
      "BATCH 101/962 - LOSS: 0.0022 - ACCURACY: 1.0000\n",
      "BATCH 121/962 - LOSS: 0.0025 - ACCURACY: 1.0000\n",
      "BATCH 141/962 - LOSS: 0.0101 - ACCURACY: 1.0000\n",
      "BATCH 161/962 - LOSS: 0.0199 - ACCURACY: 1.0000\n",
      "BATCH 181/962 - LOSS: 0.0087 - ACCURACY: 1.0000\n",
      "BATCH 201/962 - LOSS: 0.0053 - ACCURACY: 1.0000\n",
      "BATCH 221/962 - LOSS: 0.0121 - ACCURACY: 1.0000\n",
      "BATCH 241/962 - LOSS: 0.0084 - ACCURACY: 1.0000\n",
      "BATCH 261/962 - LOSS: 0.0129 - ACCURACY: 1.0000\n",
      "BATCH 281/962 - LOSS: 0.0063 - ACCURACY: 1.0000\n",
      "BATCH 301/962 - LOSS: 0.0083 - ACCURACY: 1.0000\n",
      "BATCH 321/962 - LOSS: 0.0039 - ACCURACY: 1.0000\n",
      "BATCH 341/962 - LOSS: 0.0122 - ACCURACY: 1.0000\n",
      "BATCH 361/962 - LOSS: 0.0118 - ACCURACY: 1.0000\n",
      "BATCH 381/962 - LOSS: 0.0050 - ACCURACY: 1.0000\n",
      "BATCH 401/962 - LOSS: 0.0067 - ACCURACY: 1.0000\n",
      "BATCH 421/962 - LOSS: 0.0250 - ACCURACY: 1.0000\n",
      "BATCH 441/962 - LOSS: 0.0091 - ACCURACY: 1.0000\n",
      "BATCH 461/962 - LOSS: 0.0062 - ACCURACY: 1.0000\n",
      "BATCH 481/962 - LOSS: 0.0118 - ACCURACY: 1.0000\n",
      "BATCH 501/962 - LOSS: 0.0178 - ACCURACY: 1.0000\n",
      "BATCH 521/962 - LOSS: 0.0227 - ACCURACY: 1.0000\n",
      "BATCH 541/962 - LOSS: 0.0220 - ACCURACY: 1.0000\n",
      "BATCH 561/962 - LOSS: 0.0456 - ACCURACY: 1.0000\n",
      "BATCH 581/962 - LOSS: 0.0529 - ACCURACY: 1.0000\n",
      "BATCH 601/962 - LOSS: 0.0202 - ACCURACY: 1.0000\n",
      "BATCH 621/962 - LOSS: 0.0201 - ACCURACY: 1.0000\n",
      "BATCH 641/962 - LOSS: 0.0060 - ACCURACY: 1.0000\n",
      "BATCH 661/962 - LOSS: 0.0089 - ACCURACY: 1.0000\n",
      "BATCH 681/962 - LOSS: 0.0642 - ACCURACY: 1.0000\n",
      "BATCH 701/962 - LOSS: 0.0204 - ACCURACY: 1.0000\n",
      "BATCH 721/962 - LOSS: 0.0064 - ACCURACY: 1.0000\n",
      "BATCH 741/962 - LOSS: 0.0102 - ACCURACY: 1.0000\n",
      "BATCH 761/962 - LOSS: 0.0114 - ACCURACY: 1.0000\n",
      "BATCH 781/962 - LOSS: 0.0099 - ACCURACY: 1.0000\n",
      "BATCH 801/962 - LOSS: 0.0111 - ACCURACY: 1.0000\n",
      "BATCH 821/962 - LOSS: 0.0115 - ACCURACY: 1.0000\n",
      "BATCH 841/962 - LOSS: 0.0145 - ACCURACY: 1.0000\n",
      "BATCH 861/962 - LOSS: 0.0539 - ACCURACY: 1.0000\n",
      "BATCH 881/962 - LOSS: 0.0399 - ACCURACY: 1.0000\n",
      "BATCH 901/962 - LOSS: 0.0356 - ACCURACY: 1.0000\n",
      "BATCH 921/962 - LOSS: 0.0110 - ACCURACY: 1.0000\n",
      "BATCH 941/962 - LOSS: 0.1223 - ACCURACY: 0.9375\n",
      "BATCH 961/962 - LOSS: 0.0103 - ACCURACY: 1.0000\n",
      "\n",
      "\t[TRAIN] EPOCH 15 - LOSS: 0.02280555626435792, ACCURACY: 0.9968165280665281\n",
      "\n",
      "EPOCH 15 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.9290202853580316, ACCURACY: 0.62734375\n",
      "\n",
      "Execution time: 3:09:14.095529\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.42      0.39       108\n",
      "           1       0.57      0.61      0.59       218\n",
      "           2       0.76      0.31      0.44       238\n",
      "           3       0.91      0.91      0.91      1309\n",
      "           4       0.47      0.68      0.56       255\n",
      "\n",
      "    accuracy                           0.76      2128\n",
      "   macro avg       0.62      0.59      0.58      2128\n",
      "weighted avg       0.78      0.76      0.75      2128\n",
      "\n",
      "Test Accuracy: 0.7570488721804511\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "a = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1c15221-f2cd-4e3f-9993-ed471025ff02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.47      0.42       194\n",
      "           1       0.55      0.60      0.57       392\n",
      "           2       0.73      0.31      0.44       428\n",
      "           3       0.91      0.89      0.90      2364\n",
      "           4       0.44      0.65      0.52       462\n",
      "\n",
      "    accuracy                           0.75      3840\n",
      "   macro avg       0.60      0.58      0.57      3840\n",
      "weighted avg       0.77      0.75      0.75      3840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "def generate_classification_report(model, valid_loader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # 生成分类报告\n",
    "    report = classification_report(all_labels, all_preds, target_names=[str(i) for i in range(5)])\n",
    "    print(\"Classification Report on Validation Set:\")\n",
    "    print(report)\n",
    "\n",
    "# 加载最好的模型\n",
    "best_model = ResNet16(num_classes=5)\n",
    "best_model.load_state_dict(torch.load('ResNet16.pth'))\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "# 验证集的数据加载器\n",
    "df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "train_df, test_df = model_selection.train_test_split(df, test_size=0.1, random_state=42, shuffle=True, stratify=df.label.values)\n",
    "train_df, valid_df = model_selection.train_test_split(train_df, test_size=0.2, random_state=42, shuffle=True, stratify=train_df.label.values)\n",
    "\n",
    "valid_dataset = CassavaDataset(valid_df, transforms=transforms_valid)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, drop_last=True, num_workers=4)\n",
    "\n",
    "# 生成分类报告\n",
    "generate_classification_report(best_model, valid_loader, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c46fa1d-ce84-4307-adc5-82a49116a131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 1718836,
     "sourceId": 13836,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11405.359736,
   "end_time": "2024-06-05T12:54:23.098613",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-05T09:44:17.738877",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
