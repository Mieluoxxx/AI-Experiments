{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad252ce7-ec2d-4faa-8a0a-3aa111a9dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e64214-c419-46d3-a324-1db6c95f4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51aae06f-bc91-4348-8cb9-c7d27cdb588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general global variables\n",
    "DATA_PATH = \"data/\"\n",
    "TRAIN_PATH = \"data/train_images\"\n",
    "TEST_PATH = \"data/test_images/\"\n",
    "BEST_MODEL = \"weights/AlexNet.pth\"\n",
    "SUBMISSION_FILE = \"submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce0d5c6-2eb1-4965-aa53-a71fb03fb1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model specific global variables\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "LR = 2e-05\n",
    "N_EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6891e636-6c31-4c57-a233-fdc34686d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Helper Class to create the pytorch dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, data_path=DATA_PATH, mode=\"train\", transforms=None):\n",
    "        super().__init__()\n",
    "        self.df_data = df.values\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        self.data_dir = \"train_images\" if mode == \"train\" else \"test_images\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name, label = self.df_data[index]\n",
    "        img_path = os.path.join(self.data_path, self.data_dir, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(img)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a02d6507-234f-4ecc-82de-73c4ea081fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image augmentations\n",
    "transforms_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_valid = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e401677b-4444-4b97-9d3f-ebaf326df248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(AlexNet, self).__init__()\n",
    "        # 定义第一个卷积层\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # 第二个卷积层\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # 三个连续的卷积层\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        # 定义全连接层\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(6400, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            # 输出层\n",
    "            nn.Linear(4096, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def train_one_epoch(self, train_loader, criterion, optimizer, device, writer, epoch):\n",
    "        # keep track of training loss and accuracy\n",
    "        epoch_loss = 0.0\n",
    "        epoch_accuracy = 0.0\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        self.train()  # Set the model to training mode\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if device.type == \"cuda\":\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = self.forward(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # update the model parameters\n",
    "            optimizer.step()\n",
    "            # Calculate Accuracy\n",
    "            accuracy = (output.argmax(dim=1) == target).float().mean().item()\n",
    "            # update training loss and accuracy\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_accuracy += accuracy\n",
    "            if i % 20 == 0:\n",
    "                print(f\"BATCH {i+1}/{len(train_loader)} - LOSS: {loss.item():.4f} - ACCURACY: {accuracy:.4f}\")\n",
    "                writer.add_scalar('Training Loss', loss.item(), epoch * len(train_loader) + i)\n",
    "                writer.add_scalar('Training Accuracy', accuracy, epoch * len(train_loader) + i)\n",
    "\n",
    "        return epoch_loss / len(train_loader), epoch_accuracy / len(train_loader)\n",
    "\n",
    "    def valid_one_epoch(self, valid_loader, criterion, device, writer, epoch):\n",
    "        # keep track of validation loss and accuracy\n",
    "        valid_loss = 0.0\n",
    "        valid_accuracy = 0.0\n",
    "\n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        self.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            for data, target in valid_loader:\n",
    "                # move tensors to GPU if CUDA is available\n",
    "                if device.type == \"cuda\":\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = self.forward(data)\n",
    "                # calculate the batch loss\n",
    "                loss = criterion(output, target)\n",
    "                # Calculate Accuracy\n",
    "                accuracy = (output.argmax(dim=1) == target).float().mean().item()\n",
    "                # update average validation loss and accuracy\n",
    "                valid_loss += loss.item()\n",
    "                valid_accuracy += accuracy\n",
    "\n",
    "            writer.add_scalar('Validation Loss', valid_loss / len(valid_loader), epoch)\n",
    "            writer.add_scalar('Validation Accuracy', valid_accuracy / len(valid_loader), epoch)\n",
    "\n",
    "        return valid_loss / len(valid_loader), valid_accuracy / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a523b3e-7520-4b0b-bdd6-d247320053aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gpu(model, epochs, device, criterion, optimizer, train_loader, valid_loader=None):\n",
    "    writer = SummaryWriter()\n",
    "    valid_loss_min = np.Inf\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "\n",
    "    for epoch in  range(1,epochs+1):  #调用数据和模型进行训练-Log\n",
    "        gc.collect()  #通过gc清理内存\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"EPOCH{epoch}-TRAINING...\")\n",
    "\n",
    "        train_loss,train_acc=model.train_one_epoch(train_loader,criterion,optimizer,device,writer,epoch)\n",
    "        print(f\"\\n\\t[TRAIN] EPOCH{epoch}-LOSS:{train_loss},ACCURACY:{train_acc}\\n\")\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        gc.collect()\n",
    "\n",
    "        #valid\n",
    "        if valid_loader is not None:\n",
    "            gc.collect()\n",
    "            print(f\"EPOCH{epoch}-VALIDATING...\")\n",
    "            valid_loss,valid_acc = model.valid_one_epoch(valid_loader,criterion,device,writer,epoch)\n",
    "            print(f\"\\t[VALID] LOSS:{valid_loss},ACCURACY:{valid_acc}\\n\")\n",
    "            valid_losses.append(valid_loss)\n",
    "            valid_accs.append(valid_acc)\n",
    "            gc.collect()\n",
    "            #save !!!\n",
    "            if valid_loss<=valid_loss_min and epoch!=1:\n",
    "                print(\"Validation loss decreased ({:.4f} -->{:.4f}). Saving model...\".format(valid_loss_min,valid_loss))\n",
    "                torch.save(model.state_dict(), BEST_MODEL)\n",
    "                valid_loss_min=valid_loss\n",
    "    writer.close()\n",
    "    return {\n",
    "        \"train_loss\":train_losses,\n",
    "        \"valid_losses\":valid_losses,\n",
    "        \"train_acc\":train_accs,\n",
    "        \"valid_acces\":valid_accs,   \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8410c732-56cf-4cf9-aaf9-6c981b03a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "    train_df, test_df = model_selection.train_test_split(df, test_size=0.1, random_state=42, shuffle=True, stratify=df.label.values)\n",
    "    train_df, valid_df = model_selection.train_test_split(train_df, test_size=0.2, random_state=42, shuffle=True, stratify=train_df.label.values)\n",
    "\n",
    "    train_dataset = CassavaDataset(train_df, transforms=transforms_train)\n",
    "    valid_dataset = CassavaDataset(valid_df, transforms=transforms_valid)\n",
    "    test_dataset = CassavaDataset(test_df, transforms=transforms_valid)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, drop_last=True, num_workers=4)\n",
    "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, drop_last=True, num_workers=4)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, drop_last=True, num_workers=4)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    lr = LR\n",
    "    model = AlexNet(n_classes=5)\n",
    "    model = model.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training\n",
    "    start_time = datetime.now()\n",
    "    logs = fit_gpu(model=model, epochs=N_EPOCHS, device=device, criterion=criterion, optimizer=optimizer, train_loader=train_loader, valid_loader=valid_loader)\n",
    "    print(f\"Execution time: {datetime.now() - start_time}\")\n",
    "\n",
    "    # Load the best model and evaluate on test set\n",
    "    best_model = AlexNet(n_classes=5)\n",
    "    best_model.load_state_dict(torch.load(BEST_MODEL))\n",
    "    best_model = best_model.to(device)\n",
    "    best_model.eval()\n",
    "\n",
    "    test_labels = []\n",
    "    test_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = best_model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "            test_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(test_labels, test_preds, target_names=[str(i) for i in range(5)]))\n",
    "    print(f\"Test Accuracy: {accuracy_score(test_labels, test_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b5ea858-8bf2-413f-b487-2354a071b309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EPOCH1-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.6143 - ACCURACY: 0.1562\n",
      "BATCH 21/481 - LOSS: 1.2500 - ACCURACY: 0.5938\n",
      "BATCH 41/481 - LOSS: 1.1200 - ACCURACY: 0.6250\n",
      "BATCH 61/481 - LOSS: 1.1914 - ACCURACY: 0.5938\n",
      "BATCH 81/481 - LOSS: 1.1837 - ACCURACY: 0.5938\n",
      "BATCH 101/481 - LOSS: 1.3933 - ACCURACY: 0.4688\n",
      "BATCH 121/481 - LOSS: 1.0283 - ACCURACY: 0.6562\n",
      "BATCH 141/481 - LOSS: 1.3313 - ACCURACY: 0.4688\n",
      "BATCH 161/481 - LOSS: 1.0434 - ACCURACY: 0.6562\n",
      "BATCH 181/481 - LOSS: 1.4426 - ACCURACY: 0.4062\n",
      "BATCH 201/481 - LOSS: 0.9966 - ACCURACY: 0.6875\n",
      "BATCH 221/481 - LOSS: 1.0322 - ACCURACY: 0.6250\n",
      "BATCH 241/481 - LOSS: 0.8726 - ACCURACY: 0.7188\n",
      "BATCH 261/481 - LOSS: 1.5107 - ACCURACY: 0.4062\n",
      "BATCH 281/481 - LOSS: 1.3562 - ACCURACY: 0.4688\n",
      "BATCH 301/481 - LOSS: 0.9648 - ACCURACY: 0.6562\n",
      "BATCH 321/481 - LOSS: 1.0897 - ACCURACY: 0.5625\n",
      "BATCH 341/481 - LOSS: 1.4535 - ACCURACY: 0.4375\n",
      "BATCH 361/481 - LOSS: 1.1168 - ACCURACY: 0.6562\n",
      "BATCH 381/481 - LOSS: 1.0409 - ACCURACY: 0.7500\n",
      "BATCH 401/481 - LOSS: 0.9783 - ACCURACY: 0.7188\n",
      "BATCH 421/481 - LOSS: 1.0128 - ACCURACY: 0.6562\n",
      "BATCH 441/481 - LOSS: 1.1065 - ACCURACY: 0.6250\n",
      "BATCH 461/481 - LOSS: 0.9452 - ACCURACY: 0.6562\n",
      "BATCH 481/481 - LOSS: 0.9243 - ACCURACY: 0.6875\n",
      "\n",
      "\t[TRAIN] EPOCH1-LOSS:1.118022718821147,ACCURACY:0.619737525987526\n",
      "\n",
      "EPOCH1-VALIDATING...\n",
      "\t[VALID] LOSS:1.030776431163152,ACCURACY:0.6338541666666667\n",
      "\n",
      "==================================================\n",
      "EPOCH2-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.2148 - ACCURACY: 0.5000\n",
      "BATCH 21/481 - LOSS: 1.0662 - ACCURACY: 0.6250\n",
      "BATCH 41/481 - LOSS: 1.1025 - ACCURACY: 0.6250\n",
      "BATCH 61/481 - LOSS: 1.0676 - ACCURACY: 0.6250\n",
      "BATCH 81/481 - LOSS: 1.0020 - ACCURACY: 0.6562\n",
      "BATCH 101/481 - LOSS: 1.2314 - ACCURACY: 0.5312\n",
      "BATCH 121/481 - LOSS: 0.8747 - ACCURACY: 0.6875\n",
      "BATCH 141/481 - LOSS: 1.2926 - ACCURACY: 0.4688\n",
      "BATCH 161/481 - LOSS: 0.9815 - ACCURACY: 0.6875\n",
      "BATCH 181/481 - LOSS: 1.2318 - ACCURACY: 0.5938\n",
      "BATCH 201/481 - LOSS: 0.8563 - ACCURACY: 0.7188\n",
      "BATCH 221/481 - LOSS: 1.0066 - ACCURACY: 0.6250\n",
      "BATCH 241/481 - LOSS: 0.8822 - ACCURACY: 0.7188\n",
      "BATCH 261/481 - LOSS: 1.2843 - ACCURACY: 0.5000\n",
      "BATCH 281/481 - LOSS: 1.2701 - ACCURACY: 0.5000\n",
      "BATCH 301/481 - LOSS: 0.9215 - ACCURACY: 0.6875\n",
      "BATCH 321/481 - LOSS: 1.0947 - ACCURACY: 0.6250\n",
      "BATCH 341/481 - LOSS: 1.2895 - ACCURACY: 0.4375\n",
      "BATCH 361/481 - LOSS: 0.9686 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.9693 - ACCURACY: 0.6250\n",
      "BATCH 401/481 - LOSS: 0.8650 - ACCURACY: 0.6875\n",
      "BATCH 421/481 - LOSS: 0.9422 - ACCURACY: 0.6250\n",
      "BATCH 441/481 - LOSS: 1.0425 - ACCURACY: 0.5938\n",
      "BATCH 461/481 - LOSS: 0.9137 - ACCURACY: 0.5938\n",
      "BATCH 481/481 - LOSS: 0.8391 - ACCURACY: 0.6875\n",
      "\n",
      "\t[TRAIN] EPOCH2-LOSS:1.0022796047948255,ACCURACY:0.6422817047817048\n",
      "\n",
      "EPOCH2-VALIDATING...\n",
      "\t[VALID] LOSS:0.9853079572319985,ACCURACY:0.6447916666666667\n",
      "\n",
      "Validation loss decreased (inf -->0.9853). Saving model...\n",
      "==================================================\n",
      "EPOCH3-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.2099 - ACCURACY: 0.5000\n",
      "BATCH 21/481 - LOSS: 1.0570 - ACCURACY: 0.6250\n",
      "BATCH 41/481 - LOSS: 1.0597 - ACCURACY: 0.6562\n",
      "BATCH 61/481 - LOSS: 1.0268 - ACCURACY: 0.6250\n",
      "BATCH 81/481 - LOSS: 0.9252 - ACCURACY: 0.6562\n",
      "BATCH 101/481 - LOSS: 1.1196 - ACCURACY: 0.5625\n",
      "BATCH 121/481 - LOSS: 0.8821 - ACCURACY: 0.6562\n",
      "BATCH 141/481 - LOSS: 1.2075 - ACCURACY: 0.5312\n",
      "BATCH 161/481 - LOSS: 0.9444 - ACCURACY: 0.7188\n",
      "BATCH 181/481 - LOSS: 1.1982 - ACCURACY: 0.5000\n",
      "BATCH 201/481 - LOSS: 0.7977 - ACCURACY: 0.7812\n",
      "BATCH 221/481 - LOSS: 0.9965 - ACCURACY: 0.6250\n",
      "BATCH 241/481 - LOSS: 0.8458 - ACCURACY: 0.7188\n",
      "BATCH 261/481 - LOSS: 1.2518 - ACCURACY: 0.5000\n",
      "BATCH 281/481 - LOSS: 1.2701 - ACCURACY: 0.5000\n",
      "BATCH 301/481 - LOSS: 0.8710 - ACCURACY: 0.6875\n",
      "BATCH 321/481 - LOSS: 1.0867 - ACCURACY: 0.5625\n",
      "BATCH 341/481 - LOSS: 1.2368 - ACCURACY: 0.4688\n",
      "BATCH 361/481 - LOSS: 0.9549 - ACCURACY: 0.6562\n",
      "BATCH 381/481 - LOSS: 0.9133 - ACCURACY: 0.6250\n",
      "BATCH 401/481 - LOSS: 0.8462 - ACCURACY: 0.6875\n",
      "BATCH 421/481 - LOSS: 0.9378 - ACCURACY: 0.6250\n",
      "BATCH 441/481 - LOSS: 1.0157 - ACCURACY: 0.5938\n",
      "BATCH 461/481 - LOSS: 0.8882 - ACCURACY: 0.6875\n",
      "BATCH 481/481 - LOSS: 0.8248 - ACCURACY: 0.6875\n",
      "\n",
      "\t[TRAIN] EPOCH3-LOSS:0.9709909286295798,ACCURACY:0.6507926195426196\n",
      "\n",
      "EPOCH3-VALIDATING...\n",
      "\t[VALID] LOSS:0.9746487572789192,ACCURACY:0.64453125\n",
      "\n",
      "Validation loss decreased (0.9853 -->0.9746). Saving model...\n",
      "==================================================\n",
      "EPOCH4-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.1517 - ACCURACY: 0.5000\n",
      "BATCH 21/481 - LOSS: 1.0114 - ACCURACY: 0.6562\n",
      "BATCH 41/481 - LOSS: 1.0914 - ACCURACY: 0.6562\n",
      "BATCH 61/481 - LOSS: 0.9804 - ACCURACY: 0.6250\n",
      "BATCH 81/481 - LOSS: 0.8780 - ACCURACY: 0.6250\n",
      "BATCH 101/481 - LOSS: 1.1182 - ACCURACY: 0.5625\n",
      "BATCH 121/481 - LOSS: 0.8361 - ACCURACY: 0.6875\n",
      "BATCH 141/481 - LOSS: 1.1693 - ACCURACY: 0.5312\n",
      "BATCH 161/481 - LOSS: 0.9037 - ACCURACY: 0.7188\n",
      "BATCH 181/481 - LOSS: 1.1693 - ACCURACY: 0.5625\n",
      "BATCH 201/481 - LOSS: 0.7701 - ACCURACY: 0.7812\n",
      "BATCH 221/481 - LOSS: 0.9396 - ACCURACY: 0.6562\n",
      "BATCH 241/481 - LOSS: 0.8827 - ACCURACY: 0.7188\n",
      "BATCH 261/481 - LOSS: 1.2260 - ACCURACY: 0.5625\n",
      "BATCH 281/481 - LOSS: 1.2478 - ACCURACY: 0.5000\n",
      "BATCH 301/481 - LOSS: 0.9052 - ACCURACY: 0.6875\n",
      "BATCH 321/481 - LOSS: 1.0715 - ACCURACY: 0.6562\n",
      "BATCH 341/481 - LOSS: 1.2508 - ACCURACY: 0.4375\n",
      "BATCH 361/481 - LOSS: 0.9274 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.8717 - ACCURACY: 0.6562\n",
      "BATCH 401/481 - LOSS: 0.8179 - ACCURACY: 0.6250\n",
      "BATCH 421/481 - LOSS: 0.8795 - ACCURACY: 0.6562\n",
      "BATCH 441/481 - LOSS: 0.9892 - ACCURACY: 0.6250\n",
      "BATCH 461/481 - LOSS: 0.9459 - ACCURACY: 0.6875\n",
      "BATCH 481/481 - LOSS: 0.7683 - ACCURACY: 0.7188\n",
      "\n",
      "\t[TRAIN] EPOCH4-LOSS:0.9505190322032342,ACCURACY:0.654170997920998\n",
      "\n",
      "EPOCH4-VALIDATING...\n",
      "\t[VALID] LOSS:0.9628104425966739,ACCURACY:0.64453125\n",
      "\n",
      "Validation loss decreased (0.9746 -->0.9628). Saving model...\n",
      "==================================================\n",
      "EPOCH5-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.1681 - ACCURACY: 0.5000\n",
      "BATCH 21/481 - LOSS: 0.9906 - ACCURACY: 0.6250\n",
      "BATCH 41/481 - LOSS: 1.0746 - ACCURACY: 0.6562\n",
      "BATCH 61/481 - LOSS: 0.9477 - ACCURACY: 0.6250\n",
      "BATCH 81/481 - LOSS: 0.8791 - ACCURACY: 0.5938\n",
      "BATCH 101/481 - LOSS: 1.0946 - ACCURACY: 0.5938\n",
      "BATCH 121/481 - LOSS: 0.8534 - ACCURACY: 0.6562\n",
      "BATCH 141/481 - LOSS: 1.1488 - ACCURACY: 0.5625\n",
      "BATCH 161/481 - LOSS: 0.8989 - ACCURACY: 0.7188\n",
      "BATCH 181/481 - LOSS: 1.1486 - ACCURACY: 0.5938\n",
      "BATCH 201/481 - LOSS: 0.7517 - ACCURACY: 0.7812\n",
      "BATCH 221/481 - LOSS: 0.9045 - ACCURACY: 0.6562\n",
      "BATCH 241/481 - LOSS: 0.8493 - ACCURACY: 0.7188\n",
      "BATCH 261/481 - LOSS: 1.1506 - ACCURACY: 0.5625\n",
      "BATCH 281/481 - LOSS: 1.2234 - ACCURACY: 0.5312\n",
      "BATCH 301/481 - LOSS: 0.8542 - ACCURACY: 0.6875\n",
      "BATCH 321/481 - LOSS: 1.1174 - ACCURACY: 0.6250\n",
      "BATCH 341/481 - LOSS: 1.2083 - ACCURACY: 0.4375\n",
      "BATCH 361/481 - LOSS: 0.9240 - ACCURACY: 0.6562\n",
      "BATCH 381/481 - LOSS: 0.8232 - ACCURACY: 0.7188\n",
      "BATCH 401/481 - LOSS: 0.7717 - ACCURACY: 0.6250\n",
      "BATCH 421/481 - LOSS: 0.8951 - ACCURACY: 0.6875\n",
      "BATCH 441/481 - LOSS: 0.9396 - ACCURACY: 0.6250\n",
      "BATCH 461/481 - LOSS: 0.9045 - ACCURACY: 0.6562\n",
      "BATCH 481/481 - LOSS: 0.7535 - ACCURACY: 0.7188\n",
      "\n",
      "\t[TRAIN] EPOCH5-LOSS:0.9291285116558511,ACCURACY:0.6603430353430353\n",
      "\n",
      "EPOCH5-VALIDATING...\n",
      "\t[VALID] LOSS:0.9431842145820458,ACCURACY:0.6502604166666667\n",
      "\n",
      "Validation loss decreased (0.9628 -->0.9432). Saving model...\n",
      "==================================================\n",
      "EPOCH6-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.1622 - ACCURACY: 0.5000\n",
      "BATCH 21/481 - LOSS: 0.9562 - ACCURACY: 0.6875\n",
      "BATCH 41/481 - LOSS: 1.0453 - ACCURACY: 0.6562\n",
      "BATCH 61/481 - LOSS: 0.9296 - ACCURACY: 0.6562\n",
      "BATCH 81/481 - LOSS: 0.8389 - ACCURACY: 0.6250\n",
      "BATCH 101/481 - LOSS: 1.0679 - ACCURACY: 0.6562\n",
      "BATCH 121/481 - LOSS: 0.8664 - ACCURACY: 0.6250\n",
      "BATCH 141/481 - LOSS: 1.1238 - ACCURACY: 0.5312\n",
      "BATCH 161/481 - LOSS: 0.8580 - ACCURACY: 0.7188\n",
      "BATCH 181/481 - LOSS: 1.1104 - ACCURACY: 0.6250\n",
      "BATCH 201/481 - LOSS: 0.6846 - ACCURACY: 0.7812\n",
      "BATCH 221/481 - LOSS: 0.8947 - ACCURACY: 0.6562\n",
      "BATCH 241/481 - LOSS: 0.8151 - ACCURACY: 0.7188\n",
      "BATCH 261/481 - LOSS: 1.1313 - ACCURACY: 0.5312\n",
      "BATCH 281/481 - LOSS: 1.1742 - ACCURACY: 0.4688\n",
      "BATCH 301/481 - LOSS: 0.8289 - ACCURACY: 0.6875\n",
      "BATCH 321/481 - LOSS: 1.1117 - ACCURACY: 0.6562\n",
      "BATCH 341/481 - LOSS: 1.2046 - ACCURACY: 0.4688\n",
      "BATCH 361/481 - LOSS: 0.8821 - ACCURACY: 0.6562\n",
      "BATCH 381/481 - LOSS: 0.7816 - ACCURACY: 0.7188\n",
      "BATCH 401/481 - LOSS: 0.6726 - ACCURACY: 0.7188\n",
      "BATCH 421/481 - LOSS: 0.8443 - ACCURACY: 0.7188\n",
      "BATCH 441/481 - LOSS: 0.9697 - ACCURACY: 0.5625\n",
      "BATCH 461/481 - LOSS: 0.8996 - ACCURACY: 0.6562\n",
      "BATCH 481/481 - LOSS: 0.7488 - ACCURACY: 0.7188\n",
      "\n",
      "\t[TRAIN] EPOCH6-LOSS:0.901385304771689,ACCURACY:0.6724272349272349\n",
      "\n",
      "EPOCH6-VALIDATING...\n",
      "\t[VALID] LOSS:0.9131216583152612,ACCURACY:0.6619791666666667\n",
      "\n",
      "Validation loss decreased (0.9432 -->0.9131). Saving model...\n",
      "==================================================\n",
      "EPOCH7-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.1456 - ACCURACY: 0.5312\n",
      "BATCH 21/481 - LOSS: 0.9024 - ACCURACY: 0.7188\n",
      "BATCH 41/481 - LOSS: 0.9753 - ACCURACY: 0.6875\n",
      "BATCH 61/481 - LOSS: 0.8347 - ACCURACY: 0.7500\n",
      "BATCH 81/481 - LOSS: 0.8134 - ACCURACY: 0.6250\n",
      "BATCH 101/481 - LOSS: 0.9769 - ACCURACY: 0.6250\n",
      "BATCH 121/481 - LOSS: 0.8448 - ACCURACY: 0.6250\n",
      "BATCH 141/481 - LOSS: 1.1913 - ACCURACY: 0.5312\n",
      "BATCH 161/481 - LOSS: 0.8485 - ACCURACY: 0.7188\n",
      "BATCH 181/481 - LOSS: 1.0607 - ACCURACY: 0.6250\n",
      "BATCH 201/481 - LOSS: 0.6793 - ACCURACY: 0.7812\n",
      "BATCH 221/481 - LOSS: 0.8342 - ACCURACY: 0.6875\n",
      "BATCH 241/481 - LOSS: 0.7811 - ACCURACY: 0.7188\n",
      "BATCH 261/481 - LOSS: 1.0858 - ACCURACY: 0.5625\n",
      "BATCH 281/481 - LOSS: 1.1041 - ACCURACY: 0.5312\n",
      "BATCH 301/481 - LOSS: 0.7592 - ACCURACY: 0.6875\n",
      "BATCH 321/481 - LOSS: 1.0487 - ACCURACY: 0.6250\n",
      "BATCH 341/481 - LOSS: 1.1876 - ACCURACY: 0.5000\n",
      "BATCH 361/481 - LOSS: 0.8412 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.7571 - ACCURACY: 0.7188\n",
      "BATCH 401/481 - LOSS: 0.6604 - ACCURACY: 0.7188\n",
      "BATCH 421/481 - LOSS: 0.8125 - ACCURACY: 0.7188\n",
      "BATCH 441/481 - LOSS: 1.0168 - ACCURACY: 0.5625\n",
      "BATCH 461/481 - LOSS: 0.9172 - ACCURACY: 0.6562\n",
      "BATCH 481/481 - LOSS: 0.7479 - ACCURACY: 0.7188\n",
      "\n",
      "\t[TRAIN] EPOCH7-LOSS:0.8713594556722225,ACCURACY:0.6775597713097713\n",
      "\n",
      "EPOCH7-VALIDATING...\n",
      "\t[VALID] LOSS:0.898034309844176,ACCURACY:0.665625\n",
      "\n",
      "Validation loss decreased (0.9131 -->0.8980). Saving model...\n",
      "==================================================\n",
      "EPOCH8-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.1537 - ACCURACY: 0.5625\n",
      "BATCH 21/481 - LOSS: 0.9127 - ACCURACY: 0.6875\n",
      "BATCH 41/481 - LOSS: 0.8542 - ACCURACY: 0.6875\n",
      "BATCH 61/481 - LOSS: 0.8041 - ACCURACY: 0.7812\n",
      "BATCH 81/481 - LOSS: 0.7960 - ACCURACY: 0.6250\n",
      "BATCH 101/481 - LOSS: 0.9075 - ACCURACY: 0.6875\n",
      "BATCH 121/481 - LOSS: 0.8195 - ACCURACY: 0.6875\n",
      "BATCH 141/481 - LOSS: 1.0996 - ACCURACY: 0.5312\n",
      "BATCH 161/481 - LOSS: 0.8017 - ACCURACY: 0.6875\n",
      "BATCH 181/481 - LOSS: 1.0894 - ACCURACY: 0.5625\n",
      "BATCH 201/481 - LOSS: 0.6174 - ACCURACY: 0.7812\n",
      "BATCH 221/481 - LOSS: 0.8357 - ACCURACY: 0.7188\n",
      "BATCH 241/481 - LOSS: 0.7090 - ACCURACY: 0.7812\n",
      "BATCH 261/481 - LOSS: 1.0415 - ACCURACY: 0.5625\n",
      "BATCH 281/481 - LOSS: 1.0737 - ACCURACY: 0.5625\n",
      "BATCH 301/481 - LOSS: 0.7740 - ACCURACY: 0.7188\n",
      "BATCH 321/481 - LOSS: 1.0733 - ACCURACY: 0.6250\n",
      "BATCH 341/481 - LOSS: 1.1732 - ACCURACY: 0.5312\n",
      "BATCH 361/481 - LOSS: 0.8059 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.7667 - ACCURACY: 0.7188\n",
      "BATCH 401/481 - LOSS: 0.6386 - ACCURACY: 0.7188\n",
      "BATCH 421/481 - LOSS: 0.7350 - ACCURACY: 0.7812\n",
      "BATCH 441/481 - LOSS: 0.9795 - ACCURACY: 0.5625\n",
      "BATCH 461/481 - LOSS: 0.9350 - ACCURACY: 0.6250\n",
      "BATCH 481/481 - LOSS: 0.7734 - ACCURACY: 0.6875\n",
      "\n",
      "\t[TRAIN] EPOCH8-LOSS:0.8394249471334311,ACCURACY:0.6876299376299376\n",
      "\n",
      "EPOCH8-VALIDATING...\n",
      "\t[VALID] LOSS:0.8892427670458952,ACCURACY:0.6638020833333333\n",
      "\n",
      "Validation loss decreased (0.8980 -->0.8892). Saving model...\n",
      "==================================================\n",
      "EPOCH9-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.1907 - ACCURACY: 0.5625\n",
      "BATCH 21/481 - LOSS: 0.9050 - ACCURACY: 0.6562\n",
      "BATCH 41/481 - LOSS: 0.8186 - ACCURACY: 0.7188\n",
      "BATCH 61/481 - LOSS: 0.7774 - ACCURACY: 0.8125\n",
      "BATCH 81/481 - LOSS: 0.8153 - ACCURACY: 0.6250\n",
      "BATCH 101/481 - LOSS: 0.8886 - ACCURACY: 0.7188\n",
      "BATCH 121/481 - LOSS: 0.7685 - ACCURACY: 0.6875\n",
      "BATCH 141/481 - LOSS: 1.0693 - ACCURACY: 0.5312\n",
      "BATCH 161/481 - LOSS: 0.8241 - ACCURACY: 0.6562\n",
      "BATCH 181/481 - LOSS: 1.0991 - ACCURACY: 0.5625\n",
      "BATCH 201/481 - LOSS: 0.6466 - ACCURACY: 0.7500\n",
      "BATCH 221/481 - LOSS: 0.8062 - ACCURACY: 0.6875\n",
      "BATCH 241/481 - LOSS: 0.7658 - ACCURACY: 0.7812\n",
      "BATCH 261/481 - LOSS: 1.0186 - ACCURACY: 0.5625\n",
      "BATCH 281/481 - LOSS: 1.0983 - ACCURACY: 0.5312\n",
      "BATCH 301/481 - LOSS: 0.7629 - ACCURACY: 0.7188\n",
      "BATCH 321/481 - LOSS: 1.0481 - ACCURACY: 0.6562\n",
      "BATCH 341/481 - LOSS: 1.1263 - ACCURACY: 0.5625\n",
      "BATCH 361/481 - LOSS: 0.7502 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.7428 - ACCURACY: 0.7188\n",
      "BATCH 401/481 - LOSS: 0.5751 - ACCURACY: 0.8125\n",
      "BATCH 421/481 - LOSS: 0.7172 - ACCURACY: 0.7812\n",
      "BATCH 441/481 - LOSS: 0.9700 - ACCURACY: 0.5938\n",
      "BATCH 461/481 - LOSS: 0.9270 - ACCURACY: 0.6250\n",
      "BATCH 481/481 - LOSS: 0.8018 - ACCURACY: 0.6875\n",
      "\n",
      "\t[TRAIN] EPOCH9-LOSS:0.8096893992344704,ACCURACY:0.6952312889812889\n",
      "\n",
      "EPOCH9-VALIDATING...\n",
      "\t[VALID] LOSS:0.8856538611153761,ACCURACY:0.6684895833333333\n",
      "\n",
      "Validation loss decreased (0.8892 -->0.8857). Saving model...\n",
      "==================================================\n",
      "EPOCH10-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.2101 - ACCURACY: 0.5625\n",
      "BATCH 21/481 - LOSS: 0.8912 - ACCURACY: 0.6562\n",
      "BATCH 41/481 - LOSS: 0.7551 - ACCURACY: 0.7500\n",
      "BATCH 61/481 - LOSS: 0.7462 - ACCURACY: 0.8125\n",
      "BATCH 81/481 - LOSS: 0.7905 - ACCURACY: 0.6250\n",
      "BATCH 101/481 - LOSS: 0.8380 - ACCURACY: 0.7188\n",
      "BATCH 121/481 - LOSS: 0.7213 - ACCURACY: 0.7188\n",
      "BATCH 141/481 - LOSS: 1.0013 - ACCURACY: 0.5312\n",
      "BATCH 161/481 - LOSS: 0.7684 - ACCURACY: 0.6875\n",
      "BATCH 181/481 - LOSS: 1.1123 - ACCURACY: 0.5625\n",
      "BATCH 201/481 - LOSS: 0.6246 - ACCURACY: 0.7500\n",
      "BATCH 221/481 - LOSS: 0.7546 - ACCURACY: 0.6875\n",
      "BATCH 241/481 - LOSS: 0.7110 - ACCURACY: 0.7812\n",
      "BATCH 261/481 - LOSS: 0.9959 - ACCURACY: 0.5938\n",
      "BATCH 281/481 - LOSS: 1.0883 - ACCURACY: 0.4688\n",
      "BATCH 301/481 - LOSS: 0.7254 - ACCURACY: 0.7188\n",
      "BATCH 321/481 - LOSS: 0.9996 - ACCURACY: 0.6875\n",
      "BATCH 341/481 - LOSS: 1.0841 - ACCURACY: 0.5312\n",
      "BATCH 361/481 - LOSS: 0.6911 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.7166 - ACCURACY: 0.7188\n",
      "BATCH 401/481 - LOSS: 0.5726 - ACCURACY: 0.7812\n",
      "BATCH 421/481 - LOSS: 0.6763 - ACCURACY: 0.7500\n",
      "BATCH 441/481 - LOSS: 0.9588 - ACCURACY: 0.6562\n",
      "BATCH 461/481 - LOSS: 0.9046 - ACCURACY: 0.6875\n",
      "BATCH 481/481 - LOSS: 0.7882 - ACCURACY: 0.6875\n",
      "\n",
      "\t[TRAIN] EPOCH10-LOSS:0.781421093212096,ACCURACY:0.7048466735966736\n",
      "\n",
      "EPOCH10-VALIDATING...\n",
      "\t[VALID] LOSS:0.8876160239179929,ACCURACY:0.6643229166666667\n",
      "\n",
      "==================================================\n",
      "EPOCH11-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.1704 - ACCURACY: 0.5938\n",
      "BATCH 21/481 - LOSS: 0.8566 - ACCURACY: 0.6562\n",
      "BATCH 41/481 - LOSS: 0.6900 - ACCURACY: 0.7500\n",
      "BATCH 61/481 - LOSS: 0.7467 - ACCURACY: 0.8125\n",
      "BATCH 81/481 - LOSS: 0.7920 - ACCURACY: 0.6250\n",
      "BATCH 101/481 - LOSS: 0.8120 - ACCURACY: 0.7500\n",
      "BATCH 121/481 - LOSS: 0.6914 - ACCURACY: 0.7500\n",
      "BATCH 141/481 - LOSS: 0.9712 - ACCURACY: 0.5312\n",
      "BATCH 161/481 - LOSS: 0.7788 - ACCURACY: 0.6875\n",
      "BATCH 181/481 - LOSS: 1.0487 - ACCURACY: 0.5938\n",
      "BATCH 201/481 - LOSS: 0.6568 - ACCURACY: 0.7188\n",
      "BATCH 221/481 - LOSS: 0.7024 - ACCURACY: 0.7188\n",
      "BATCH 241/481 - LOSS: 0.7011 - ACCURACY: 0.7500\n",
      "BATCH 261/481 - LOSS: 0.9788 - ACCURACY: 0.5625\n",
      "BATCH 281/481 - LOSS: 1.0365 - ACCURACY: 0.5312\n",
      "BATCH 301/481 - LOSS: 0.6866 - ACCURACY: 0.7188\n",
      "BATCH 321/481 - LOSS: 1.0159 - ACCURACY: 0.6875\n",
      "BATCH 341/481 - LOSS: 0.9853 - ACCURACY: 0.5625\n",
      "BATCH 361/481 - LOSS: 0.6554 - ACCURACY: 0.7500\n",
      "BATCH 381/481 - LOSS: 0.6880 - ACCURACY: 0.7188\n",
      "BATCH 401/481 - LOSS: 0.5503 - ACCURACY: 0.8125\n",
      "BATCH 421/481 - LOSS: 0.6213 - ACCURACY: 0.7500\n",
      "BATCH 441/481 - LOSS: 0.9222 - ACCURACY: 0.6562\n",
      "BATCH 461/481 - LOSS: 0.9388 - ACCURACY: 0.5938\n",
      "BATCH 481/481 - LOSS: 0.7746 - ACCURACY: 0.6875\n",
      "\n",
      "\t[TRAIN] EPOCH11-LOSS:0.7493261630470688,ACCURACY:0.7163461538461539\n",
      "\n",
      "EPOCH11-VALIDATING...\n",
      "\t[VALID] LOSS:0.8886810819307963,ACCURACY:0.6671875\n",
      "\n",
      "==================================================\n",
      "EPOCH12-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.2244 - ACCURACY: 0.5625\n",
      "BATCH 21/481 - LOSS: 0.7845 - ACCURACY: 0.6875\n",
      "BATCH 41/481 - LOSS: 0.6221 - ACCURACY: 0.7812\n",
      "BATCH 61/481 - LOSS: 0.7240 - ACCURACY: 0.7812\n",
      "BATCH 81/481 - LOSS: 0.7951 - ACCURACY: 0.6562\n",
      "BATCH 101/481 - LOSS: 0.7673 - ACCURACY: 0.7500\n",
      "BATCH 121/481 - LOSS: 0.6281 - ACCURACY: 0.7188\n",
      "BATCH 141/481 - LOSS: 0.8480 - ACCURACY: 0.5938\n",
      "BATCH 161/481 - LOSS: 0.7424 - ACCURACY: 0.6875\n",
      "BATCH 181/481 - LOSS: 1.0228 - ACCURACY: 0.6250\n",
      "BATCH 201/481 - LOSS: 0.6501 - ACCURACY: 0.6875\n",
      "BATCH 221/481 - LOSS: 0.6828 - ACCURACY: 0.7500\n",
      "BATCH 241/481 - LOSS: 0.6408 - ACCURACY: 0.7812\n",
      "BATCH 261/481 - LOSS: 0.9113 - ACCURACY: 0.5938\n",
      "BATCH 281/481 - LOSS: 1.0229 - ACCURACY: 0.5312\n",
      "BATCH 301/481 - LOSS: 0.6623 - ACCURACY: 0.7188\n",
      "BATCH 321/481 - LOSS: 0.9776 - ACCURACY: 0.6562\n",
      "BATCH 341/481 - LOSS: 0.9403 - ACCURACY: 0.5938\n",
      "BATCH 361/481 - LOSS: 0.5901 - ACCURACY: 0.7188\n",
      "BATCH 381/481 - LOSS: 0.6366 - ACCURACY: 0.7500\n",
      "BATCH 401/481 - LOSS: 0.5530 - ACCURACY: 0.8438\n",
      "BATCH 421/481 - LOSS: 0.5755 - ACCURACY: 0.7500\n",
      "BATCH 441/481 - LOSS: 0.8934 - ACCURACY: 0.7188\n",
      "BATCH 461/481 - LOSS: 0.8817 - ACCURACY: 0.6250\n",
      "BATCH 481/481 - LOSS: 0.7939 - ACCURACY: 0.6875\n",
      "\n",
      "\t[TRAIN] EPOCH12-LOSS:0.71534527711214,ACCURACY:0.7283004158004158\n",
      "\n",
      "EPOCH12-VALIDATING...\n",
      "\t[VALID] LOSS:0.8898410802086194,ACCURACY:0.6677083333333333\n",
      "\n",
      "==================================================\n",
      "EPOCH13-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.1794 - ACCURACY: 0.5625\n",
      "BATCH 21/481 - LOSS: 0.7315 - ACCURACY: 0.7188\n",
      "BATCH 41/481 - LOSS: 0.5137 - ACCURACY: 0.7500\n",
      "BATCH 61/481 - LOSS: 0.7037 - ACCURACY: 0.8125\n",
      "BATCH 81/481 - LOSS: 0.7557 - ACCURACY: 0.5938\n",
      "BATCH 101/481 - LOSS: 0.7301 - ACCURACY: 0.7500\n",
      "BATCH 121/481 - LOSS: 0.6495 - ACCURACY: 0.7812\n",
      "BATCH 141/481 - LOSS: 0.8092 - ACCURACY: 0.6562\n",
      "BATCH 161/481 - LOSS: 0.7286 - ACCURACY: 0.7812\n",
      "BATCH 181/481 - LOSS: 0.9447 - ACCURACY: 0.6562\n",
      "BATCH 201/481 - LOSS: 0.6545 - ACCURACY: 0.6562\n",
      "BATCH 221/481 - LOSS: 0.6283 - ACCURACY: 0.7188\n",
      "BATCH 241/481 - LOSS: 0.4726 - ACCURACY: 0.8125\n",
      "BATCH 261/481 - LOSS: 0.8802 - ACCURACY: 0.6250\n",
      "BATCH 281/481 - LOSS: 1.0393 - ACCURACY: 0.5312\n",
      "BATCH 301/481 - LOSS: 0.6472 - ACCURACY: 0.7500\n",
      "BATCH 321/481 - LOSS: 0.9478 - ACCURACY: 0.6250\n",
      "BATCH 341/481 - LOSS: 0.9114 - ACCURACY: 0.5625\n",
      "BATCH 361/481 - LOSS: 0.5756 - ACCURACY: 0.6875\n",
      "BATCH 381/481 - LOSS: 0.5900 - ACCURACY: 0.8438\n",
      "BATCH 401/481 - LOSS: 0.5140 - ACCURACY: 0.8438\n",
      "BATCH 421/481 - LOSS: 0.5566 - ACCURACY: 0.7812\n",
      "BATCH 441/481 - LOSS: 0.8667 - ACCURACY: 0.6875\n",
      "BATCH 461/481 - LOSS: 0.8136 - ACCURACY: 0.7188\n",
      "BATCH 481/481 - LOSS: 0.7754 - ACCURACY: 0.6875\n",
      "\n",
      "\t[TRAIN] EPOCH13-LOSS:0.6757318745222012,ACCURACY:0.7423986486486487\n",
      "\n",
      "EPOCH13-VALIDATING...\n",
      "\t[VALID] LOSS:0.9096878185868263,ACCURACY:0.6752604166666667\n",
      "\n",
      "==================================================\n",
      "EPOCH14-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.1394 - ACCURACY: 0.5938\n",
      "BATCH 21/481 - LOSS: 0.7040 - ACCURACY: 0.7188\n",
      "BATCH 41/481 - LOSS: 0.4534 - ACCURACY: 0.8125\n",
      "BATCH 61/481 - LOSS: 0.6491 - ACCURACY: 0.8125\n",
      "BATCH 81/481 - LOSS: 0.7314 - ACCURACY: 0.6250\n",
      "BATCH 101/481 - LOSS: 0.6499 - ACCURACY: 0.7812\n",
      "BATCH 121/481 - LOSS: 0.6507 - ACCURACY: 0.7812\n",
      "BATCH 141/481 - LOSS: 0.7968 - ACCURACY: 0.6875\n",
      "BATCH 161/481 - LOSS: 0.6479 - ACCURACY: 0.8125\n",
      "BATCH 181/481 - LOSS: 0.9146 - ACCURACY: 0.6562\n",
      "BATCH 201/481 - LOSS: 0.6244 - ACCURACY: 0.6562\n",
      "BATCH 221/481 - LOSS: 0.5703 - ACCURACY: 0.7188\n",
      "BATCH 241/481 - LOSS: 0.4744 - ACCURACY: 0.8125\n",
      "BATCH 261/481 - LOSS: 0.8467 - ACCURACY: 0.6562\n",
      "BATCH 281/481 - LOSS: 0.8937 - ACCURACY: 0.6250\n",
      "BATCH 301/481 - LOSS: 0.5863 - ACCURACY: 0.7500\n",
      "BATCH 321/481 - LOSS: 0.8528 - ACCURACY: 0.6250\n",
      "BATCH 341/481 - LOSS: 0.8034 - ACCURACY: 0.6562\n",
      "BATCH 361/481 - LOSS: 0.4688 - ACCURACY: 0.8125\n",
      "BATCH 381/481 - LOSS: 0.5425 - ACCURACY: 0.8438\n",
      "BATCH 401/481 - LOSS: 0.5335 - ACCURACY: 0.8750\n",
      "BATCH 421/481 - LOSS: 0.4815 - ACCURACY: 0.7812\n",
      "BATCH 441/481 - LOSS: 0.8599 - ACCURACY: 0.6250\n",
      "BATCH 461/481 - LOSS: 0.7554 - ACCURACY: 0.6875\n",
      "BATCH 481/481 - LOSS: 0.7629 - ACCURACY: 0.6875\n",
      "\n",
      "\t[TRAIN] EPOCH14-LOSS:0.6380180969307675,ACCURACY:0.7576013513513513\n",
      "\n",
      "EPOCH14-VALIDATING...\n",
      "\t[VALID] LOSS:0.938729873796304,ACCURACY:0.6755208333333333\n",
      "\n",
      "==================================================\n",
      "EPOCH15-TRAINING...\n",
      "BATCH 1/481 - LOSS: 1.1108 - ACCURACY: 0.6250\n",
      "BATCH 21/481 - LOSS: 0.7196 - ACCURACY: 0.6875\n",
      "BATCH 41/481 - LOSS: 0.3940 - ACCURACY: 0.8125\n",
      "BATCH 61/481 - LOSS: 0.6251 - ACCURACY: 0.8125\n",
      "BATCH 81/481 - LOSS: 0.6634 - ACCURACY: 0.6562\n",
      "BATCH 101/481 - LOSS: 0.6443 - ACCURACY: 0.7812\n",
      "BATCH 121/481 - LOSS: 0.6665 - ACCURACY: 0.7500\n",
      "BATCH 141/481 - LOSS: 0.6929 - ACCURACY: 0.7812\n",
      "BATCH 161/481 - LOSS: 0.5618 - ACCURACY: 0.8750\n",
      "BATCH 181/481 - LOSS: 0.7310 - ACCURACY: 0.7188\n",
      "BATCH 201/481 - LOSS: 0.5733 - ACCURACY: 0.7812\n",
      "BATCH 221/481 - LOSS: 0.5456 - ACCURACY: 0.7812\n",
      "BATCH 241/481 - LOSS: 0.4154 - ACCURACY: 0.8438\n",
      "BATCH 261/481 - LOSS: 0.7652 - ACCURACY: 0.7188\n",
      "BATCH 281/481 - LOSS: 0.6321 - ACCURACY: 0.7188\n",
      "BATCH 301/481 - LOSS: 0.5304 - ACCURACY: 0.7812\n",
      "BATCH 321/481 - LOSS: 0.8718 - ACCURACY: 0.5938\n",
      "BATCH 341/481 - LOSS: 0.7166 - ACCURACY: 0.6250\n",
      "BATCH 361/481 - LOSS: 0.4536 - ACCURACY: 0.8125\n",
      "BATCH 381/481 - LOSS: 0.4931 - ACCURACY: 0.8438\n",
      "BATCH 401/481 - LOSS: 0.4866 - ACCURACY: 0.8438\n",
      "BATCH 421/481 - LOSS: 0.4328 - ACCURACY: 0.8125\n",
      "BATCH 441/481 - LOSS: 0.7263 - ACCURACY: 0.7500\n",
      "BATCH 461/481 - LOSS: 0.7041 - ACCURACY: 0.7500\n",
      "BATCH 481/481 - LOSS: 0.6786 - ACCURACY: 0.7188\n",
      "\n",
      "\t[TRAIN] EPOCH15-LOSS:0.590257371041978,ACCURACY:0.7781964656964657\n",
      "\n",
      "EPOCH15-VALIDATING...\n",
      "\t[VALID] LOSS:0.9492081830898921,ACCURACY:0.67109375\n",
      "\n",
      "Execution time: 0:09:31.530521\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.23      0.29       108\n",
      "           1       0.38      0.55      0.45       214\n",
      "           2       0.32      0.03      0.06       237\n",
      "           3       0.76      0.95      0.84      1299\n",
      "           4       0.45      0.15      0.22       254\n",
      "\n",
      "    accuracy                           0.67      2112\n",
      "   macro avg       0.46      0.38      0.37      2112\n",
      "weighted avg       0.61      0.67      0.61      2112\n",
      "\n",
      "Test Accuracy: 0.671875\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "a = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b9e3be-5716-48a0-bf16-0868aa10aa76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
