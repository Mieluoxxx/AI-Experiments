{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import timm\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import model_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Seeds basic parameters for reproductibility of results\n",
    "    \n",
    "    Arguments:\n",
    "        seed {int} -- Number of the seed\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general global variables\n",
    "DATA_PATH = \"/kaggle/input/cassava-leaf-disease-classification\"\n",
    "TRAIN_PATH = \"/kaggle/input/cassava-leaf-disease-classification/train_images\"\n",
    "TRAIN_PATH = \"/kaggle/input/cassava-leaf-disease-classification/test_images/\"\n",
    "MODEL_PATH = (\n",
    "    \"/kaggle/input/vit-base-models-pretrained-pytorch/jx_vit_base_p16_224-80ecf9dd.pth\"\n",
    ")\n",
    "BEST_MODEL = \"/kaggle/working/best_model.pth\"\n",
    "SUBMISSION_FILE = \"submission.csv\"\n",
    "\n",
    "# model specific global variables\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "LR = 2e-05\n",
    "GAMMA = 0.7\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = model_selection.train_test_split(\n",
    "    df, test_size=0.1, random_state=42, stratify=df.label.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Helper Class to create the pytorch dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, data_path=DATA_PATH, mode=\"train\", transforms=None):\n",
    "        super().__init__()\n",
    "        self.df_data = df.values\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        self.data_dir = \"train_images\" if mode == \"train\" else \"test_images\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name, label = self.df_data[index]\n",
    "        img_path = os.path.join(self.data_path, self.data_dir, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(img)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image augmentations\n",
    "transforms_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(p=0.3),\n",
    "        transforms.RandomVerticalFlip(p=0.3),\n",
    "        transforms.RandomResizedCrop(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_valid = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available Vision Transformer Models: \")\n",
    "timm.list_models(\"vit*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "class ViTBase16(nn.Module):\n",
    "    def __init__(self, n_classes, pretrained=False):\n",
    "\n",
    "        super(ViTBase16, self).__init__()\n",
    "\n",
    "        self.model = timm.create_model(\"vit_base_patch16_224\", pretrained=False)\n",
    "        if pretrained:\n",
    "            self.model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def train_one_epoch(self, train_loader, criterion, optimizer, device, writer, epoch):\n",
    "        # keep track of training loss\n",
    "        epoch_loss = 0.0\n",
    "        epoch_accuracy = 0.0\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        self.model.train()\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if device.type == \"cuda\":\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = self.forward(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # Calculate Accuracy\n",
    "            accuracy = (output.argmax(dim=1) == target).float().mean()\n",
    "            # update training loss and accuracy\n",
    "            epoch_loss += loss\n",
    "            epoch_accuracy += accuracy\n",
    "            if i % 20 == 0:\n",
    "                print(f\"BATCH {i+1}/{len(train_loader)} - LOSS: {loss.item():.4f} - ACCURACY: {accuracy.item():.4f}\")\n",
    "                writer.add_scalar('Training Loss', loss.item(), epoch * len(train_loader) + i)\n",
    "                writer.add_scalar('Training Accuracy', accuracy.item(), epoch * len(train_loader) + i)\n",
    "            optimizer.step()\n",
    "\n",
    "        return epoch_loss / len(train_loader), epoch_accuracy / len(train_loader)\n",
    "\n",
    "    def valid_one_epoch(self, valid_loader, criterion, device, writer, epoch):\n",
    "        # keep track of validation loss\n",
    "        valid_loss = 0.0\n",
    "        valid_accuracy = 0.0\n",
    "\n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        self.model.eval()\n",
    "        for data, target in valid_loader:\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if device.type == \"cuda\":\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            elif device.type == \"xla\":\n",
    "                data = data.to(device, dtype=torch.float32)\n",
    "                target = target.to(device, dtype=torch.int64)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = self.model(data)\n",
    "                # calculate the batch loss\n",
    "                loss = criterion(output, target)\n",
    "                # Calculate Accuracy\n",
    "                accuracy = (output.argmax(dim=1) == target).float().mean()\n",
    "                # update average validation loss and accuracy\n",
    "                valid_loss += loss\n",
    "                valid_accuracy += accuracy\n",
    "\n",
    "        writer.add_scalar('Validation Loss', valid_loss / len(valid_loader), epoch)\n",
    "        writer.add_scalar('Validation Accuracy', valid_accuracy / len(valid_loader), epoch)\n",
    "\n",
    "        return valid_loss / len(valid_loader), valid_accuracy / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gpu(model, epochs, device, criterion, optimizer, train_loader, valid_loader=None):\n",
    "    writer = SummaryWriter()\n",
    "    valid_loss_min = np.Inf\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "\n",
    "    for epoch in  range(1,epochs+1):  #调用数据和模型进行训练-Log\n",
    "        gc.collect()  #通过gc清理内存\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"EPOCH{epoch}-TRAINING...\")\n",
    "\n",
    "        train_loss,train_acc=model.train_one_epoch(train_loader,criterion,optimizer,device,writer,epoch)\n",
    "        print(f\"\\n\\t[TRAIN] EPOCH{epoch}-LOSS:{train_loss},ACCURACY:{train_acc}\\n\")\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        gc.collect()\n",
    "\n",
    "        #valid\n",
    "        if valid_loader is not None:\n",
    "            gc.collect()\n",
    "            print(f\"EPOCH{epoch}-VALIDATING...\")\n",
    "            valid_loss,valid_acc = model.valid_one_epoch(valid_loader,criterion,device,writer,epoch)\n",
    "            print(f\"\\t[VALID] LOSS:{valid_loss},ACCURACY:{valid_acc}\\n\")\n",
    "            valid_losses.append(valid_loss)\n",
    "            valid_accs.append(valid_acc)\n",
    "            gc.collect()\n",
    "            #save !!!\n",
    "            if valid_loss<=valid_loss_min and epoch!=1:\n",
    "                print(\"Validation loss decreased ({:.4f} -->{:.4f}). Saving model...\".format(valid_loss_min,valid_loss))\n",
    "                torch.save(model.state_dict(),'best_model.pth')\n",
    "                valid_loss_min=valid_loss\n",
    "    writer.close()\n",
    "    return {\n",
    "        \"train_loss\":train_losses,\n",
    "        \"valid_losses\":valid_losses,\n",
    "        \"train_acc\":train_accs,\n",
    "        \"valid_acces\":valid_accs,   \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "    train_df, valid_df = model_selection.train_test_split(df, test_size=0.1, random_state=42, shuffle=True,\n",
    "                                                         stratify=df.label.values)\n",
    "\n",
    "    train_dataset = CassavaDataset(train_df, transforms=transforms_train)\n",
    "    valid_dataset = CassavaDataset(valid_df, transforms=transforms_valid)\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        drop_last=True,\n",
    "        num_workers=4,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        drop_last=True,\n",
    "        num_workers=4,\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    lr = LR\n",
    "    model = ViTBase16(n_classes=5, pretrained=True)\n",
    "    model=model.cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    #开始训练前\n",
    "    start_time=datetime.now()\n",
    "    logs = fit_gpu(model=model,\n",
    "                       epochs=N_EPOCHS,\n",
    "                       device=device,\n",
    "                       criterion=criterion,\n",
    "                       optimizer=optimizer,\n",
    "                       train_loader=train_loader,\n",
    "                       valid_loader=valid_loader)\n",
    "\n",
    "    print(f\"Execution time:{datetime.now() - start_time}\")\n",
    "    torch.save(model.state_dict(),f'end_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "# a = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL=\"/kaggle/input/cassava-vit-b16/best_model.pth\"\n",
    "test_df = pd.read_csv(\"/kaggle/input/cassava-leaf-disease-classification/sample_submission.csv\")\n",
    "transforms_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_dataset = CassavaDataset(test_df, transforms=transforms_test, mode=\"test\")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pretrained_model = ViTBase16(n_classes=5)\n",
    "pretrained_model.load_state_dict(torch.load(BEST_MODEL, map_location=device))\n",
    "pretrained_model =pretrained_model.to(device)\n",
    "pretrained_model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = pretrained_model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        \n",
    "test_df['label'] = predictions\n",
    "\n",
    "# Save to CSV\n",
    "test_df.to_csv(SUBMISSION_FILE, index=False)\n",
    "print(f\"Submission file saved to {SUBMISSION_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
