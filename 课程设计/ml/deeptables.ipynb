{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 13:19:57.356948: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-11 13:19:57.356977: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06-11 13:19:58 I deeptables.m.deeptable.py 337 - X.Shape=(144000, 35), y.Shape=(144000,), batch_size=128, config=ModelConfig(name='conf-1', nets=['dnn_nets', 'linear', 'fm_nets'], categorical_columns='auto', exclude_columns=[], task='auto', pos_label=None, metrics=['accuracy'], auto_categorize=False, cat_exponent=0.5, cat_remain_numeric=True, auto_encode_label=True, auto_imputation=True, auto_discrete=False, auto_discard_unique=True, apply_gbm_features=False, gbm_params={}, gbm_feature_type='embedding', fixed_embedding_dim=True, embeddings_output_dim=4, embeddings_initializer='uniform', embeddings_regularizer=None, embeddings_activity_regularizer=None, dense_dropout=0, embedding_dropout=0.3, stacking_op='add', output_use_bias=True, apply_class_weight=False, optimizer='auto', loss='auto', dnn_params={'hidden_units': ((128, 0, False), (64, 0, False)), 'activation': 'relu'}, autoint_params={'num_attention': 3, 'num_heads': 1, 'dropout_rate': 0, 'use_residual': True}, fgcnn_params={'fg_filters': (14, 16), 'fg_heights': (7, 7), 'fg_pool_heights': (2, 2), 'fg_new_feat_filters': (2, 2)}, fibinet_params={'senet_pooling_op': 'mean', 'senet_reduction_ratio': 3, 'bilinear_type': 'field_interaction'}, cross_params={'num_cross_layer': 4}, pnn_params={'outer_product_kernel_type': 'mat'}, afm_params={'attention_factor': 4, 'dropout_rate': 0}, cin_params={'cross_layer_size': (128, 128), 'activation': 'relu', 'use_residual': False, 'use_bias': False, 'direct': False, 'reduce_D': False}, home_dir=None, monitor_metric=None, earlystopping_patience=1, earlystopping_mode='auto', gpu_usage_strategy='memory_growth', distribute_strategy=None, var_len_categorical_columns=None)\n",
      "06-11 13:19:58 I deeptables.m.deeptable.py 338 - metrics:['accuracy']\n",
      "06-11 13:19:58 I hypernets.t.toolbox.py 329 - 2 class detected, {0, 1}, so inferred as a [binary classification] task\n",
      "06-11 13:19:58 I deeptables.m.preprocessor.py 261 - Preparing features...\n",
      "06-11 13:19:58 I deeptables.m.preprocessor.py 336 - Preparing features taken 0.03810453414916992s\n",
      "06-11 13:19:58 I deeptables.m.preprocessor.py 341 - Data imputation...\n",
      "06-11 13:19:59 I deeptables.m.preprocessor.py 383 - Imputation taken 0.1388089656829834s\n",
      "06-11 13:19:59 I deeptables.m.preprocessor.py 388 - Categorical encoding...\n",
      "06-11 13:19:59 I deeptables.m.preprocessor.py 393 - Categorical encoding taken 0.00039005279541015625s\n",
      "06-11 13:19:59 I deeptables.m.preprocessor.py 196 - fit_transform taken 0.22305774688720703s\n",
      "06-11 13:19:59 I deeptables.m.deeptable.py 353 - Training...\n",
      "06-11 13:19:59 I deeptables.m.deeptable.py 752 - Injected a callback [EarlyStopping]. monitor:val_accuracy, patience:1, mode:max\n",
      "06-11 13:19:59 I deeptables.u.dataset_generator.py 250 - create dataset generator with _TFDGForPandas, batch_size=128, shuffle=True, drop_remainder=True\n",
      "06-11 13:19:59 I deeptables.u.dataset_generator.py 250 - create dataset generator with _TFDGForPandas, batch_size=128, shuffle=True, drop_remainder=True\n",
      "06-11 13:19:59 I deeptables.m.deepmodel.py 231 - Building model...\n",
      "06-11 13:19:59 I deeptables.m.deepmodel.py 287 - >>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['input_continuous_all: (35)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "None\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 35)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets', 'linear', 'fm_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 35), output_shape (None, 64)\n",
      "linear: input_shape (None, 35), output_shape (None, 1)\n",
      "fm: input_shape None, output_shape None\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 1), use_bias: True\n",
      "loss: binary_crossentropy\n",
      "optimizer: Adam\n",
      "---------------------------------------------------------\n",
      "\n",
      "06-11 13:19:59 I deeptables.m.deepmodel.py 105 - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 13:19:59.115785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-11 13:19:59.116107: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-11 13:19:59.116433: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-11 13:19:59.116764: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-11 13:19:59.116851: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-06-11 13:19:59.167001: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-11 13:19:59.167145: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-06-11 13:19:59.167158: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-06-11 13:19:59.221240: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/900 [..............................] - ETA: 6:43 - loss: 32392.4688 - accuracy: 0.4766"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 13:19:59.596753: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 2s 1ms/step - loss: 4357.5938 - accuracy: 0.6231 - val_loss: 325.6506 - val_accuracy: 0.7863\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 221.7709 - accuracy: 0.7741 - val_loss: 68.0954 - val_accuracy: 0.8054\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 67.3900 - accuracy: 0.7759 - val_loss: 33.0061 - val_accuracy: 0.8002\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00003: early stopping\n",
      "06-11 13:20:03 I deeptables.m.deepmodel.py 122 - Training finished.\n",
      "06-11 13:20:03 I deeptables.m.deeptable.py 369 - Training finished.\n",
      "06-11 13:20:03 I deeptables.m.deeptable.py 704 - Model has been saved to:dt_output/dt_20240611131958_dnn_nets_linear_fm_nets/dnn_nets+linear+fm_nets.h5\n",
      "06-11 13:20:03 I deeptables.m.preprocessor.py 242 - Transform [X]...\n",
      "06-11 13:20:03 I deeptables.m.preprocessor.py 249 - transform_X taken 0.019307613372802734s\n",
      "06-11 13:20:03 I deeptables.m.preprocessor.py 230 - Transform [y]...\n",
      "06-11 13:20:03 I deeptables.m.preprocessor.py 236 - transform_y taken 0.0013165473937988281s\n",
      "06-11 13:20:03 I deeptables.m.deepmodel.py 158 - Performing evaluation...\n",
      "06-11 13:20:03 I deeptables.u.dataset_generator.py 250 - create dataset generator with _TFDGForPandas, batch_size=512, shuffle=False, drop_remainder=False\n",
      "06-11 13:20:03 I deeptables.m.deeptable.py 685 - Perform prediction...\n",
      "06-11 13:20:03 I deeptables.m.preprocessor.py 242 - Transform [X]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moguw/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06-11 13:20:03 I deeptables.m.preprocessor.py 249 - transform_X taken 0.01616191864013672s\n",
      "06-11 13:20:03 I deeptables.m.deepmodel.py 130 - Performing predictions...\n",
      "06-11 13:20:03 I deeptables.u.dataset_generator.py 250 - create dataset generator with _TFDGForPandas, batch_size=128, shuffle=False, drop_remainder=False\n",
      "06-11 13:20:03 I deeptables.m.deeptable.py 559 - predict_proba taken 0.18422889709472656s\n",
      "06-11 13:20:03 I deeptables.m.deeptable.py 594 - Reverse indicators to labels.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81     17909\n",
      "           1       0.80      0.83      0.81     18091\n",
      "\n",
      "    accuracy                           0.81     36000\n",
      "   macro avg       0.81      0.81      0.81     36000\n",
      "weighted avg       0.81      0.81      0.81     36000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from deeptables.models import deeptable, deepnets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# 加载数据\n",
    "train_df = pd.read_csv('train.csv')\n",
    "train_df = train_df.drop(['id', 'timecc'], axis=1)\n",
    "\n",
    "# 创建交叉特征\n",
    "train_df['kd_ratio'] = train_df['kills'] / (train_df['deaths'] + 1)\n",
    "train_df['multikill_ratio'] = train_df['largestmultikill'] / (train_df['kills'] + 1)\n",
    "train_df['heal_damage_ratio'] = train_df['totheal'] / (train_df['totdmgdealt'] + 1)\n",
    "train_df['damage_taken_ratio'] = train_df['totdmgtochamp'] / (train_df['totdmgtaken'] + 1)\n",
    "train_df['kill_turret_ratio'] = train_df['kills'] / (train_df['dmgtoturrets'] + 1)\n",
    "train_df['crit_damage_ratio'] = train_df['largestcrit'] / (train_df['totdmgdealt'] + 1)\n",
    "\n",
    "# 划分数据集\n",
    "X = train_df.drop('win', axis=1)\n",
    "y = train_df['win']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定义模型配置\n",
    "config = deeptable.ModelConfig(nets=deepnets.DeepFM)\n",
    "\n",
    "# 创建深度表模型\n",
    "dt = deeptable.DeepTable(config=config)\n",
    "\n",
    "# 模型训练\n",
    "model, history = dt.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# 模型评估\n",
    "result = dt.evaluate(X_val, y_val, batch_size=512, verbose=0)\n",
    "\n",
    "# 预测\n",
    "y_pred = dt.predict(X_val)\n",
    "\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
